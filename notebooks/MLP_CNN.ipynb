{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your first fully connected network and a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple fully connected network (a Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the paths and make a dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_handling import WCH5Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's make our model. We'll talk about \n",
    "  - model parameters\n",
    "  - inputs and the forward method\n",
    "  - Modules containing modules\n",
    "  - Sequential Module  \n",
    "  Lets open [simpleMLP](/edit/models/simpleMLP.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleMLP import SimpleMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP=SimpleMLP(num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's look at the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc5.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc5.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by default the parameters have `requires_grad` set - i.e. we will be able to obtain gradient of the loss function with respect to these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the [source](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear) for the linear module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters descend from the `Tensor` class. When `Parameter` object is instantiated as a member of a `Module` object class the parameter is added to `Module`s list of parameters automatically. This list and values are captured in the 'state dictionary' of a module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.0034, -0.0018,  0.0042,  ...,  0.0044, -0.0044,  0.0034],\n",
       "                      [-0.0020,  0.0016,  0.0041,  ...,  0.0006,  0.0044, -0.0031],\n",
       "                      [-0.0059, -0.0050,  0.0059,  ...,  0.0046,  0.0033, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0012,  0.0008, -0.0027,  ...,  0.0004,  0.0059,  0.0063],\n",
       "                      [ 0.0001, -0.0037, -0.0049,  ..., -0.0060, -0.0035,  0.0046],\n",
       "                      [ 0.0051, -0.0008,  0.0006,  ..., -0.0034, -0.0043,  0.0031]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-5.7431e-03,  1.9700e-03, -2.9609e-03,  2.2011e-03,  2.2593e-03,\n",
       "                      -2.6920e-04,  4.4453e-03, -5.2280e-03,  6.3320e-03, -1.3988e-03,\n",
       "                      -3.4343e-03,  3.5975e-03, -4.4380e-03, -4.6579e-03, -3.5768e-03,\n",
       "                       1.8131e-03,  2.8693e-03,  5.3007e-03, -4.6061e-03, -6.3432e-03,\n",
       "                       3.6595e-03, -1.1523e-03, -3.6214e-04,  3.2673e-03,  1.3983e-03,\n",
       "                      -2.0657e-03, -1.9644e-03, -2.4844e-03, -2.3870e-03,  4.8651e-03,\n",
       "                       3.5064e-04, -2.1769e-03,  4.7764e-03, -1.6895e-03,  5.7970e-03,\n",
       "                      -5.3684e-03,  2.2993e-03,  1.6568e-03, -2.9558e-03, -6.2719e-03,\n",
       "                       5.0084e-03, -4.6509e-03,  2.8107e-04,  2.2958e-03, -5.8528e-03,\n",
       "                       2.3483e-03,  4.8395e-03,  4.8358e-03,  3.4887e-03, -4.6587e-03,\n",
       "                      -5.9347e-03, -2.0851e-03, -3.2527e-03, -9.1377e-04,  1.6352e-03,\n",
       "                       4.9445e-03,  3.3726e-03,  4.4195e-03,  3.6327e-03,  5.0762e-04,\n",
       "                      -4.4382e-03, -2.4216e-03, -1.6452e-03,  1.0007e-03, -4.4316e-03,\n",
       "                       3.7829e-03,  8.5410e-04,  1.2815e-03,  1.0145e-03,  1.3106e-03,\n",
       "                      -3.8448e-03, -4.3315e-03, -3.5938e-03,  5.5900e-03, -4.4035e-04,\n",
       "                      -3.0505e-03, -2.2733e-03,  6.1844e-03,  5.9772e-03, -6.2212e-03,\n",
       "                      -1.2580e-03,  3.3150e-03,  4.9420e-03,  3.1864e-03, -8.4477e-05,\n",
       "                      -3.1269e-03, -5.1107e-03, -1.5834e-04, -4.7733e-03, -2.6478e-03,\n",
       "                      -2.9444e-03,  4.0259e-03,  5.9342e-03, -3.4682e-03, -7.8817e-05,\n",
       "                      -4.4949e-03,  1.3085e-03,  1.2780e-03,  7.1880e-04, -4.8886e-03,\n",
       "                      -4.4664e-03, -5.1005e-03, -9.5658e-04,  5.0754e-03,  5.5918e-04,\n",
       "                      -5.1359e-03,  4.5123e-03, -2.7515e-05, -2.1379e-03,  1.6710e-03,\n",
       "                      -6.0369e-04,  4.2602e-03,  5.8266e-03,  3.5075e-03,  1.4251e-03,\n",
       "                       2.3885e-03, -2.3306e-03,  6.2067e-03,  6.2324e-03, -5.8322e-03,\n",
       "                       1.8319e-03, -5.3531e-03, -4.9091e-03, -2.4267e-03,  2.1497e-03,\n",
       "                       2.6530e-03, -5.2859e-03, -2.9688e-03, -1.7585e-04, -2.2891e-03,\n",
       "                       2.6650e-03,  4.4656e-03,  4.9258e-03, -5.9519e-03, -4.8624e-03,\n",
       "                      -2.1953e-04,  3.4967e-03,  8.8732e-04, -1.6428e-03,  4.5353e-03,\n",
       "                      -2.0702e-03,  8.8469e-04,  4.6406e-03,  4.7636e-03,  3.3617e-03,\n",
       "                       2.3794e-03, -3.3681e-03, -2.0154e-03,  4.4800e-03,  9.9900e-04,\n",
       "                      -4.7548e-03, -6.3664e-03,  1.0429e-03, -2.9813e-03,  5.0107e-06,\n",
       "                      -1.7741e-03, -5.0080e-03,  2.9981e-03,  2.2945e-03,  7.8563e-04,\n",
       "                      -1.6025e-04, -1.4090e-03, -1.2591e-03, -5.0090e-03,  1.0495e-03,\n",
       "                      -6.2578e-03,  5.0254e-03, -3.9700e-03,  3.3722e-05, -9.6692e-05,\n",
       "                       3.5864e-03,  6.0141e-03,  4.5027e-03, -4.4768e-04,  2.2386e-03,\n",
       "                      -2.0477e-03, -1.7994e-03,  8.6827e-04, -4.1141e-03,  2.8327e-03,\n",
       "                      -2.5120e-04,  2.3070e-03,  2.0281e-03,  1.1473e-03,  5.9867e-03,\n",
       "                      -2.5868e-03, -5.6581e-03, -3.1835e-03,  5.6999e-03, -1.5333e-03,\n",
       "                       5.0987e-04,  3.2722e-03,  5.3151e-03,  4.0930e-03, -4.5948e-03,\n",
       "                      -3.0911e-03, -1.3146e-03, -5.9250e-03, -2.8038e-03, -4.1907e-03,\n",
       "                       5.4501e-04,  4.9663e-03, -4.9032e-03, -2.2833e-03, -5.7708e-03,\n",
       "                       3.9966e-03, -2.4192e-03,  5.9754e-03,  3.7601e-05, -6.0661e-03,\n",
       "                      -2.2473e-03,  2.3536e-03,  2.3932e-04,  4.8665e-03, -1.3675e-04,\n",
       "                       5.0964e-03,  4.0754e-03,  1.9819e-03,  1.3358e-03, -3.2818e-03,\n",
       "                       5.1944e-03, -2.3797e-03, -4.5950e-03,  5.6378e-03, -2.7984e-03,\n",
       "                       4.1476e-03,  2.9873e-04,  9.1410e-04, -3.6471e-03, -3.8909e-03,\n",
       "                       9.6287e-04,  9.0552e-04,  5.9872e-03,  5.5660e-03, -6.2347e-03,\n",
       "                       5.3266e-03,  4.3745e-03, -4.8159e-04,  6.8574e-04, -5.2654e-03,\n",
       "                       1.1694e-03,  5.8005e-03,  2.2486e-03,  9.4321e-04,  3.7653e-03,\n",
       "                      -2.2121e-03,  6.3893e-03, -2.8535e-03,  2.0556e-03, -3.7205e-03,\n",
       "                       5.4172e-03, -2.8197e-03, -6.1228e-03,  2.2847e-03, -4.3836e-03,\n",
       "                       5.9855e-03,  9.5236e-04, -1.2070e-03,  8.2304e-04,  3.9076e-03,\n",
       "                      -4.5579e-03,  6.2512e-03, -3.3708e-03,  5.0161e-03,  4.7875e-03,\n",
       "                       2.5221e-03,  6.3373e-03, -2.5301e-03, -5.9744e-03, -3.1995e-03,\n",
       "                       2.2129e-03,  1.1251e-03,  5.8831e-03, -1.1252e-03,  2.8225e-03,\n",
       "                       4.1638e-03,  6.3259e-03,  6.0092e-03, -1.1673e-03,  5.1171e-03,\n",
       "                      -3.7586e-03,  1.9655e-04,  2.6807e-03, -4.4904e-03, -1.7919e-03,\n",
       "                       1.2483e-03, -5.3126e-03, -3.6242e-03, -5.7940e-03,  1.8687e-03,\n",
       "                       1.6300e-03,  8.8677e-04,  5.0060e-03,  2.0942e-03,  3.6430e-03,\n",
       "                       4.9925e-03, -4.6362e-04, -7.6935e-05,  2.7667e-04,  2.2406e-03,\n",
       "                       5.5948e-03,  3.3304e-03, -8.4846e-04,  4.8495e-03,  5.9991e-03,\n",
       "                      -2.9805e-03, -4.0412e-03, -2.9998e-03,  4.1294e-03, -3.0015e-03,\n",
       "                      -1.4230e-04,  5.8607e-03,  1.0216e-03, -2.7848e-03, -4.7603e-03,\n",
       "                      -1.2104e-03,  8.4059e-04, -1.0789e-03, -2.5501e-03, -6.3057e-04,\n",
       "                      -1.0209e-03,  2.8761e-03,  5.5505e-03,  3.8050e-03,  4.6180e-03,\n",
       "                      -5.8621e-04,  5.3194e-03,  1.6082e-03, -3.2780e-03,  2.7397e-03,\n",
       "                      -1.2224e-03,  2.8914e-03,  4.4197e-03,  2.9462e-03, -4.3906e-04,\n",
       "                       5.9907e-03,  2.3250e-03, -5.2760e-03,  4.3814e-03,  1.1598e-03,\n",
       "                      -4.4594e-03,  1.6786e-03, -2.8974e-03, -3.1631e-03, -2.3335e-03,\n",
       "                       5.0254e-03, -5.7726e-03, -1.1254e-03, -5.4166e-03, -6.0329e-03,\n",
       "                      -3.4641e-03, -5.1787e-03,  2.6781e-03, -7.3650e-04, -6.1469e-03,\n",
       "                       4.2488e-03, -2.5376e-03,  5.6753e-03, -5.7297e-03, -1.0298e-03,\n",
       "                      -3.6054e-03, -4.2793e-03,  3.1341e-03, -3.6619e-03,  3.4800e-03,\n",
       "                       2.9858e-03,  1.6836e-03,  4.2444e-03, -7.0657e-04,  3.6570e-03,\n",
       "                      -3.4931e-03,  1.1402e-03, -4.9315e-03,  1.4710e-03,  4.0567e-03,\n",
       "                      -3.0917e-03, -2.3261e-03,  4.7464e-03,  4.8819e-03,  2.4150e-03,\n",
       "                      -3.0639e-03, -1.4582e-03,  4.3538e-03,  1.0551e-04,  3.3612e-03,\n",
       "                       2.9998e-04, -1.2045e-04,  5.9524e-03, -2.7543e-03, -4.9409e-03,\n",
       "                       2.4453e-03,  6.1988e-03, -4.6056e-03, -2.9221e-03, -1.6718e-04,\n",
       "                      -5.9327e-03,  2.1331e-03,  6.2766e-03, -8.4461e-04,  5.8324e-03,\n",
       "                      -3.2337e-03,  3.7335e-03,  4.3392e-03,  4.7510e-03,  6.1553e-03,\n",
       "                      -3.7159e-03, -3.1246e-03,  5.5604e-03, -3.5749e-03,  4.5245e-03,\n",
       "                       4.1624e-03, -1.8248e-03,  5.6585e-03, -5.7026e-03,  2.3936e-03,\n",
       "                      -2.9026e-03,  1.1343e-03,  5.0755e-03,  2.2465e-03,  5.0819e-03,\n",
       "                       8.5890e-04, -1.3368e-04, -5.0235e-03, -3.1685e-03, -4.5915e-03,\n",
       "                      -2.2306e-03, -5.3420e-03, -2.2460e-03,  3.9429e-03, -5.1428e-03,\n",
       "                       3.7564e-03,  1.7999e-03,  1.6964e-03, -3.3158e-03,  2.0059e-03,\n",
       "                       5.0542e-03,  1.7157e-05,  3.6930e-03, -3.6916e-03, -4.9336e-03,\n",
       "                      -4.3911e-03, -5.9585e-03, -4.7923e-03, -2.6717e-03, -2.1110e-03,\n",
       "                       1.7263e-03, -4.1123e-03, -2.8009e-03, -4.6664e-03,  2.5162e-03,\n",
       "                       3.3365e-03, -4.1756e-03,  1.9003e-03, -6.3072e-03, -3.8650e-03,\n",
       "                       1.5163e-03,  2.6408e-03,  6.1414e-03, -5.3037e-03,  4.0210e-03,\n",
       "                      -3.5047e-03,  1.1506e-03,  5.7296e-03,  3.3352e-03, -6.0263e-03,\n",
       "                       1.1834e-03,  5.1374e-03,  3.0643e-03, -2.1295e-03, -3.7411e-03,\n",
       "                       4.0264e-03, -8.4095e-04,  1.9508e-04,  1.6244e-04,  5.7789e-03,\n",
       "                      -2.3605e-03,  1.3277e-03, -2.9283e-03,  3.8094e-03, -1.2509e-03,\n",
       "                      -5.3323e-03, -4.0404e-03,  4.1695e-03,  5.1376e-03, -4.1295e-03,\n",
       "                       9.5557e-04, -2.8027e-03, -6.2688e-03,  5.5857e-03, -3.1904e-03,\n",
       "                      -1.9675e-03,  3.5434e-03, -3.7082e-03, -9.6820e-04, -1.4347e-03,\n",
       "                       5.3882e-03, -1.8013e-03,  1.4027e-03, -3.7229e-03, -5.0402e-04,\n",
       "                       2.4277e-03,  1.0051e-03, -2.1561e-03,  3.8163e-03,  6.1913e-03,\n",
       "                      -4.5287e-03, -3.5512e-03,  2.8948e-03,  6.3644e-03,  2.7560e-03,\n",
       "                       2.3582e-04, -2.1650e-03,  4.3977e-03, -4.5572e-04,  9.0009e-04,\n",
       "                       5.9948e-03,  4.8420e-03,  4.0942e-03, -7.0553e-04,  5.5898e-03,\n",
       "                       5.0620e-03,  5.7934e-03, -1.2869e-04,  2.6231e-03, -2.8451e-04,\n",
       "                      -5.2665e-04,  6.3451e-03,  2.2926e-03,  4.0753e-03, -3.8882e-03,\n",
       "                       3.8053e-03, -4.3987e-03, -3.6183e-03, -3.5225e-03, -9.5384e-04,\n",
       "                      -3.5756e-03,  3.9356e-03, -3.5302e-03,  5.6688e-03,  3.9868e-03,\n",
       "                       1.0157e-03, -1.8986e-04,  8.1842e-04,  1.3198e-03,  2.3316e-03,\n",
       "                      -4.5520e-03,  5.5712e-03, -4.9817e-03, -2.2424e-03, -5.6889e-03,\n",
       "                       3.1608e-03,  1.0924e-04, -5.5240e-03,  2.0418e-03,  2.9045e-03,\n",
       "                      -1.7255e-03,  2.2108e-03, -2.2708e-04,  3.9628e-03,  5.1829e-03,\n",
       "                       4.6910e-03, -5.3232e-03, -6.1840e-03,  3.8124e-03,  5.2978e-03,\n",
       "                      -5.5932e-03, -4.9003e-03, -1.7074e-03, -2.7964e-03,  6.8316e-04,\n",
       "                       3.5610e-03, -5.8348e-04, -5.7337e-03,  3.2055e-03, -4.9363e-03,\n",
       "                      -1.4413e-03,  8.8686e-04,  4.8306e-03, -6.1128e-03, -2.5621e-04,\n",
       "                      -3.3372e-03,  2.4536e-03, -6.4079e-03,  2.0381e-03,  4.5090e-03,\n",
       "                      -1.6296e-03, -4.2722e-03, -1.7006e-04,  3.9005e-03, -4.9387e-03,\n",
       "                       1.5191e-03,  3.1415e-03,  5.3608e-03, -5.8570e-03,  2.5740e-03,\n",
       "                       1.2643e-03,  2.8504e-03, -3.4981e-03,  3.8291e-03,  5.6836e-03,\n",
       "                      -8.3841e-04, -4.7197e-03, -3.9043e-03, -3.6748e-04, -6.1549e-03,\n",
       "                       3.5918e-04, -1.4282e-03, -2.3044e-03, -2.8012e-03, -5.7623e-03,\n",
       "                       1.3401e-03, -9.1589e-04,  1.1996e-03,  1.7444e-03,  1.2416e-03,\n",
       "                       5.6061e-03,  1.3437e-03, -3.1336e-03, -8.4696e-04,  6.0332e-03,\n",
       "                      -4.9325e-03, -9.7180e-04, -3.4984e-03,  1.0460e-04, -4.6513e-03,\n",
       "                      -2.5321e-03,  4.2360e-03,  4.1988e-03, -2.8074e-04, -3.0251e-03,\n",
       "                       1.5885e-03,  5.3745e-03,  1.8448e-03,  6.0477e-03,  5.4702e-03,\n",
       "                      -5.0400e-04, -4.4053e-04, -6.2537e-03,  2.1574e-03, -6.0987e-03,\n",
       "                       1.5908e-03, -2.0539e-03,  2.3656e-03,  3.6750e-04, -5.7714e-03,\n",
       "                       4.6265e-04,  5.2723e-04,  2.9358e-03,  6.1152e-03,  4.3362e-03,\n",
       "                      -3.5187e-03,  3.9923e-03,  3.4945e-03, -2.2776e-03, -5.0362e-03,\n",
       "                      -4.1544e-03,  1.5753e-03, -7.3087e-04,  5.9705e-03, -1.3604e-03,\n",
       "                       1.1764e-03,  2.8600e-03,  4.0048e-03, -2.7824e-03,  5.5814e-03,\n",
       "                       2.1484e-03, -2.6578e-03,  6.4087e-03,  2.2819e-03, -6.3902e-03,\n",
       "                       2.4848e-03, -3.5532e-03, -1.2997e-03,  1.8122e-03,  9.2777e-04,\n",
       "                      -3.0493e-03,  4.6595e-03, -2.0019e-03, -2.1510e-03,  5.0192e-03,\n",
       "                       1.4890e-03,  1.6620e-03,  3.6788e-03,  1.6256e-03,  5.9860e-03,\n",
       "                      -2.8311e-03, -5.4655e-03, -5.5904e-03, -6.0272e-04, -5.2080e-03,\n",
       "                      -6.2414e-03, -1.5201e-04,  5.6146e-04,  5.8229e-03, -1.3718e-03,\n",
       "                      -7.4415e-04, -4.6899e-03, -6.3040e-03, -8.3156e-04,  5.8010e-03,\n",
       "                       8.0803e-04, -1.8222e-03,  5.5573e-03, -6.5619e-04,  4.1731e-03,\n",
       "                       5.7329e-03, -9.4903e-04, -2.9821e-03,  2.1632e-03, -4.4272e-03,\n",
       "                      -1.3432e-03,  6.2539e-03, -7.5600e-04, -1.9307e-03,  1.4878e-03,\n",
       "                       4.4712e-03,  5.6544e-03, -4.0223e-03,  7.6784e-04, -2.4129e-03,\n",
       "                       1.4819e-03, -4.9575e-03,  4.9945e-03, -2.2859e-03, -4.0953e-03,\n",
       "                      -5.9573e-03,  2.1542e-03,  1.2435e-03, -4.2413e-04,  6.9058e-04,\n",
       "                      -5.2259e-03,  2.4554e-03, -5.3074e-03, -2.2771e-03, -8.2901e-04,\n",
       "                       2.5764e-03, -4.7405e-03,  5.5020e-03,  9.5177e-04,  4.7781e-03,\n",
       "                      -4.0064e-03, -1.1472e-03, -5.8225e-03, -2.9691e-03, -4.4011e-03,\n",
       "                       5.1027e-03,  3.7778e-03,  5.0805e-03,  4.4480e-03,  5.6770e-03,\n",
       "                       5.8830e-03,  4.5781e-03, -1.1196e-03,  2.0755e-03, -4.7813e-03,\n",
       "                      -4.0603e-03, -5.4227e-03,  4.7158e-03, -6.3180e-03, -1.5104e-03,\n",
       "                       4.2119e-03, -4.2705e-03,  4.2110e-03,  1.4975e-03, -4.7059e-03,\n",
       "                      -5.9724e-03, -5.5921e-03, -5.1422e-03,  9.8960e-04,  5.2661e-03,\n",
       "                       5.3914e-03,  5.5340e-03,  2.7706e-03,  5.5233e-03, -1.1662e-03,\n",
       "                       1.9853e-03,  2.0556e-03,  9.6367e-04, -3.1745e-03, -5.2070e-03,\n",
       "                      -1.6953e-03, -4.5529e-03, -1.0121e-03, -1.9020e-03,  3.4012e-03,\n",
       "                       4.8877e-03,  6.0905e-03, -1.8863e-03,  4.5271e-05, -1.3669e-03,\n",
       "                       1.7297e-03,  5.5024e-03, -6.3057e-04, -4.2522e-03,  7.9907e-04,\n",
       "                      -4.4979e-03,  6.0812e-03, -2.1817e-03, -4.1416e-03, -5.5402e-03,\n",
       "                       5.0985e-03,  2.1629e-03,  1.8588e-03, -1.6538e-03, -2.5979e-03,\n",
       "                       8.4546e-05, -2.0255e-03, -1.7320e-03,  3.5046e-03, -4.4760e-03,\n",
       "                       2.8083e-03, -5.3070e-03, -6.1519e-03, -9.4086e-04,  5.7966e-03,\n",
       "                       4.3348e-03,  2.5846e-03,  9.3287e-04,  3.3099e-03, -5.3301e-03,\n",
       "                      -5.3122e-03, -6.2518e-03, -1.0577e-03,  4.1970e-03,  3.5018e-03,\n",
       "                       3.2385e-03, -5.6887e-03, -6.3799e-03, -3.1674e-03,  4.4607e-03,\n",
       "                       1.9278e-03,  6.2099e-03, -5.6946e-03, -5.1525e-03, -2.8994e-03,\n",
       "                       5.8922e-04,  2.6349e-03,  5.3858e-03, -4.6428e-03, -3.1846e-03,\n",
       "                      -9.1234e-04, -3.3630e-03, -1.9449e-03,  6.2774e-03, -3.0251e-03,\n",
       "                       1.4325e-03, -5.1550e-03,  3.1456e-03, -6.2464e-03, -1.4339e-04,\n",
       "                       4.0771e-03, -3.0761e-03,  6.0183e-04,  5.9386e-03,  5.2376e-03,\n",
       "                      -5.6619e-03,  5.6936e-03, -7.1665e-04, -5.0245e-04,  1.0165e-03,\n",
       "                      -3.7271e-03, -2.8153e-03,  1.5114e-03,  3.0097e-03,  2.0996e-03,\n",
       "                      -4.1468e-03, -1.0292e-04,  5.1315e-03,  1.1386e-03,  5.3283e-03,\n",
       "                       1.1704e-03,  2.7388e-03, -1.4426e-03, -1.7512e-03,  2.6898e-04,\n",
       "                      -2.1088e-04, -4.0634e-03, -6.1505e-03, -5.0674e-03, -1.1501e-03,\n",
       "                       6.2511e-04,  2.0807e-03,  8.3308e-04, -3.9879e-03, -5.9217e-03,\n",
       "                      -5.6141e-03,  2.2668e-03,  3.6977e-03, -9.5205e-04,  3.9795e-03,\n",
       "                       1.8742e-05, -5.4067e-04,  1.4650e-03, -1.6435e-03,  3.0151e-03,\n",
       "                      -5.7450e-03,  2.6790e-03, -3.3758e-03,  4.4176e-03, -6.1032e-03,\n",
       "                      -4.1242e-03, -1.6621e-03, -1.3381e-03, -2.6116e-03, -2.8368e-03,\n",
       "                      -1.5309e-03,  1.4054e-03,  2.0748e-04, -1.1706e-03,  3.7170e-03,\n",
       "                       3.2994e-03,  5.3874e-03, -5.6576e-03,  3.6813e-03,  4.3724e-03,\n",
       "                      -4.3691e-03, -4.9133e-03,  6.0408e-03, -5.1443e-03,  6.1796e-03,\n",
       "                       3.3128e-03,  1.7091e-03, -4.7232e-03,  2.1594e-03, -4.7161e-03,\n",
       "                      -2.2180e-03, -1.1379e-04,  1.2778e-03,  8.0837e-04, -6.2650e-03,\n",
       "                       2.0311e-03, -3.0710e-03,  5.6106e-03,  2.8828e-03,  4.0721e-04,\n",
       "                      -4.0217e-04, -7.0749e-04,  2.1799e-03, -5.2732e-03, -5.3495e-03,\n",
       "                       1.2822e-03,  3.5881e-04,  1.4734e-03,  2.6560e-03,  2.2982e-03,\n",
       "                       4.5573e-03, -1.8059e-03,  5.9674e-04,  5.6147e-03,  1.4780e-03,\n",
       "                      -4.3220e-03,  2.8156e-03, -4.4578e-04,  1.0015e-03,  2.7177e-04,\n",
       "                       5.1961e-03,  3.5157e-03,  5.8016e-03,  3.2345e-03, -4.8740e-03,\n",
       "                       3.9464e-03, -4.3702e-03, -2.8779e-03,  3.9299e-03,  2.3029e-03,\n",
       "                       4.4051e-04, -1.8911e-03,  4.2842e-03, -3.5191e-03,  2.6511e-03,\n",
       "                      -5.6214e-04,  9.2463e-04])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0309,  0.0071, -0.0310,  ..., -0.0226, -0.0237, -0.0238],\n",
       "                      [-0.0308,  0.0180,  0.0300,  ...,  0.0256, -0.0028,  0.0267],\n",
       "                      [-0.0106,  0.0087,  0.0227,  ..., -0.0067, -0.0292, -0.0296],\n",
       "                      ...,\n",
       "                      [ 0.0108,  0.0054,  0.0189,  ..., -0.0166,  0.0046, -0.0270],\n",
       "                      [-0.0143,  0.0297,  0.0052,  ..., -0.0110, -0.0318, -0.0202],\n",
       "                      [-0.0037, -0.0118, -0.0152,  ...,  0.0038, -0.0222,  0.0025]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 1.6939e-02, -2.2627e-02,  3.0342e-03,  2.0535e-02, -7.0561e-03,\n",
       "                      -1.0274e-02,  2.4829e-02,  4.8154e-03, -3.9294e-03,  1.3183e-02,\n",
       "                       6.3221e-03, -2.7442e-02, -1.2131e-02, -2.2500e-02, -1.6500e-02,\n",
       "                       2.4206e-02, -6.7685e-03, -1.1196e-02,  1.5286e-02, -4.1720e-04,\n",
       "                      -4.4039e-04, -1.3142e-02, -1.6938e-02,  1.8143e-02,  2.5706e-02,\n",
       "                       1.8698e-02, -2.0669e-02, -1.3245e-02, -1.7257e-03, -4.1829e-03,\n",
       "                       1.3478e-02,  1.7050e-03, -2.5899e-03, -6.2362e-03, -8.9770e-03,\n",
       "                      -2.4865e-02,  3.0270e-02, -1.0547e-03, -2.2614e-02,  2.1634e-02,\n",
       "                       2.8303e-02,  5.4522e-03, -1.6331e-02,  9.2374e-03,  1.3723e-02,\n",
       "                      -2.8532e-02,  2.5792e-02, -3.1462e-02,  8.8303e-03, -2.9451e-02,\n",
       "                       1.7156e-02, -2.1237e-02, -1.8385e-02, -1.3641e-02, -2.9958e-02,\n",
       "                       3.1299e-02,  1.1228e-02, -2.6422e-02, -2.3224e-02,  1.5699e-03,\n",
       "                       8.2530e-03,  2.9097e-02, -2.3006e-02,  3.1894e-02, -1.6088e-02,\n",
       "                       2.9801e-02, -3.2011e-02,  1.7056e-02, -6.6438e-03,  1.8008e-02,\n",
       "                      -1.7597e-02,  1.0923e-02, -2.5726e-02, -1.3966e-02, -2.7547e-02,\n",
       "                      -2.8770e-02,  3.1866e-02, -1.0021e-02,  1.5732e-02, -2.6455e-02,\n",
       "                      -1.1667e-02,  1.9921e-02,  1.0820e-02, -1.3028e-02,  1.8723e-02,\n",
       "                      -2.9079e-02,  4.8955e-03, -6.1257e-03,  1.0329e-02, -9.1385e-05,\n",
       "                      -2.3972e-02, -2.5454e-02,  1.7349e-02,  7.0198e-03, -1.6801e-02,\n",
       "                      -1.5012e-02, -1.8455e-02,  2.4923e-02,  2.4544e-03,  2.0145e-03,\n",
       "                       2.1658e-02,  2.7928e-03,  8.3190e-03,  1.7118e-02, -1.6402e-02,\n",
       "                       2.6825e-03, -1.8024e-03, -3.7317e-03,  5.8399e-03, -1.8161e-02,\n",
       "                      -2.1470e-04, -6.3390e-04, -7.4094e-03, -2.8771e-02, -2.8463e-02,\n",
       "                      -1.8666e-02,  1.1866e-02,  2.7622e-02, -2.8945e-02, -2.3262e-02,\n",
       "                      -1.8748e-02,  2.4394e-03,  1.4229e-02,  1.1104e-03, -1.2114e-04,\n",
       "                       2.3212e-02,  1.5904e-02,  3.0138e-02,  2.4369e-03, -2.4580e-02,\n",
       "                      -2.5694e-02, -1.6300e-02,  2.0174e-02,  1.6881e-02, -1.8989e-02,\n",
       "                      -3.6040e-03,  1.1010e-02, -1.1400e-02,  1.7393e-02,  5.1756e-03,\n",
       "                      -7.7105e-03, -6.9931e-03,  2.2822e-02, -1.9104e-02,  4.3618e-04,\n",
       "                       1.7696e-02,  1.3213e-02, -1.4662e-02, -8.3186e-03, -8.6255e-03,\n",
       "                      -1.5209e-02, -2.9743e-03,  2.1104e-02, -2.1755e-02,  2.6814e-02,\n",
       "                       1.9687e-02, -2.3968e-02,  2.2469e-02, -7.1014e-03,  3.3878e-03,\n",
       "                      -2.4588e-02,  4.7224e-03,  1.2036e-02, -7.4259e-03, -1.9051e-02,\n",
       "                       2.4191e-03, -3.0719e-02,  2.6379e-03, -1.8236e-02, -1.0989e-02,\n",
       "                       6.8651e-03, -2.5541e-02,  1.0668e-03,  1.3562e-02,  2.7688e-02,\n",
       "                      -4.1893e-03, -2.0369e-02,  1.4278e-03, -1.6329e-03,  1.6493e-03,\n",
       "                       3.1090e-02,  2.7989e-02, -2.6609e-02,  1.7394e-02, -3.0464e-02,\n",
       "                       2.9427e-02, -1.2172e-02,  2.9369e-02, -2.4388e-02, -1.8205e-03,\n",
       "                       3.1386e-02, -5.7922e-03, -2.0429e-02,  1.5852e-02,  1.9053e-02,\n",
       "                       1.3159e-02, -2.7899e-02, -2.7098e-02, -1.9863e-03,  2.2337e-02,\n",
       "                       2.9470e-02, -3.1478e-02, -2.2142e-02,  1.5359e-02,  1.9013e-02,\n",
       "                      -3.1105e-02, -1.3706e-02,  6.8292e-03, -2.9609e-02, -1.5133e-02,\n",
       "                      -2.2138e-02,  3.1956e-02,  8.9927e-03, -1.3776e-02, -1.1429e-02,\n",
       "                       1.8797e-03,  2.3618e-02,  2.8248e-02, -2.7120e-02, -2.1548e-02,\n",
       "                      -2.4311e-02, -3.0503e-02, -3.4602e-03, -1.0829e-02, -1.1353e-02,\n",
       "                       1.6568e-02,  2.8831e-02, -2.5122e-02, -2.5361e-02,  2.4371e-02,\n",
       "                       4.7961e-03, -1.5099e-03,  1.1456e-02, -1.7915e-02,  1.0539e-02,\n",
       "                       3.0096e-02, -3.1495e-02, -1.5334e-02,  1.2644e-02, -4.4995e-03,\n",
       "                      -1.4624e-02,  1.4447e-02,  1.2615e-02, -1.4157e-02, -1.3781e-02,\n",
       "                       1.5909e-04,  2.0988e-02, -3.0280e-02, -1.9680e-02,  3.1570e-02,\n",
       "                       9.6980e-03, -2.8602e-03, -4.1367e-03,  2.2129e-02, -2.2213e-02,\n",
       "                      -2.4946e-02,  2.7197e-02, -2.9558e-02, -1.3274e-02,  2.1736e-02,\n",
       "                      -1.4857e-02,  1.3084e-02, -1.5530e-02, -1.9491e-02, -2.4611e-02,\n",
       "                      -2.7090e-02,  1.3037e-02, -7.7905e-03,  1.9213e-02,  3.0231e-02,\n",
       "                      -2.2834e-02,  2.6226e-02, -8.9227e-03, -1.1244e-02, -1.8698e-02,\n",
       "                       2.8852e-02,  9.9855e-03, -1.1116e-02,  2.6679e-02,  2.2144e-02,\n",
       "                      -1.6703e-02, -1.2617e-02,  2.3021e-02,  3.1082e-02, -2.6085e-02,\n",
       "                      -3.9605e-03, -6.2378e-03, -9.4258e-03, -7.0957e-04,  3.0230e-02,\n",
       "                      -3.0500e-02, -9.9299e-03, -1.2056e-02, -1.3283e-02,  2.7376e-02,\n",
       "                      -7.7204e-03, -3.9911e-03, -2.0532e-02, -3.1720e-02,  1.8037e-02,\n",
       "                      -1.6676e-02,  2.1269e-02, -6.1519e-03, -1.5228e-02,  2.6053e-02,\n",
       "                       1.1466e-02, -1.8947e-02,  5.9236e-03,  9.8487e-03, -9.8263e-03,\n",
       "                       6.2787e-03,  2.2673e-02,  1.7035e-02, -2.5206e-02, -7.7851e-03,\n",
       "                       3.0454e-02, -1.2916e-02, -1.9997e-02, -8.6847e-03,  6.1050e-03,\n",
       "                       2.1948e-02, -1.1744e-03, -1.0739e-02, -6.9568e-03,  3.1709e-02,\n",
       "                       1.2468e-02, -1.1658e-02,  2.3548e-02,  2.9301e-02, -7.7281e-04,\n",
       "                       2.9417e-02,  2.2425e-02,  1.0215e-02,  1.4855e-02,  2.2125e-02,\n",
       "                      -2.3371e-02,  8.9236e-03, -1.5816e-02, -9.3362e-03,  5.7322e-04,\n",
       "                       2.7034e-02,  3.0776e-02, -1.7116e-02, -2.6587e-02,  7.9608e-03,\n",
       "                       2.4753e-02, -2.4896e-02,  1.3651e-02, -1.6908e-02, -2.4130e-02,\n",
       "                       2.5037e-02,  1.3443e-02, -2.8978e-02, -1.7283e-02, -1.1673e-02,\n",
       "                       2.8083e-02, -1.1542e-02, -1.4833e-03, -2.9052e-02, -2.7295e-02,\n",
       "                       2.3110e-02,  1.0450e-02,  3.0123e-02, -6.7815e-03, -2.1500e-02,\n",
       "                      -2.2419e-02,  9.9856e-03, -7.8087e-03, -1.2926e-02, -1.1969e-02,\n",
       "                      -2.1924e-02, -2.3434e-02, -2.5584e-02, -2.8615e-02,  2.6102e-02,\n",
       "                      -1.9426e-02,  1.9659e-02, -1.8177e-02,  1.0551e-02, -2.0449e-02,\n",
       "                       2.3421e-02,  7.2080e-03, -2.5321e-02,  1.4698e-02,  1.7019e-02,\n",
       "                       1.2179e-02, -8.6437e-03,  3.1890e-02, -2.9099e-02, -2.2503e-04,\n",
       "                       9.1937e-03, -3.8552e-03, -2.0230e-02, -1.4367e-02,  3.9452e-03,\n",
       "                       2.1358e-02, -7.5883e-03, -9.9738e-03, -1.4512e-02,  1.7192e-02,\n",
       "                       1.5236e-02,  1.7349e-02, -3.0076e-02, -1.6793e-03,  9.3989e-03,\n",
       "                       1.8104e-02, -3.1045e-02, -5.3801e-03, -1.8149e-02,  1.9973e-02,\n",
       "                      -2.5302e-02,  1.6348e-02,  2.9922e-03,  9.4477e-03, -2.0951e-02,\n",
       "                       1.6409e-02, -9.7668e-03,  6.9170e-03, -2.0462e-02, -5.2659e-03,\n",
       "                      -1.3689e-02, -1.8010e-02, -1.8753e-02,  3.0108e-02,  3.4757e-04,\n",
       "                      -1.2890e-02, -6.4530e-03, -6.6071e-03,  1.8061e-02, -2.8674e-02,\n",
       "                      -2.0200e-02, -2.3228e-02, -1.4111e-02,  3.4875e-03,  2.9351e-03,\n",
       "                      -1.3216e-02, -4.8730e-03,  1.6506e-02,  2.3648e-02,  2.1209e-02,\n",
       "                      -2.4450e-02,  1.5084e-02,  5.5583e-03,  7.6120e-03, -7.8328e-03,\n",
       "                       2.4268e-02, -2.2836e-02,  2.6899e-02,  4.0810e-03, -2.7336e-02,\n",
       "                      -7.5841e-04,  2.8622e-02,  1.6562e-02,  2.0152e-02, -1.3982e-02,\n",
       "                      -4.5368e-03,  1.5021e-02,  2.9048e-02,  3.1981e-03,  3.1006e-02,\n",
       "                       7.7154e-03,  2.8592e-02,  2.8859e-02,  2.4433e-02,  2.4270e-02,\n",
       "                      -1.6540e-02,  1.4955e-02,  2.6522e-02, -2.6132e-02,  8.8409e-03,\n",
       "                      -1.1661e-02, -9.5988e-03,  1.7311e-02,  1.9166e-02, -9.3947e-03,\n",
       "                      -2.7058e-02, -2.1985e-03,  1.9629e-02,  2.6957e-03,  1.6049e-02,\n",
       "                      -8.3001e-03, -3.1340e-02, -1.9615e-02, -1.0978e-02,  3.2070e-02,\n",
       "                       9.1095e-03])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[-0.0304,  0.0415,  0.0157,  ..., -0.0342, -0.0228,  0.0036],\n",
       "                      [-0.0152, -0.0333, -0.0356,  ..., -0.0295,  0.0360, -0.0384],\n",
       "                      [ 0.0233, -0.0369,  0.0402,  ..., -0.0444, -0.0033, -0.0380],\n",
       "                      ...,\n",
       "                      [ 0.0373,  0.0138,  0.0362,  ..., -0.0038, -0.0109,  0.0054],\n",
       "                      [-0.0343,  0.0296, -0.0101,  ...,  0.0425, -0.0349,  0.0295],\n",
       "                      [ 0.0288, -0.0433, -0.0060,  ...,  0.0357, -0.0164,  0.0120]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.0256,  0.0368,  0.0287, -0.0315, -0.0160, -0.0227,  0.0222, -0.0010,\n",
       "                      -0.0452, -0.0292, -0.0139, -0.0279, -0.0442, -0.0387, -0.0429, -0.0030,\n",
       "                       0.0061, -0.0410, -0.0274,  0.0172,  0.0234, -0.0248, -0.0228,  0.0346,\n",
       "                       0.0013,  0.0381,  0.0243,  0.0260, -0.0441, -0.0149,  0.0145, -0.0137,\n",
       "                       0.0237, -0.0216, -0.0127,  0.0221,  0.0372,  0.0238, -0.0002, -0.0174,\n",
       "                      -0.0430,  0.0370,  0.0210,  0.0124, -0.0198, -0.0267,  0.0021,  0.0438,\n",
       "                       0.0266, -0.0315, -0.0165, -0.0149, -0.0120, -0.0301,  0.0421,  0.0431,\n",
       "                       0.0139, -0.0243,  0.0448, -0.0195,  0.0349,  0.0093, -0.0442,  0.0244,\n",
       "                      -0.0267,  0.0343, -0.0266,  0.0343,  0.0307,  0.0079, -0.0243, -0.0211,\n",
       "                       0.0017,  0.0236,  0.0274,  0.0052,  0.0014,  0.0411,  0.0392,  0.0324,\n",
       "                      -0.0138,  0.0008,  0.0219,  0.0361,  0.0244, -0.0337, -0.0276,  0.0343,\n",
       "                       0.0425,  0.0247,  0.0109, -0.0295, -0.0259,  0.0422,  0.0453, -0.0278,\n",
       "                      -0.0413,  0.0370, -0.0292, -0.0329, -0.0316,  0.0049,  0.0307,  0.0130,\n",
       "                       0.0086,  0.0436,  0.0318, -0.0348, -0.0375, -0.0312, -0.0037,  0.0281,\n",
       "                      -0.0040, -0.0004,  0.0233, -0.0265,  0.0359,  0.0098,  0.0112,  0.0336,\n",
       "                       0.0176,  0.0274,  0.0010, -0.0349,  0.0112,  0.0346, -0.0401,  0.0271,\n",
       "                       0.0154,  0.0392, -0.0420,  0.0254, -0.0203, -0.0146,  0.0130,  0.0302,\n",
       "                      -0.0366, -0.0226,  0.0330,  0.0021, -0.0248,  0.0297,  0.0310,  0.0182,\n",
       "                      -0.0066, -0.0441,  0.0138, -0.0373,  0.0131,  0.0438,  0.0295,  0.0452,\n",
       "                       0.0138, -0.0036, -0.0270,  0.0264, -0.0093,  0.0122,  0.0177,  0.0315])),\n",
       "             ('fc4.weight',\n",
       "              tensor([[ 0.0183,  0.0446, -0.0486,  ...,  0.0344,  0.0746, -0.0302],\n",
       "                      [ 0.0766, -0.0124, -0.0570,  ...,  0.0619, -0.0703, -0.0577],\n",
       "                      [-0.0530,  0.0009, -0.0441,  ...,  0.0786,  0.0532, -0.0427],\n",
       "                      ...,\n",
       "                      [-0.0044,  0.0267, -0.0788,  ..., -0.0030,  0.0681,  0.0281],\n",
       "                      [-0.0051, -0.0262, -0.0698,  ...,  0.0475,  0.0436,  0.0286],\n",
       "                      [-0.0644, -0.0203,  0.0619,  ..., -0.0418,  0.0654, -0.0027]])),\n",
       "             ('fc4.bias',\n",
       "              tensor([-0.0130,  0.0455, -0.0101,  0.0458, -0.0249, -0.0272,  0.0715,  0.0528,\n",
       "                       0.0088,  0.0048, -0.0450, -0.0272, -0.0532,  0.0597, -0.0282, -0.0398,\n",
       "                       0.0480,  0.0043, -0.0500, -0.0044,  0.0442,  0.0005, -0.0193,  0.0720,\n",
       "                       0.0053,  0.0662, -0.0723, -0.0123,  0.0297, -0.0365,  0.0285,  0.0675,\n",
       "                       0.0762,  0.0587, -0.0364,  0.0499, -0.0334,  0.0771,  0.0529,  0.0293])),\n",
       "             ('fc5.weight',\n",
       "              tensor([[-0.0432, -0.1233, -0.0949, -0.1196, -0.1066,  0.1454, -0.0675,  0.0277,\n",
       "                       -0.0088, -0.0779,  0.0656, -0.0321,  0.1329, -0.0818,  0.1515, -0.0075,\n",
       "                        0.1256,  0.0616,  0.0030, -0.1436, -0.0288, -0.0437,  0.0579, -0.1514,\n",
       "                       -0.0092,  0.0703, -0.0430,  0.1276, -0.0680, -0.1427, -0.1429, -0.0432,\n",
       "                       -0.0622,  0.1458, -0.0553,  0.0572, -0.0359, -0.0329, -0.1319, -0.0499],\n",
       "                      [-0.0970,  0.1110, -0.0202,  0.0857,  0.1537, -0.0275,  0.1271,  0.1184,\n",
       "                       -0.0946, -0.0677,  0.1260,  0.0581, -0.0948,  0.0037,  0.0717, -0.1395,\n",
       "                        0.1370,  0.1355, -0.0257, -0.1038,  0.0471, -0.0902, -0.0593,  0.0798,\n",
       "                        0.0149, -0.1121,  0.1520,  0.0060,  0.1451, -0.0419,  0.0784,  0.0252,\n",
       "                       -0.0674, -0.0304, -0.1041,  0.0324,  0.0494,  0.0268,  0.0351, -0.1085],\n",
       "                      [ 0.0123, -0.1103, -0.0014, -0.0174,  0.1336,  0.0623, -0.0594,  0.0206,\n",
       "                       -0.1227,  0.0196,  0.0068,  0.0686, -0.1237,  0.0706, -0.1099,  0.1297,\n",
       "                        0.0401, -0.0062,  0.0027, -0.0373, -0.0628,  0.0289,  0.0867,  0.1522,\n",
       "                       -0.0640, -0.0490, -0.1063,  0.1498, -0.1477, -0.1252, -0.0051, -0.0596,\n",
       "                        0.0687, -0.0383, -0.0080,  0.0320, -0.1476, -0.1415,  0.0064,  0.0218]])),\n",
       "             ('fc5.bias', tensor([-0.0948, -0.0788,  0.0620]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that the values are not 0? This is actually by design - by default that initialization follows an accepted scheme - but many strategies are possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleMLP import SimpleMLPSEQ\n",
    "model_MLPSEQ=SimpleMLPSEQ(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: _sequence.0.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.0.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.6.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.6.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.8.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.8.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLPSEQ.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('_sequence.0.weight', tensor([[ 0.0007,  0.0022, -0.0023,  ...,  0.0011,  0.0040, -0.0008],\n",
      "        [ 0.0008, -0.0016,  0.0020,  ...,  0.0022,  0.0058, -0.0043],\n",
      "        [ 0.0035,  0.0054, -0.0012,  ..., -0.0015,  0.0007, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0025, -0.0034, -0.0004,  ...,  0.0044, -0.0026,  0.0014],\n",
      "        [ 0.0043,  0.0039, -0.0034,  ...,  0.0006, -0.0014, -0.0049],\n",
      "        [-0.0050, -0.0038,  0.0033,  ...,  0.0053, -0.0047, -0.0051]])), ('_sequence.0.bias', tensor([-1.8141e-03, -2.7412e-03, -4.8666e-03, -4.4414e-03,  1.7997e-03,\n",
      "        -2.5045e-03,  4.3096e-03,  4.3308e-03,  8.8577e-04, -2.5449e-03,\n",
      "         2.6009e-03,  1.7342e-03, -2.5921e-03,  4.4904e-03,  3.4002e-03,\n",
      "         1.3574e-03, -1.4386e-03,  2.6128e-03, -3.1699e-03,  4.9712e-03,\n",
      "        -5.5630e-03,  1.3042e-03, -3.2158e-03, -3.0635e-03,  5.7648e-03,\n",
      "         3.9290e-03, -2.1759e-03, -1.0880e-03, -5.4842e-03,  6.5068e-04,\n",
      "         2.4297e-03,  5.9228e-03,  2.1371e-03, -1.2185e-03, -6.2811e-03,\n",
      "        -4.4198e-03,  5.4224e-03, -3.7624e-03,  2.9330e-03,  5.6819e-03,\n",
      "        -4.1720e-03,  1.5852e-03,  3.8139e-03, -2.1180e-03,  5.5780e-03,\n",
      "         3.4868e-03,  1.9847e-03,  3.7275e-03,  4.6206e-03,  2.1864e-03,\n",
      "         5.4690e-03,  2.5554e-03, -2.2290e-03,  5.6783e-03,  5.3662e-03,\n",
      "        -3.3721e-03, -5.1802e-03, -3.9968e-04,  3.8583e-03, -4.2151e-03,\n",
      "         1.2809e-03, -7.6590e-04, -5.2250e-03, -6.0428e-03,  3.3703e-03,\n",
      "        -4.9667e-03,  1.4635e-04, -3.9216e-03,  7.9216e-04, -5.5408e-03,\n",
      "        -6.3490e-03, -3.3074e-03, -3.5558e-04, -6.2410e-03,  1.2253e-03,\n",
      "        -5.8157e-03, -4.5465e-03, -2.2770e-03,  4.6065e-03, -5.8778e-03,\n",
      "         3.8976e-03, -9.1568e-04,  2.1680e-03, -8.1703e-04,  3.7888e-03,\n",
      "        -2.9006e-03, -4.1862e-03, -9.7959e-04,  3.6448e-03,  4.6050e-03,\n",
      "         5.1169e-03, -3.9833e-03, -5.9400e-03, -1.3618e-03,  2.6782e-03,\n",
      "         1.5755e-03,  3.9846e-03, -1.7087e-03, -5.9528e-03, -8.0334e-04,\n",
      "        -1.1969e-03,  1.7377e-03, -2.0768e-03,  5.3768e-03,  9.4963e-04,\n",
      "         5.2298e-03, -5.2014e-04, -5.6795e-03,  3.8341e-03,  2.5046e-03,\n",
      "         4.5558e-03, -4.8226e-03,  5.9352e-03,  6.1208e-03,  2.3563e-03,\n",
      "        -2.1375e-03, -4.6691e-03, -4.8898e-03,  5.0526e-03, -1.2860e-03,\n",
      "        -2.1371e-03, -2.4970e-03,  3.8950e-03, -5.2487e-03, -4.0619e-03,\n",
      "        -4.6586e-04, -3.4843e-03,  2.9294e-03,  2.6534e-03, -2.6253e-03,\n",
      "         5.8201e-03,  8.7678e-04,  3.3299e-03,  1.6324e-03, -5.2112e-03,\n",
      "         4.3368e-03, -6.0499e-03,  2.9478e-03,  4.1369e-03, -7.4325e-04,\n",
      "         4.3709e-03, -1.2433e-04,  4.1236e-03,  2.1416e-03,  3.2076e-03,\n",
      "        -2.7500e-03,  2.8244e-03,  3.3295e-03,  2.6540e-03,  2.7906e-03,\n",
      "         4.2608e-03, -4.6947e-03,  6.3550e-04,  4.9754e-03, -2.5470e-04,\n",
      "         1.6350e-03, -5.7345e-03,  1.0778e-03,  6.3720e-03,  4.7022e-03,\n",
      "        -3.0754e-03,  1.1184e-03, -3.6401e-03,  4.4711e-03,  4.8043e-03,\n",
      "        -5.4769e-03, -3.0745e-03,  1.0085e-03,  2.0722e-03, -9.6597e-04,\n",
      "        -5.7217e-03,  6.0896e-03, -2.0031e-03, -4.4651e-03, -1.6356e-03,\n",
      "        -4.5878e-03,  2.9934e-03, -5.8875e-03,  1.4724e-03, -1.7049e-04,\n",
      "         3.9008e-03, -1.4984e-03, -1.5309e-03,  1.7525e-03,  4.3009e-03,\n",
      "        -6.2829e-03,  6.2882e-03,  1.7316e-03, -1.6988e-03, -3.6369e-03,\n",
      "        -1.1431e-04, -1.2636e-03, -2.1833e-03, -5.8368e-03, -1.6241e-03,\n",
      "        -6.1757e-06, -2.9837e-03, -2.5329e-03, -4.9042e-03,  1.6978e-03,\n",
      "        -4.9631e-03,  3.3400e-03,  4.9908e-03, -3.5971e-03,  3.1055e-03,\n",
      "         3.3405e-03,  2.1546e-03, -4.9199e-03,  4.3334e-03, -3.7868e-03,\n",
      "        -2.6423e-03,  2.1156e-03,  6.1074e-03, -1.3306e-03, -3.0407e-03,\n",
      "         1.6656e-03,  8.7291e-04, -4.7740e-03,  4.6606e-03, -3.8829e-03,\n",
      "        -1.2746e-03, -4.8527e-03, -1.3235e-03,  4.1186e-03, -2.3544e-03,\n",
      "         4.1126e-03,  1.5689e-03, -3.1190e-03, -7.3219e-04,  3.8541e-03,\n",
      "        -3.9460e-03, -1.6408e-04,  3.6943e-03, -2.4863e-03,  1.9165e-03,\n",
      "        -1.5364e-03,  4.5175e-03,  4.4844e-03, -4.9846e-03, -6.4748e-04,\n",
      "         1.4311e-03,  6.0326e-03, -3.9438e-03, -8.9294e-04,  3.0138e-03,\n",
      "        -2.8143e-03,  6.3646e-03,  4.5198e-05,  5.6097e-03, -3.7144e-03,\n",
      "        -5.9112e-04,  2.4283e-03, -2.4213e-03, -5.6189e-03, -4.0719e-03,\n",
      "         5.7823e-03,  2.4587e-03,  5.2072e-03,  4.3562e-03,  3.9208e-03,\n",
      "        -1.7759e-03, -6.0888e-03,  4.8467e-03,  4.8489e-03, -5.1863e-03,\n",
      "         4.1555e-03, -3.4599e-03,  3.8829e-03, -5.9375e-03, -2.9167e-03,\n",
      "         3.3406e-04,  6.3592e-03,  1.6285e-03,  6.2218e-03,  4.0676e-03,\n",
      "        -6.2494e-03, -1.6620e-03, -2.9176e-03, -5.1501e-03,  3.6420e-03,\n",
      "        -6.1460e-03, -5.4514e-03,  4.0227e-03,  4.4871e-03,  4.4296e-04,\n",
      "         1.0780e-03,  1.1951e-03,  2.1639e-03, -5.2170e-03, -6.1675e-03,\n",
      "         3.3071e-03, -3.2773e-03,  1.6741e-03,  2.5568e-03, -3.3469e-03,\n",
      "        -3.7463e-03,  3.2181e-03,  5.8303e-03,  6.3209e-03,  4.6386e-03,\n",
      "        -2.6007e-04, -2.3819e-03,  5.4540e-03, -3.8649e-03, -1.7983e-03,\n",
      "        -4.1969e-03,  3.4271e-03,  5.3439e-03, -2.6490e-03,  3.1953e-03,\n",
      "        -6.0191e-03, -2.2631e-04, -5.7550e-03,  2.6499e-03, -2.8560e-03,\n",
      "         3.0616e-03,  4.7353e-03, -2.2114e-04, -2.1329e-03, -3.0948e-03,\n",
      "         3.0713e-03,  6.3943e-04, -5.7276e-03,  3.2734e-03, -1.6387e-03,\n",
      "        -2.5981e-03, -5.0642e-03, -4.6892e-04,  4.9271e-03, -2.8911e-03,\n",
      "         4.8962e-03, -2.3614e-03,  1.1039e-03, -4.5349e-03,  3.4534e-03,\n",
      "        -2.9559e-04, -2.1363e-03, -4.8480e-03, -5.0643e-03,  2.9254e-03,\n",
      "         5.6564e-05,  3.0965e-03, -3.2343e-04, -3.8142e-03,  3.0573e-03,\n",
      "        -6.3381e-03, -4.8894e-04,  3.2660e-03,  1.0901e-03,  4.6298e-05,\n",
      "        -1.4605e-03,  1.1274e-03, -5.0822e-03, -5.1757e-03, -3.9702e-03,\n",
      "        -4.3390e-04,  4.8369e-03,  5.9941e-03, -1.8130e-03,  9.5011e-04,\n",
      "         5.8894e-03, -3.8100e-03, -4.9497e-03,  8.0800e-04,  4.5984e-04,\n",
      "        -3.3521e-03,  5.2900e-03, -2.4823e-03, -1.4194e-03, -4.3553e-03,\n",
      "         4.6026e-03, -1.9911e-03,  4.0049e-04,  5.4049e-03,  5.4574e-03,\n",
      "        -2.5007e-03, -2.9150e-03,  1.6989e-03, -6.2884e-03, -1.8368e-03,\n",
      "         4.0161e-03,  4.4357e-03, -1.5131e-03, -3.8725e-03,  9.6068e-04,\n",
      "         2.5137e-03, -2.7629e-03, -1.6452e-03,  1.6308e-03, -5.4272e-04,\n",
      "         5.0062e-03,  3.6891e-03, -1.7736e-03,  2.7851e-03, -1.4391e-04,\n",
      "         8.6655e-04, -9.2181e-04,  3.8607e-05,  1.1498e-03,  1.0613e-03,\n",
      "         3.0668e-03, -3.5153e-03,  4.0404e-03,  5.8453e-04, -4.3354e-03,\n",
      "         1.9863e-03, -7.0913e-05,  1.7202e-03,  2.8561e-03,  1.8467e-03,\n",
      "        -2.0880e-03,  2.1341e-03, -2.9420e-03,  4.8725e-03,  6.2928e-03,\n",
      "        -4.0388e-04,  2.6317e-03, -6.3293e-03, -2.2626e-03,  1.3975e-03,\n",
      "         1.5868e-03,  2.7580e-03, -1.0082e-03,  5.9864e-03,  1.8332e-04,\n",
      "         4.2876e-03,  4.9698e-03,  3.0635e-03, -7.3873e-04, -3.1797e-03,\n",
      "        -4.4659e-03, -5.0263e-03,  4.1000e-03, -6.2714e-04,  2.3407e-03,\n",
      "        -2.9554e-03, -2.7085e-03, -3.3962e-03, -8.4452e-05, -4.4697e-03,\n",
      "         1.6889e-03, -4.5393e-03, -7.0387e-04, -4.6980e-03,  6.1352e-03,\n",
      "         1.1938e-03,  1.8913e-03, -4.9819e-03,  5.4919e-03,  5.0738e-03,\n",
      "         4.0974e-03, -4.1720e-03,  1.4548e-03,  2.4687e-03,  5.4915e-03,\n",
      "        -7.5462e-04, -1.3177e-03, -1.9503e-03, -3.3822e-03, -7.9766e-04,\n",
      "         1.8846e-03, -2.5590e-03,  7.8820e-04, -2.0855e-03, -1.5894e-03,\n",
      "         2.7614e-03,  2.9460e-03,  4.9095e-03,  3.5865e-03,  3.0867e-03,\n",
      "         5.1293e-03,  5.5537e-03, -1.5106e-03, -1.3684e-04,  3.3297e-03,\n",
      "        -1.9975e-03,  3.3440e-03,  2.6495e-03,  2.9053e-03, -5.2381e-03,\n",
      "        -6.2210e-03, -4.7652e-03, -1.2454e-03, -5.4940e-03, -3.3145e-03,\n",
      "         3.1240e-03,  4.7447e-03,  4.7371e-03,  4.7592e-03, -4.5771e-03,\n",
      "         1.2909e-04,  2.7686e-03,  1.5389e-03, -5.7069e-03, -5.0642e-03,\n",
      "         2.8106e-03,  5.2161e-03, -5.0104e-03, -2.2332e-03, -5.6142e-03,\n",
      "        -3.5636e-03, -4.4762e-03,  5.7600e-03,  2.9858e-03, -5.5276e-03,\n",
      "        -1.3960e-03,  3.8046e-03, -4.3848e-03,  2.8625e-03, -5.5060e-04,\n",
      "        -1.2095e-03,  4.7840e-03, -1.7476e-03, -5.2697e-03,  4.6289e-03,\n",
      "        -7.5183e-04,  1.5585e-03, -4.7389e-03, -2.2416e-03, -4.9562e-03,\n",
      "        -4.2176e-03,  1.8432e-03, -1.2830e-03, -5.9171e-03, -5.7927e-03,\n",
      "        -1.6406e-03, -5.4425e-03, -4.5201e-03, -2.5353e-03, -1.7301e-03,\n",
      "        -5.3901e-03,  2.2715e-03, -4.1215e-03, -5.4291e-03, -5.6480e-03,\n",
      "        -5.7093e-03, -2.7399e-03, -9.3153e-04,  3.0728e-03, -1.3579e-03,\n",
      "         6.0206e-04, -5.4511e-04,  1.6800e-03, -6.1061e-03, -1.4640e-03,\n",
      "        -1.6745e-03,  4.4344e-03,  5.9119e-03,  3.4286e-03,  4.2951e-03,\n",
      "        -2.5450e-03, -2.7087e-03, -4.6584e-03,  6.0297e-03, -2.3054e-03,\n",
      "        -5.6210e-04, -2.7736e-03, -1.6352e-05, -2.7138e-03,  1.5929e-03,\n",
      "        -3.7383e-03,  2.2490e-03,  3.6159e-03,  3.5051e-03,  2.5830e-03,\n",
      "         2.7972e-03,  4.7903e-03, -1.1790e-03, -2.0609e-03, -5.9959e-03,\n",
      "         5.0941e-04,  3.5426e-03,  6.8864e-04,  3.6583e-03, -3.2552e-03,\n",
      "        -3.8958e-03, -6.1526e-03,  3.8655e-03, -2.5632e-03, -3.1995e-03,\n",
      "        -1.0041e-03, -3.9373e-03,  4.7707e-04,  4.6572e-03,  9.3312e-04,\n",
      "         1.9744e-03, -3.0863e-03,  4.9828e-03, -5.2594e-03,  4.0513e-03,\n",
      "         6.1310e-03, -1.4082e-03,  5.7356e-03,  2.7239e-03,  6.5782e-04,\n",
      "         4.7395e-03, -1.9184e-03,  1.9745e-03,  5.4311e-03,  1.4294e-04,\n",
      "        -5.2742e-03,  1.9461e-03, -4.7605e-03, -4.6070e-03, -3.2271e-03,\n",
      "         1.9052e-03, -2.2236e-03,  1.4459e-03,  5.1186e-03,  1.9790e-03,\n",
      "         1.6405e-03, -5.5859e-03, -3.2535e-04, -6.2364e-03, -3.5961e-04,\n",
      "        -6.3391e-03, -5.0026e-03, -5.7885e-03, -1.3609e-03,  5.6480e-03,\n",
      "         2.5543e-03, -4.2178e-03, -3.4939e-03, -5.8119e-03, -3.5663e-05,\n",
      "         3.7050e-03, -5.4017e-04, -4.7402e-03, -1.6347e-03,  1.0366e-03,\n",
      "         4.4780e-03,  4.2227e-03,  3.3273e-03,  4.3628e-03,  5.3448e-03,\n",
      "        -1.8837e-03, -4.7223e-03, -4.2842e-03, -1.0520e-03,  5.1400e-03,\n",
      "        -1.2182e-04, -5.2210e-03,  3.1746e-03,  1.6500e-03, -5.9100e-03,\n",
      "        -4.0647e-04,  1.2157e-03,  5.0040e-03, -2.6577e-04,  1.6200e-03,\n",
      "        -2.5233e-03, -1.8906e-03,  4.6965e-03,  3.3961e-03,  2.2580e-03,\n",
      "         2.5073e-03,  3.5700e-03,  5.5502e-03, -2.8512e-03, -4.6080e-04,\n",
      "         2.0912e-03,  4.8360e-03, -7.7291e-04, -2.2198e-03,  3.2962e-03,\n",
      "         5.7632e-03,  5.1138e-03, -5.0366e-03, -5.7629e-03, -6.2470e-03,\n",
      "         2.6210e-03,  1.5759e-03, -3.1157e-03, -3.9009e-04, -4.3915e-03,\n",
      "         3.4387e-03,  6.7555e-04, -2.9664e-03, -3.5402e-03, -2.6390e-03,\n",
      "         2.6032e-03,  3.5855e-03, -4.6968e-03, -6.3477e-03,  1.4156e-03,\n",
      "        -2.7136e-04, -2.1002e-03, -2.9826e-03,  2.5525e-03, -5.0043e-03,\n",
      "        -4.1929e-03,  1.5814e-03, -2.2935e-03,  5.0976e-03,  1.6503e-03,\n",
      "         4.1516e-03, -1.1344e-03,  5.7715e-03,  5.0764e-03,  9.0401e-04,\n",
      "        -1.0695e-03,  5.0107e-03,  6.0856e-03,  1.7879e-03,  1.6673e-03,\n",
      "        -8.8086e-04,  3.8021e-03,  1.0949e-03,  5.3764e-03,  1.4957e-03,\n",
      "         2.8929e-03,  4.6504e-03, -4.6247e-04,  1.0282e-03,  2.1264e-03,\n",
      "         3.3018e-04,  5.8737e-03,  1.3739e-03, -4.7328e-03,  4.7680e-03,\n",
      "        -3.9910e-03,  2.4487e-03, -5.6834e-03,  5.9112e-03,  5.2620e-03,\n",
      "        -5.0977e-03,  3.1061e-03, -5.7211e-03,  1.3351e-03,  1.7192e-03,\n",
      "        -1.5802e-03,  6.2443e-03,  1.9759e-03, -6.0659e-03,  2.7598e-03,\n",
      "        -1.1622e-03, -1.4488e-03, -2.5074e-03, -2.0358e-03, -5.6983e-03,\n",
      "         8.0559e-04,  3.8353e-05,  3.1802e-03, -9.4575e-04, -4.2672e-03,\n",
      "        -1.4908e-03,  3.5101e-03, -2.2716e-03,  1.2898e-03, -4.7019e-03,\n",
      "        -3.1583e-03, -1.7300e-03, -2.1217e-03, -8.3096e-04, -5.4429e-03,\n",
      "        -1.4591e-03, -4.2613e-04, -3.2383e-03,  6.5251e-04, -1.5189e-03,\n",
      "        -4.1145e-03, -8.0480e-04, -1.6467e-03,  3.4937e-03, -3.3760e-03,\n",
      "         5.8833e-03,  1.0795e-03,  4.4155e-03,  5.9880e-03,  3.7794e-03,\n",
      "        -5.6372e-03, -3.3370e-03, -4.2707e-03,  4.1577e-03, -5.1152e-03,\n",
      "         6.2184e-03,  4.9935e-03, -2.8989e-03,  5.8415e-03,  1.6392e-03,\n",
      "        -3.8244e-03,  4.1626e-04,  6.5143e-04,  1.6253e-03,  4.3958e-03,\n",
      "         1.1496e-03, -4.9786e-03, -4.9549e-03, -5.3875e-03,  2.4245e-03,\n",
      "        -1.4566e-03, -6.3471e-03, -6.0851e-03, -5.8181e-03, -4.1075e-03,\n",
      "        -9.8864e-04,  1.4704e-03, -9.7247e-04, -5.2988e-04, -3.3605e-03,\n",
      "         2.8000e-03,  5.8741e-03,  3.3256e-03, -4.4766e-03,  3.8784e-03,\n",
      "        -1.9964e-03, -4.3892e-03, -7.5509e-04, -2.7171e-03,  2.1077e-03,\n",
      "         2.2959e-03, -5.9289e-04,  3.1885e-03, -2.9116e-03,  6.0160e-03,\n",
      "        -1.2998e-03, -5.5237e-03,  2.5304e-03, -3.4729e-03,  1.2645e-03,\n",
      "        -3.3179e-03, -1.8127e-03, -5.4574e-03,  4.8727e-03, -5.2980e-03,\n",
      "        -1.7814e-03,  3.1884e-03,  4.2113e-03,  4.4559e-05,  6.2185e-03,\n",
      "         3.2472e-03, -1.8078e-03,  3.3901e-03,  4.5712e-03, -3.9886e-03,\n",
      "        -1.6609e-03, -9.7055e-04, -3.6548e-03,  5.5857e-03,  2.8850e-03,\n",
      "        -2.2156e-03,  5.7390e-03,  4.6448e-03,  4.1285e-03,  8.3086e-04,\n",
      "         2.6183e-03,  4.0609e-03, -2.0299e-04, -1.8212e-03,  8.1935e-04,\n",
      "         1.7313e-03,  2.4926e-03, -6.1497e-03,  2.4252e-03,  3.8546e-03,\n",
      "         3.0838e-03, -9.5487e-04,  3.8170e-03, -5.7236e-03, -1.0592e-03,\n",
      "        -5.1614e-03,  7.0032e-04, -9.6600e-04, -3.3107e-03,  3.5997e-03,\n",
      "         5.4114e-03,  6.2165e-03,  5.2326e-03,  8.7036e-04,  1.3021e-03,\n",
      "        -3.1327e-03,  4.3314e-03,  1.7069e-03,  5.0277e-03, -4.2237e-03,\n",
      "         4.3833e-03, -1.7396e-03,  1.2077e-03, -2.7513e-03, -1.7762e-03,\n",
      "        -5.1404e-03,  6.3461e-03,  5.5201e-03,  2.4672e-03, -5.7361e-03,\n",
      "         4.6239e-03, -5.2547e-03,  3.9517e-03,  2.9480e-03, -7.0687e-04,\n",
      "        -2.4774e-03,  6.1575e-03,  6.1631e-03,  1.3099e-03, -4.1922e-03,\n",
      "        -2.3582e-03, -5.2356e-03,  2.2810e-03,  5.8455e-03,  3.5361e-03,\n",
      "        -3.7512e-03, -3.9366e-04,  1.2714e-04, -1.0395e-03, -2.3159e-03,\n",
      "         1.6803e-03,  5.3793e-03, -5.8176e-03, -3.6893e-03,  6.3798e-03,\n",
      "        -6.4526e-04, -7.5645e-04,  6.3390e-03, -5.7957e-04, -2.2872e-03,\n",
      "         3.5988e-03, -5.8135e-04, -5.9316e-03,  2.7610e-03,  5.8697e-03,\n",
      "         3.4510e-03,  3.6135e-03,  1.9201e-03,  5.6272e-03, -1.6527e-04,\n",
      "        -5.9558e-03,  3.8764e-03, -5.0476e-03, -9.0881e-05, -6.2752e-04,\n",
      "         3.4165e-03, -4.0084e-03, -2.5585e-03,  2.4057e-03, -7.7962e-05,\n",
      "        -2.5168e-03, -9.5373e-04,  4.4076e-03,  5.1997e-04,  1.9134e-03,\n",
      "         9.2927e-04,  2.1165e-03,  9.9705e-04,  2.8091e-03, -1.2129e-04,\n",
      "        -5.1481e-03,  4.8521e-03,  1.3930e-03, -4.4690e-03, -2.1765e-04,\n",
      "         6.0618e-03,  9.3669e-04, -3.4617e-03,  3.9907e-05,  9.8247e-04,\n",
      "        -2.9866e-03,  4.0599e-03, -4.5096e-03,  2.3963e-03, -4.1122e-03,\n",
      "        -2.7870e-03, -5.9712e-04, -1.5097e-03, -5.1628e-03,  5.0520e-03,\n",
      "        -3.7471e-03, -3.4969e-03,  5.5890e-03,  4.9606e-05, -2.1509e-03,\n",
      "         5.2677e-03, -3.0360e-03])), ('_sequence.2.weight', tensor([[-1.4742e-02, -2.5296e-03, -1.6806e-02,  ...,  1.1105e-03,\n",
      "         -3.0569e-02, -2.7946e-02],\n",
      "        [-5.9584e-04, -1.0623e-02, -1.4914e-02,  ...,  1.4457e-02,\n",
      "          1.9885e-02, -2.9413e-02],\n",
      "        [ 2.7911e-02,  1.7106e-02, -2.9314e-02,  ..., -2.2986e-02,\n",
      "          9.6569e-04, -1.0410e-02],\n",
      "        ...,\n",
      "        [-2.4329e-02, -6.1216e-04, -3.9752e-03,  ..., -1.3406e-02,\n",
      "          1.2888e-02,  2.2370e-02],\n",
      "        [-5.0024e-03, -1.5429e-02, -3.4280e-03,  ..., -2.0039e-02,\n",
      "         -7.7516e-03,  1.5484e-02],\n",
      "        [-5.0264e-03,  3.1975e-02, -2.9227e-03,  ..., -2.2992e-02,\n",
      "          6.3075e-05,  1.2668e-02]])), ('_sequence.2.bias', tensor([ 2.0362e-02, -2.1918e-02, -6.9882e-04, -1.9309e-02,  2.5123e-02,\n",
      "         1.1030e-03, -9.6879e-03, -6.7368e-03,  5.8691e-03,  2.2570e-03,\n",
      "        -1.2504e-02,  1.5297e-02, -1.6296e-02, -6.7769e-03,  2.8396e-02,\n",
      "         2.1733e-02,  1.0252e-02, -1.6495e-02,  1.4696e-02, -1.5462e-02,\n",
      "        -8.2260e-03,  5.0656e-03, -5.7997e-03, -1.3107e-02, -2.6654e-02,\n",
      "        -1.8209e-02,  1.4985e-02, -2.9042e-02, -2.8990e-02, -1.8716e-02,\n",
      "         8.5047e-03, -4.9341e-03,  1.3933e-02,  4.9897e-03, -5.3312e-03,\n",
      "        -3.2014e-02,  7.8631e-03,  1.8271e-02, -2.7074e-02, -2.3473e-02,\n",
      "         3.1116e-02,  1.9747e-02, -2.7144e-02, -3.7132e-03,  2.1752e-02,\n",
      "         5.8007e-03, -1.9249e-02, -1.9253e-02,  3.0420e-02,  2.0336e-02,\n",
      "        -1.9028e-02, -7.6620e-03,  8.6263e-03, -1.8357e-02, -2.9296e-02,\n",
      "        -4.2874e-03,  2.1756e-02,  2.0522e-02,  1.7036e-02,  2.7630e-02,\n",
      "         2.7785e-02, -1.9889e-02,  1.0151e-02,  2.8135e-02,  1.5799e-02,\n",
      "         1.4037e-02,  2.9556e-03, -4.2771e-03, -5.3256e-03,  1.5508e-02,\n",
      "         2.9033e-02, -2.6518e-02,  2.8921e-02, -1.0050e-02,  3.0881e-02,\n",
      "         1.5049e-02,  1.9537e-02, -4.0311e-04, -3.7649e-03, -7.4371e-03,\n",
      "        -2.5397e-02, -2.5706e-02, -3.8601e-03, -3.0918e-02,  2.9680e-02,\n",
      "        -1.5637e-02, -2.0480e-02, -1.5395e-03,  2.6651e-02, -1.8446e-02,\n",
      "        -3.1166e-02, -2.3397e-02, -3.1534e-02, -1.7728e-04, -1.5611e-03,\n",
      "        -2.4610e-02, -3.1012e-02,  2.3340e-02, -3.0365e-02, -1.4555e-02,\n",
      "        -2.5186e-02,  2.2512e-02, -5.4301e-04, -2.8145e-02, -2.0340e-02,\n",
      "        -2.3395e-02,  2.2101e-02, -1.1633e-02,  2.7943e-02,  2.5970e-02,\n",
      "         7.0180e-03, -2.4388e-04,  1.7138e-03, -3.1201e-03,  1.1807e-02,\n",
      "         7.5782e-03, -9.0348e-03, -2.5846e-02,  7.8042e-03,  1.8277e-02,\n",
      "         2.3142e-02,  4.8678e-03,  1.6704e-02,  3.2542e-03,  1.1216e-03,\n",
      "         3.1564e-02,  3.5014e-03, -5.3630e-03,  2.2231e-02, -1.8394e-02,\n",
      "         1.7512e-02,  1.6982e-02,  1.4642e-02,  2.6128e-02, -2.6456e-02,\n",
      "        -4.3633e-03, -2.0100e-02, -1.2858e-02,  1.2340e-02,  1.3944e-02,\n",
      "         3.1411e-02,  1.5504e-02,  1.3831e-02, -2.7047e-02,  6.7952e-03,\n",
      "         1.9369e-02,  1.3992e-02,  2.9897e-02, -3.0815e-02,  7.6654e-03,\n",
      "         2.5770e-02,  1.5396e-02,  1.6827e-02,  2.1059e-02,  6.7733e-03,\n",
      "         2.6164e-02,  9.8116e-03, -2.8512e-02,  1.7619e-02, -2.0140e-02,\n",
      "         2.8121e-03, -1.2070e-02,  1.7081e-02, -1.5877e-02,  6.8614e-03,\n",
      "        -6.8892e-03,  6.7204e-05,  3.1736e-02,  1.0886e-02, -1.1275e-02,\n",
      "         2.7393e-02,  2.6235e-02,  1.4644e-02, -1.0906e-02,  2.4166e-02,\n",
      "        -7.0988e-03,  1.5359e-02, -2.1960e-03, -2.4978e-02, -2.7574e-02,\n",
      "        -4.7841e-03, -7.1122e-03,  2.8617e-02, -5.9867e-03,  2.4071e-02,\n",
      "        -2.8655e-02,  1.2161e-02,  2.7870e-02, -2.3145e-02,  3.0167e-02,\n",
      "        -9.3221e-04,  1.1516e-02, -2.4151e-02,  2.4254e-02, -1.7353e-02,\n",
      "         2.3121e-02,  4.9206e-03, -2.6809e-02,  1.8911e-02,  3.5039e-04,\n",
      "        -2.7244e-02,  3.0045e-03, -1.8367e-02, -3.8145e-03,  2.5316e-02,\n",
      "        -1.9430e-02,  3.3854e-03,  1.9825e-02,  1.3821e-02, -1.0330e-02,\n",
      "         1.8847e-02, -2.1730e-02, -8.7529e-04,  2.2391e-02, -1.1390e-02,\n",
      "        -1.9836e-02, -5.1904e-03,  7.2562e-03,  9.9305e-03,  1.8825e-02,\n",
      "         2.8909e-02,  3.0941e-02,  6.1240e-03,  1.8391e-02, -1.6866e-02,\n",
      "        -3.1427e-02, -2.9117e-02, -2.1047e-02,  3.4085e-03,  3.1102e-02,\n",
      "        -2.2694e-02, -1.5709e-02, -1.5396e-02, -1.2527e-02, -3.2047e-03,\n",
      "         8.9433e-03, -2.4033e-02,  2.6714e-02,  1.6973e-02, -2.1506e-03,\n",
      "        -2.1112e-02,  2.6978e-02, -2.6985e-02, -1.2676e-02,  7.5605e-03,\n",
      "        -1.9761e-02,  1.8483e-02, -3.0949e-02,  4.4767e-04,  1.5137e-02,\n",
      "        -2.7770e-02, -1.0901e-02, -3.0629e-02, -2.2153e-02,  1.7375e-02,\n",
      "        -1.0976e-02,  1.1666e-02, -4.4670e-03,  1.6931e-02,  2.8763e-02,\n",
      "        -5.0390e-04, -5.2587e-03,  2.0319e-03,  4.5906e-03, -7.5440e-04,\n",
      "         2.7668e-02,  1.1825e-02, -1.5332e-02, -7.1213e-03, -2.9011e-02,\n",
      "        -1.7070e-02,  2.1244e-02,  1.0100e-02,  5.9638e-03,  2.1145e-03,\n",
      "         3.1778e-02, -1.7856e-02,  5.1011e-03,  1.1524e-02, -1.7893e-02,\n",
      "        -2.2604e-02,  2.4364e-02,  2.5645e-03, -3.0100e-03, -9.3715e-03,\n",
      "        -1.4611e-02,  1.4627e-02, -2.6996e-02, -2.0386e-02,  1.7231e-03,\n",
      "        -2.2591e-02, -3.2639e-03, -2.7373e-02, -7.3347e-04, -1.9992e-02,\n",
      "         8.9487e-04, -4.3450e-03,  1.9308e-03, -1.0747e-02,  5.7835e-03,\n",
      "        -6.1449e-03, -6.9075e-03,  2.6925e-03,  1.2592e-02,  5.7491e-03,\n",
      "        -1.8149e-02, -1.2400e-02, -1.8953e-02,  1.1373e-02, -2.4812e-02,\n",
      "         5.7086e-03,  1.8423e-02,  5.8878e-03, -3.0811e-02,  2.4785e-02,\n",
      "         1.1860e-02,  6.0625e-03, -3.1475e-02,  1.3892e-02,  9.0794e-03,\n",
      "         9.3532e-03,  2.8926e-02,  1.3530e-02,  1.3153e-02, -2.2165e-02,\n",
      "         1.6734e-03, -2.4559e-02, -2.5148e-02,  1.3179e-03, -3.0144e-02,\n",
      "        -4.8327e-03,  2.7771e-02,  2.6923e-02,  1.7744e-02, -2.9075e-02,\n",
      "         1.5879e-02,  1.1225e-02,  1.5090e-02, -1.3116e-02,  1.1012e-02,\n",
      "        -7.2943e-03,  6.2543e-03, -1.2935e-02,  1.8164e-02, -5.5961e-03,\n",
      "         3.1669e-02, -3.3515e-03, -2.6874e-02,  2.3253e-02, -5.3381e-04,\n",
      "         2.4944e-03,  1.0778e-02, -2.1695e-02, -2.4449e-02,  1.5236e-02,\n",
      "         5.3214e-03, -1.3826e-02, -1.9981e-02,  2.6184e-02,  1.0814e-03,\n",
      "         3.0072e-02,  3.1717e-02, -1.0686e-02,  2.4076e-02,  9.2877e-03,\n",
      "        -2.4758e-02,  3.0857e-02,  2.8609e-02, -8.1410e-03, -1.1496e-02,\n",
      "        -2.8698e-02, -2.4829e-02, -7.3317e-03,  1.6674e-03, -2.2707e-02,\n",
      "         1.4779e-02, -1.7667e-02, -2.8916e-02, -1.3803e-02,  3.1463e-02,\n",
      "        -2.0432e-02, -2.7445e-03,  6.3483e-03,  2.6202e-02, -2.5791e-02,\n",
      "        -2.4133e-02, -1.8623e-03, -1.7530e-02,  1.7092e-02, -2.4995e-02,\n",
      "         3.0221e-02, -1.7125e-02,  2.3152e-02, -3.8056e-03,  2.6246e-02,\n",
      "         1.6134e-02, -2.1784e-02, -2.8206e-02,  1.1823e-03, -4.1133e-03,\n",
      "         6.2816e-03, -2.1205e-02, -4.0292e-03, -8.4625e-03, -5.4750e-03,\n",
      "         2.3678e-02, -2.7844e-02,  2.1361e-02,  9.9053e-04, -2.5602e-02,\n",
      "        -4.0746e-04, -9.7456e-03, -1.6428e-02, -2.3853e-02, -1.7937e-02,\n",
      "        -1.2290e-02, -1.6109e-02, -3.4164e-03,  1.0630e-03,  1.7364e-02,\n",
      "        -2.1721e-02,  4.9188e-03, -1.5432e-02, -3.3384e-03, -1.0695e-02,\n",
      "         3.0229e-02, -2.6228e-02,  1.4716e-02,  1.2908e-02, -6.4141e-03,\n",
      "         1.3497e-02, -1.0608e-02, -2.2541e-02, -2.0049e-02, -9.6625e-03,\n",
      "         2.2959e-02,  1.8727e-02, -1.8942e-02, -3.1220e-02,  4.5039e-03,\n",
      "        -3.5269e-03,  2.8421e-02, -6.1032e-03,  9.2316e-03, -1.3506e-02,\n",
      "        -8.6972e-04,  3.6864e-03, -3.1878e-02, -1.9812e-02,  6.5892e-03,\n",
      "        -2.5908e-02, -1.7893e-02,  8.5958e-04,  1.8730e-02,  1.3879e-02,\n",
      "         1.5878e-02, -2.6912e-02, -3.8643e-03, -1.0204e-02, -1.2193e-02,\n",
      "        -1.2244e-02, -2.6788e-02,  3.1609e-02,  3.0997e-02, -2.2651e-02,\n",
      "        -4.4180e-03,  2.2305e-02, -2.9388e-02,  1.2730e-02, -1.9921e-03,\n",
      "        -2.9953e-02, -1.8180e-02, -3.0682e-02,  3.0931e-02, -3.0286e-02,\n",
      "        -2.6303e-02,  6.1263e-04,  7.6323e-03, -2.3778e-02, -1.0408e-02,\n",
      "        -1.6201e-02, -1.8465e-02, -1.6239e-02, -1.4958e-02,  2.7020e-02,\n",
      "         2.4769e-02])), ('_sequence.4.weight', tensor([[ 0.0372, -0.0181, -0.0415,  ...,  0.0365, -0.0258,  0.0375],\n",
      "        [ 0.0335, -0.0209,  0.0186,  ..., -0.0244, -0.0384,  0.0337],\n",
      "        [-0.0238,  0.0002, -0.0141,  ..., -0.0097, -0.0037,  0.0231],\n",
      "        ...,\n",
      "        [ 0.0325, -0.0096, -0.0191,  ...,  0.0188, -0.0002, -0.0184],\n",
      "        [ 0.0441,  0.0379, -0.0287,  ...,  0.0052,  0.0133, -0.0418],\n",
      "        [ 0.0077,  0.0266, -0.0391,  ...,  0.0352, -0.0144,  0.0289]])), ('_sequence.4.bias', tensor([ 0.0116,  0.0182, -0.0018,  0.0168, -0.0061,  0.0082,  0.0218, -0.0243,\n",
      "        -0.0111,  0.0261,  0.0194,  0.0171,  0.0234,  0.0309, -0.0396, -0.0303,\n",
      "        -0.0189, -0.0115, -0.0004,  0.0440, -0.0001, -0.0402, -0.0319,  0.0290,\n",
      "        -0.0347,  0.0163, -0.0444, -0.0366, -0.0392,  0.0171,  0.0389, -0.0055,\n",
      "         0.0028, -0.0251, -0.0094, -0.0397,  0.0085, -0.0340, -0.0442,  0.0432,\n",
      "         0.0138, -0.0069, -0.0015, -0.0429, -0.0377, -0.0399,  0.0272,  0.0259,\n",
      "         0.0151, -0.0290,  0.0174,  0.0301,  0.0289,  0.0081,  0.0303,  0.0287,\n",
      "        -0.0284, -0.0079, -0.0024, -0.0044,  0.0391,  0.0116, -0.0227,  0.0371,\n",
      "        -0.0217,  0.0254, -0.0110,  0.0446, -0.0222, -0.0021, -0.0256, -0.0019,\n",
      "        -0.0154, -0.0376,  0.0224,  0.0018,  0.0256,  0.0041,  0.0436,  0.0313,\n",
      "         0.0374, -0.0243,  0.0389,  0.0271, -0.0101, -0.0347,  0.0019, -0.0074,\n",
      "         0.0248, -0.0356, -0.0355, -0.0162,  0.0183, -0.0194,  0.0410,  0.0157,\n",
      "         0.0194,  0.0432,  0.0097, -0.0094,  0.0199, -0.0143,  0.0017, -0.0442,\n",
      "        -0.0397,  0.0431, -0.0076, -0.0257, -0.0319,  0.0282, -0.0369,  0.0260,\n",
      "        -0.0296, -0.0296,  0.0005,  0.0043,  0.0251,  0.0109, -0.0340,  0.0095,\n",
      "        -0.0129, -0.0107,  0.0063, -0.0120,  0.0419, -0.0378, -0.0062, -0.0151,\n",
      "         0.0239,  0.0321, -0.0233,  0.0450,  0.0098, -0.0171, -0.0102, -0.0395,\n",
      "         0.0162,  0.0136, -0.0025, -0.0298, -0.0175,  0.0084, -0.0106,  0.0349,\n",
      "        -0.0019,  0.0251, -0.0282,  0.0050,  0.0015, -0.0104, -0.0148, -0.0140,\n",
      "        -0.0382,  0.0330,  0.0400,  0.0091, -0.0222,  0.0078, -0.0003,  0.0114])), ('_sequence.6.weight', tensor([[ 0.0353,  0.0498, -0.0717,  ..., -0.0627, -0.0211,  0.0135],\n",
      "        [-0.0346, -0.0086, -0.0754,  ..., -0.0025, -0.0025,  0.0723],\n",
      "        [-0.0214, -0.0345,  0.0388,  ..., -0.0467,  0.0510, -0.0187],\n",
      "        ...,\n",
      "        [ 0.0519, -0.0629,  0.0286,  ...,  0.0745, -0.0119, -0.0115],\n",
      "        [-0.0056,  0.0585, -0.0130,  ...,  0.0211,  0.0206,  0.0178],\n",
      "        [ 0.0546, -0.0687,  0.0709,  ..., -0.0685, -0.0715, -0.0691]])), ('_sequence.6.bias', tensor([-0.0418,  0.0287, -0.0269, -0.0509,  0.0023,  0.0713, -0.0332,  0.0128,\n",
      "         0.0342,  0.0561,  0.0697,  0.0120,  0.0272, -0.0537, -0.0295, -0.0415,\n",
      "         0.0716,  0.0422, -0.0148, -0.0733, -0.0013, -0.0143, -0.0036,  0.0400,\n",
      "         0.0247,  0.0616, -0.0302,  0.0555, -0.0111, -0.0397, -0.0429, -0.0312,\n",
      "         0.0034, -0.0237, -0.0706,  0.0187, -0.0614, -0.0276, -0.0650, -0.0181])), ('_sequence.8.weight', tensor([[-0.1386, -0.0678, -0.1091,  0.1487, -0.0186, -0.1496,  0.0479, -0.0410,\n",
      "         -0.1179,  0.0355, -0.1025,  0.1548,  0.0980,  0.0596, -0.0447,  0.0104,\n",
      "          0.1163,  0.0754, -0.0072, -0.0921,  0.0633, -0.0381,  0.0930, -0.0385,\n",
      "          0.1165, -0.0448, -0.0873, -0.1169, -0.1271, -0.0647,  0.1200,  0.1304,\n",
      "         -0.0239,  0.1516,  0.0277, -0.0855, -0.1118,  0.0339,  0.1295,  0.0662],\n",
      "        [-0.0943, -0.1248, -0.0981, -0.0700, -0.0684,  0.0970,  0.1123,  0.0606,\n",
      "         -0.0932, -0.0203,  0.1451, -0.1568, -0.1365,  0.0053,  0.0100, -0.0747,\n",
      "          0.0715, -0.1326, -0.1454,  0.1127, -0.0746,  0.0871, -0.0286, -0.0292,\n",
      "          0.1259,  0.0913,  0.0740, -0.1410,  0.1444,  0.0598, -0.0283,  0.1364,\n",
      "          0.1555,  0.0959,  0.0842, -0.0508, -0.0027, -0.1085, -0.1413, -0.0261],\n",
      "        [-0.1087, -0.1575, -0.1050, -0.0413,  0.1473,  0.0318, -0.0306,  0.1174,\n",
      "         -0.0205,  0.0033, -0.1352, -0.0219, -0.0938,  0.0601,  0.0766,  0.0778,\n",
      "         -0.1244, -0.0142,  0.0594,  0.0519, -0.0759,  0.0592,  0.1405,  0.0056,\n",
      "         -0.0965,  0.1381, -0.0614, -0.0187, -0.0349, -0.0228, -0.1259, -0.0122,\n",
      "         -0.0870, -0.0215, -0.0460, -0.1448,  0.1141,  0.1441, -0.0644, -0.0839]])), ('_sequence.8.bias', tensor([-0.0918, -0.0682,  0.1302]))])\n"
     ]
    }
   ],
   "source": [
    "print(model_MLPSEQ.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the parameters look similar but have different names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced size: 50000\n"
     ]
    }
   ],
   "source": [
    "dset=WCH5Dataset(\"/project/rpp-blairt2k/machine_learning/data/TRISEP_data/NUPRISM.h5\",reduced_dataset_size=50000,val_split=0.1,test_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataloader and grab a first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_dldr=DataLoader(dset,\n",
    "                      batch_size=32,\n",
    "                      shuffle=False,\n",
    "                      sampler=SubsetRandomSampler(dset.train_indices))\n",
    "train_iter=iter(train_dldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch0=next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 40, 38])\n"
     ]
    }
   ],
   "source": [
    "data=batch0[0]\n",
    "labels=batch0[1]\n",
    "print(batch0[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the model output on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out=model_MLP(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5588e-01, 8.3167e-01, 1.2453e-02],\n",
      "        [1.4184e-01, 8.4643e-01, 1.1730e-02],\n",
      "        [5.3019e-02, 3.1128e-01, 6.3570e-01],\n",
      "        [6.0719e-05, 9.9991e-01, 2.7565e-05],\n",
      "        [1.7808e-03, 9.9481e-01, 3.4095e-03],\n",
      "        [1.2115e-08, 9.9999e-01, 9.0245e-06],\n",
      "        [7.1416e-07, 9.9806e-01, 1.9428e-03],\n",
      "        [1.4362e-02, 9.8489e-01, 7.4995e-04],\n",
      "        [7.3253e-05, 9.9993e-01, 1.0818e-08],\n",
      "        [4.1722e-08, 1.0000e+00, 1.0546e-09],\n",
      "        [2.1765e-06, 9.9994e-01, 5.6662e-05],\n",
      "        [2.5608e-10, 9.9998e-01, 1.7752e-05],\n",
      "        [3.3819e-06, 9.9997e-01, 2.2380e-05],\n",
      "        [3.8054e-07, 9.9992e-01, 7.7136e-05],\n",
      "        [1.4792e-05, 9.9993e-01, 5.7855e-05],\n",
      "        [2.4005e-07, 9.4046e-01, 5.9542e-02],\n",
      "        [1.2570e-07, 1.0000e+00, 1.5149e-07],\n",
      "        [6.5383e-06, 9.9999e-01, 4.3536e-07],\n",
      "        [9.2929e-01, 6.6639e-03, 6.4043e-02],\n",
      "        [5.4381e-02, 9.3027e-01, 1.5347e-02],\n",
      "        [1.2859e-09, 1.0000e+00, 1.8534e-09],\n",
      "        [1.2375e-06, 9.9994e-01, 5.9870e-05],\n",
      "        [2.4822e-03, 9.9554e-01, 1.9815e-03],\n",
      "        [5.8883e-04, 9.9922e-01, 1.8830e-04],\n",
      "        [4.5476e-04, 9.9954e-01, 1.2814e-06],\n",
      "        [3.0506e-01, 6.9494e-01, 1.3676e-07],\n",
      "        [2.9809e-03, 1.9822e-03, 9.9504e-01],\n",
      "        [1.4003e-05, 9.8944e-01, 1.0545e-02],\n",
      "        [9.9452e-01, 5.3618e-03, 1.1606e-04],\n",
      "        [9.9248e-01, 1.8715e-05, 7.5007e-03],\n",
      "        [6.1039e-01, 3.8015e-01, 9.4605e-03],\n",
      "        [1.2091e-03, 9.9872e-01, 6.5980e-05]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have model's predictions and we above got 'true' labels from the dataset, so we can now compute the loss - CrossEntropyLoss is the apropropriate one to use here. We will use `CrossEntropyLoss` from `torch.nn` - btw it is also a `Module`. First create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_module=CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_tensor=loss_module(model_out,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1716, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a 'forward pass'. We should now have a computational graph available - let's plot it for the kicks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't get torchivz in compute canada\n",
    "#from torchviz import make_dot\n",
    "#make_dot(loss_tensor,params=dict(model_MLP.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we calculate the gradients - let's check what they are now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, gradient: None\n",
      "name of a parameter: fc1.bias, gradient: None\n",
      "name of a parameter: fc2.weight, gradient: None\n",
      "name of a parameter: fc2.bias, gradient: None\n",
      "name of a parameter: fc3.weight, gradient: None\n",
      "name of a parameter: fc3.bias, gradient: None\n",
      "name of a parameter: fc4.weight, gradient: None\n",
      "name of a parameter: fc4.bias, gradient: None\n",
      "name of a parameter: fc5.weight, gradient: None\n",
      "name of a parameter: fc5.bias, gradient: None\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, gradient: {}\".\n",
    "          format(name, param.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No wonder - let's calculate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, gradient: tensor([[-2.1617e+01, -7.9434e+00,  0.0000e+00,  ...,  3.4940e-04,\n",
      "          3.9461e+03,  4.1098e+03],\n",
      "        [ 6.9727e+00,  0.0000e+00,  0.0000e+00,  ...,  4.4715e-03,\n",
      "          0.0000e+00, -7.3408e+03],\n",
      "        [ 1.8214e+01, -4.3554e-08,  0.0000e+00,  ...,  5.0821e-03,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-4.3934e+01,  4.8338e+01,  0.0000e+00,  ...,  6.2508e+03,\n",
      "          4.7601e+04, -4.0172e+03],\n",
      "        [ 6.6170e+01, -6.3718e+01,  0.0000e+00,  ...,  9.0761e+03,\n",
      "          6.1383e+04, -2.1802e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.5062e+04,\n",
      "          0.0000e+00, -1.7265e+04]])\n",
      "name of a parameter: fc1.bias, gradient: tensor([-2.8549e+01,  2.3962e+02,  1.6695e+02,  2.8477e+01,  1.4819e+02,\n",
      "        -3.7478e+01,  5.8402e+00,  1.0911e+02,  1.2432e+02,  1.2563e+02,\n",
      "        -2.8127e+00,  1.0869e+02, -3.4048e+01,  1.7507e+02, -6.9100e+01,\n",
      "        -3.5757e+01, -1.8806e+01, -2.2051e+02,  2.8780e+01,  7.6794e+00,\n",
      "         1.4813e+02, -4.3210e+01, -1.0493e+02,  8.0639e+00, -1.2220e+02,\n",
      "         1.6411e+02,  1.5550e+02, -4.9182e+01,  5.3589e+01, -8.9656e+01,\n",
      "         5.5379e+01,  1.7016e+02,  4.4083e+01, -1.8674e+01, -5.6244e-02,\n",
      "         1.0829e+02,  1.0792e+02,  2.2076e+01,  4.4606e+00,  1.9295e+02,\n",
      "         6.0086e+01,  1.9123e+02, -2.0398e+02,  8.9075e+01,  5.9131e+01,\n",
      "        -1.3080e+01, -5.6358e+01, -3.8618e+01, -1.3837e+02,  5.8896e+01,\n",
      "        -2.0922e+01, -1.8559e+01,  4.0633e+01, -1.3132e+02,  1.8969e+02,\n",
      "         9.5021e+01,  3.4724e+01,  1.8970e+02, -5.0129e+01, -2.5003e+02,\n",
      "        -5.1012e+01,  1.3119e-01,  4.3194e+01,  1.7868e+01,  8.5579e+01,\n",
      "         3.2625e-01, -2.3110e+01,  6.3821e+01,  6.1007e+01,  9.4228e+01,\n",
      "         2.3741e+00, -2.5354e+02,  4.4615e+01,  2.5241e+02,  9.4353e+01,\n",
      "         1.6799e+02,  6.2325e+01,  3.6798e+01, -1.0383e+01, -4.3570e+01,\n",
      "        -1.2832e+02,  1.6447e+01, -1.8768e+01, -9.6075e+01,  1.0374e+01,\n",
      "        -9.3542e+01, -2.3888e+02,  2.3234e+01, -9.5002e+01,  2.4677e+02,\n",
      "        -5.3107e+01,  1.2566e+01, -5.9710e+00, -4.0373e+01,  2.5354e+01,\n",
      "        -2.0961e+01,  5.3957e+01, -1.1794e+02,  1.3063e+02, -1.1259e+02,\n",
      "         6.7261e-01,  1.3122e+02,  3.7855e+01, -1.5964e+01,  1.4821e+02,\n",
      "         1.1025e+02,  9.9702e+01, -2.4720e+01, -3.7397e+01,  6.8545e+01,\n",
      "        -1.4788e+02,  1.9970e+02,  2.3008e+01, -1.3647e+02, -1.0596e+02,\n",
      "        -8.1882e+01,  2.5976e+02,  1.5185e+01, -4.5536e+00, -1.2362e+02,\n",
      "        -6.8116e+01,  1.9777e+02, -1.4407e+02, -1.0660e+02, -2.6436e+00,\n",
      "         2.7024e+01,  4.7945e+01, -1.2153e+02, -7.0154e+01,  2.3157e+02,\n",
      "         8.1187e+01, -9.0313e+00,  1.4815e+02,  1.0225e+01, -5.6703e+01,\n",
      "         1.5077e+02,  6.7618e+01,  2.8863e+02,  5.4364e+01,  1.1569e+01,\n",
      "         3.4940e+00,  1.2854e+01,  1.2892e+01,  1.2189e+02, -4.1058e+01,\n",
      "        -5.1012e+01,  1.0722e+02,  8.4798e+00,  2.6245e+02,  4.4076e+01,\n",
      "        -8.8834e+01,  1.5896e+01, -7.2170e+01,  1.9392e+02, -3.7172e+01,\n",
      "         8.4727e+01,  1.1607e+02, -1.6721e+02,  2.0984e+01, -1.3275e+02,\n",
      "        -2.1351e+01,  3.0958e+01,  1.2579e+01, -4.6250e+01,  1.8684e+02,\n",
      "        -8.8646e+01,  8.0996e+01, -8.8154e+00,  2.7584e+00,  2.4724e+01,\n",
      "         7.6260e+01, -3.4339e+01,  9.4382e+01,  8.3173e+01, -1.1865e+01,\n",
      "         1.4669e+02, -3.6866e+01, -5.3364e+00,  1.2099e+02,  1.0253e+02,\n",
      "         2.0565e+02, -8.5683e+00,  1.5669e+02, -1.3699e+02, -2.5116e+01,\n",
      "         4.1615e+02, -5.1093e+01, -1.7461e+01,  2.6662e+01,  3.8538e+01,\n",
      "        -1.2574e+02,  3.8436e+02, -1.4001e+01,  1.2550e+02, -3.9251e+01,\n",
      "         9.1230e+01,  1.0152e+02, -3.4540e+01,  1.3797e+02,  7.9685e+00,\n",
      "         3.9564e+01, -1.4954e+02,  1.5473e+02,  5.9513e+01,  1.2666e+02,\n",
      "         1.9295e+02,  5.5832e+01, -5.0572e+01, -4.5983e+01, -3.0506e+02,\n",
      "         2.5667e+00,  1.1731e+02,  9.9580e+01, -1.6479e+01,  1.2221e+01,\n",
      "         1.9809e+01, -1.4852e+01,  3.3915e+01,  1.2210e+02,  2.9004e+01,\n",
      "         5.9283e+01,  7.1755e+01, -9.2606e+01,  1.6565e+02,  4.8166e+01,\n",
      "        -3.6701e+01, -1.8952e+01,  3.8294e+01,  4.5348e+01, -2.1179e-02,\n",
      "         2.5145e+01, -4.8271e+01,  6.3847e+01,  1.7965e+02,  4.4687e+00,\n",
      "         7.7549e+00,  1.7184e+02,  1.0508e+02,  9.3273e+01,  5.8352e+01,\n",
      "         1.4444e+02, -2.2032e+02,  1.1510e+02,  5.3770e+01,  1.3303e+02,\n",
      "         8.7510e+01, -3.7018e+01,  2.9673e+02,  2.6533e+01, -6.7418e+01,\n",
      "         1.2958e+01, -2.2699e+01,  5.8481e+01, -7.4684e+01,  6.1604e+01,\n",
      "         8.7941e+01,  1.8594e+02,  1.0373e+02, -4.3622e-01, -1.2448e+02,\n",
      "         2.3167e+02, -1.2005e+02, -1.1980e+02,  6.1137e+01,  4.1996e+01,\n",
      "         1.5313e+01, -7.6153e+01, -2.6703e+02, -8.7775e+01, -1.1751e+02,\n",
      "         3.3350e+01,  2.4019e+02,  1.7291e+02,  7.3038e+01, -8.0221e+01,\n",
      "        -4.7474e+01,  1.3819e+02, -1.1257e+02, -2.7964e+02, -6.6720e+01,\n",
      "         7.0465e+01,  1.3708e+02,  3.0781e+02,  1.7011e+01,  1.2533e+02,\n",
      "        -2.9180e+01,  5.2351e+01,  1.9314e+02,  4.8370e+00,  3.3910e+02,\n",
      "         8.9167e+01, -1.3705e+02,  1.9192e+02,  1.4084e+01, -2.4397e+02,\n",
      "         1.1407e+02,  1.0746e+02,  1.5315e+02,  2.5885e+02,  4.9299e+01,\n",
      "         3.7351e+02, -1.1817e+02,  2.0136e+02, -9.1975e+01, -1.4309e+02,\n",
      "         2.4027e+02, -2.0956e+02, -2.6170e+02, -7.7208e+01, -1.1212e+02,\n",
      "        -2.4709e+02,  5.0980e+01, -1.1069e+02, -1.7318e+01,  1.1636e+02,\n",
      "        -4.2554e+01, -1.5832e+02,  1.7631e+01,  1.5892e+01,  4.8578e+01,\n",
      "        -3.3367e+01,  2.1321e+02, -8.8150e+01, -1.4192e+02,  5.3944e+01,\n",
      "         2.1900e+02, -7.1487e+01, -1.5883e+02, -2.6561e+02,  1.8471e+02,\n",
      "        -5.8377e+01,  4.3446e+01, -3.1303e+01, -3.8812e+01, -2.9364e+01,\n",
      "         2.1278e+02,  1.5083e+02, -3.6774e+00,  5.6415e+01,  5.3901e+01,\n",
      "        -1.0763e+02, -3.3169e+01, -1.5796e+02, -1.7594e+02,  3.3534e+01,\n",
      "        -5.5903e+01,  2.9972e+02, -3.5360e+01, -6.1345e+01,  1.1811e+02,\n",
      "        -1.7258e+02,  1.1260e+02,  1.2306e+02,  5.2141e+00,  3.7187e+01,\n",
      "         8.7383e+01,  1.4803e+02, -7.8023e+01,  5.6323e+01,  6.2978e+01,\n",
      "         6.0020e+01, -1.7129e+01,  6.0440e-01,  2.0953e+01, -1.9555e+02,\n",
      "         7.1426e+01, -6.3710e+01, -8.6572e+01, -5.3201e+01,  2.6242e+02,\n",
      "        -2.9913e+02,  1.7372e+02,  3.1046e+02,  2.1373e+02, -2.5804e+01,\n",
      "         6.8872e+01, -4.3726e+01, -1.9091e+02,  1.6211e+01,  7.9141e+01,\n",
      "         3.4999e+01,  6.9407e+01,  1.2361e+02, -1.2771e+02, -1.8312e+02,\n",
      "        -6.2531e+01, -6.1098e+01, -1.2964e+02,  2.3779e+02, -1.8385e+02,\n",
      "         1.4144e+02, -6.9637e+01, -1.6622e+02, -6.4142e+01,  1.7426e+02,\n",
      "         1.0093e+01,  5.6774e+01,  7.9473e+01, -7.7294e+01, -8.2038e+01,\n",
      "        -4.8433e+01, -8.0979e+01,  1.7627e+01, -2.0621e+01,  3.0390e+01,\n",
      "         2.3263e+02, -1.3312e+02,  1.1598e+02, -1.5959e+02, -1.8276e+01,\n",
      "         1.6945e+02,  1.5622e+02, -1.2180e+02,  1.7996e+02, -8.1896e+01,\n",
      "         6.1756e+01, -6.1649e+01,  8.4711e+01,  4.6758e+01, -1.4465e+02,\n",
      "        -1.2755e+02, -3.7752e+01, -2.4824e+02,  6.8531e+01, -2.3588e+01,\n",
      "        -1.0012e+02, -2.0972e+01, -1.8948e+02, -7.5495e+01,  1.4365e+02,\n",
      "         6.3907e+01,  1.5001e+02,  1.0397e+02,  1.6960e+02,  3.2011e+01,\n",
      "         1.0659e+02,  3.0740e+02,  3.6782e+00, -2.2599e+02,  5.0623e+01,\n",
      "         1.6380e+02,  6.3089e+01,  9.6018e+01,  9.6880e+01, -2.9980e+01,\n",
      "        -4.8754e+00, -6.0625e+00, -1.0240e+02, -1.0866e+02, -6.6232e+01,\n",
      "         2.7622e+01,  1.0827e+02,  1.8702e+02,  1.2685e+02,  1.4066e+02,\n",
      "        -2.4067e+01, -4.7404e+01,  1.5925e+02,  1.0742e+01, -4.6447e+01,\n",
      "        -7.9114e+01,  1.0021e+02, -6.9095e+01, -6.3686e+01,  9.2118e+01,\n",
      "        -6.3830e+01,  1.1705e+02, -1.2416e+02, -1.1377e+02,  3.9192e+01,\n",
      "         4.2365e+01, -7.7962e+01,  4.8493e+01, -1.9525e+01, -1.8215e+01,\n",
      "         2.1947e+02,  4.0814e+01,  8.2945e+01,  5.2990e+00,  5.0322e+01,\n",
      "        -3.5483e+01, -1.3629e+02,  1.6877e+02, -1.6575e+02, -5.9916e+01,\n",
      "         1.1349e+02, -4.8095e+01, -8.5515e+01, -8.2200e+01, -1.1663e+02,\n",
      "         2.2650e+02,  1.4659e+02, -1.3022e+02,  7.9760e+01, -8.7263e+01,\n",
      "        -7.6246e+01,  4.1396e+01,  9.1646e+01,  1.1201e+02,  2.6149e+01,\n",
      "         1.1821e+01, -6.7690e+01, -1.3543e+02, -2.8660e+02,  5.9108e+01,\n",
      "         3.0666e+02,  1.0732e+02,  8.2832e+01, -1.1493e+02,  2.5932e+01,\n",
      "         6.3478e+01,  7.0204e+01, -2.3034e+01, -8.5650e+01, -4.2997e+01,\n",
      "         9.4936e+01, -1.3507e+01, -2.0643e+01,  4.0230e+01,  4.7561e+01,\n",
      "        -1.5924e+02,  4.0223e+01,  1.5592e+02,  1.5839e+01,  1.1632e+01,\n",
      "        -1.3393e+02,  1.5424e+02, -2.3996e+02,  8.6403e+01, -3.8831e+01,\n",
      "        -3.2648e+02, -1.4889e+01,  1.2335e+02, -9.6513e+01, -8.5461e+01,\n",
      "        -4.0044e+01, -1.9371e+02,  1.8432e+02, -5.1605e+01, -1.4782e+02,\n",
      "         1.0234e+00,  6.7277e+01,  1.5549e+02,  5.9591e+00,  7.7728e+00,\n",
      "         3.3230e+02, -6.5359e+01, -3.0386e+02,  6.3049e+01,  3.1805e+01,\n",
      "         2.9392e+01, -1.3481e+02,  2.6896e+01,  2.1673e+02,  1.6840e+02,\n",
      "        -6.6880e+01, -1.6705e+02,  3.1799e+02, -9.9104e+01, -1.1450e+01,\n",
      "         4.6065e+02, -1.7246e+02, -5.4207e+01,  1.2310e+01,  7.2696e+01,\n",
      "        -3.2149e+02, -7.4900e+01, -5.9415e+01, -8.2441e+01,  2.4315e+02,\n",
      "         1.4372e+02, -2.0295e+02, -1.5871e+02, -3.7575e+00, -1.3218e+02,\n",
      "         2.5707e+02,  1.9560e+02, -4.0434e+01,  2.2556e+02, -2.0884e+01,\n",
      "         3.5518e+01, -2.1440e+02,  1.3997e+02, -3.8337e+01, -4.3657e+01,\n",
      "         1.6861e+02,  3.9255e+01, -2.7933e+01,  2.1940e+02,  1.4105e+02,\n",
      "        -2.3206e+01, -2.1843e+02,  1.4430e+02, -5.1802e+01, -3.0828e+02,\n",
      "        -2.4585e+02,  1.3376e+02, -2.0884e+02,  1.8970e+02, -7.6927e+01,\n",
      "        -1.9878e+01,  2.3061e+02,  1.3025e+02, -3.6941e+01,  1.0164e+02,\n",
      "         1.5840e+02, -9.4522e+01, -2.7312e+01, -9.0746e+01,  1.1399e+02,\n",
      "        -9.7396e+01,  8.6699e+01,  1.3012e+02, -2.2006e+02, -5.1972e+00,\n",
      "         3.0887e+02,  1.1294e+02,  5.6135e+01,  8.5811e+01,  2.3647e+01,\n",
      "         3.7122e+02, -5.7274e+00,  5.0819e+01,  1.2691e+02, -2.3793e+02,\n",
      "        -6.1228e+01, -2.8996e+02,  2.6337e+02,  3.5672e+02, -2.1770e+02,\n",
      "        -9.4009e+01, -1.7768e+02, -1.5091e+01,  1.6769e+01, -2.6900e+01,\n",
      "         8.3711e+01,  7.1307e+01, -2.0894e+02,  2.3194e+02, -1.1056e-01,\n",
      "         4.1856e+01,  2.4752e+02, -1.2871e+02,  1.5210e+02,  2.2512e+02,\n",
      "        -3.1115e+01, -6.5212e+01,  1.1402e+02, -1.9424e+00,  2.2361e+01,\n",
      "         2.1326e+02,  6.0767e+01,  2.9005e+00,  1.1998e+02, -6.8796e+00,\n",
      "        -1.4436e+02, -7.5340e+00,  2.3704e+01,  1.9775e+01, -3.4979e+01,\n",
      "         8.1397e+01,  3.3887e+01,  6.3535e+01, -9.0472e+01, -2.7553e+01,\n",
      "         2.4062e+02, -1.9269e+02,  1.7670e+01, -6.6706e+01, -2.1428e+02,\n",
      "         2.1611e+02,  1.9827e+02, -3.3681e+01, -4.9498e+01,  1.3023e+02,\n",
      "         2.5604e+01,  9.7419e+01, -1.0317e+02,  1.9454e+02,  1.6575e+01,\n",
      "        -3.1710e+01,  4.0966e+02, -4.4547e+02,  4.7591e+01,  2.6580e+01,\n",
      "         9.3030e+01,  1.1916e+01,  9.8569e+01,  9.3293e+01, -8.5460e+01,\n",
      "        -1.9601e+02,  9.9670e+01,  7.3318e+01,  3.3525e+01, -4.7699e+01,\n",
      "        -1.4384e+02, -9.0481e+01, -3.1650e+01,  1.6741e+02, -2.2233e+02,\n",
      "        -4.9554e+01,  2.1681e+02,  8.1755e+01, -3.9418e+00,  6.8724e+01,\n",
      "         9.0560e+00,  1.0087e+02,  7.6258e+01,  3.4750e+02, -1.3994e+02,\n",
      "         5.3841e+01,  1.6392e+02,  2.2850e+01,  4.5222e+02,  3.1592e+02,\n",
      "         1.6307e+01, -2.7628e+01,  1.2755e+02,  1.1726e+02, -3.3069e+02,\n",
      "        -3.6645e+00, -6.4710e+01, -6.9151e+01,  4.1849e+02,  1.7992e+02,\n",
      "        -4.2322e+02,  1.3809e+02,  3.5765e+02, -7.9538e+01,  1.1287e+02,\n",
      "         5.8747e+01, -7.4038e+01,  1.7105e+02,  1.8172e+02, -5.1310e+01,\n",
      "        -1.4908e+02,  1.0746e+02,  3.4441e+02, -1.2571e+01,  9.9127e+01,\n",
      "         3.0147e+02,  4.6767e+01,  2.3816e+02, -7.5422e+01,  1.9092e+02,\n",
      "         3.6248e+02, -9.4196e+01,  1.0753e+02, -9.5873e+00, -6.2059e+01,\n",
      "         3.9974e+01, -1.9048e+02, -7.8843e+01,  2.5492e+02,  1.3638e+01,\n",
      "        -1.0092e+02,  1.2344e+02, -5.6812e+00,  3.7185e+01,  8.8482e+01,\n",
      "         8.1691e+01,  3.5183e+01, -1.4839e+02, -1.1257e+02, -1.4343e+02,\n",
      "         1.2597e+01,  6.4964e+01, -5.3508e+01,  3.0540e+00,  4.6453e+01,\n",
      "         2.0918e+01, -1.7406e+02, -8.8536e+00, -5.7235e+01, -5.5334e+01,\n",
      "        -1.4488e+00, -2.8305e+01,  4.7131e+01,  5.6208e+01, -3.6827e+01,\n",
      "        -1.6820e+01, -9.7066e+01, -1.3552e+02, -1.9186e+02,  4.5124e+01,\n",
      "         1.5449e+02,  7.9867e+01,  8.7739e+01,  1.4598e+02, -3.7960e+02,\n",
      "         1.2379e+02,  1.1680e+02,  2.0603e+02,  4.4272e+01, -2.3093e+02,\n",
      "         2.1048e+01,  4.0343e+01, -1.7465e+02,  7.8378e+01, -1.9839e+02,\n",
      "         2.3935e+02, -6.8522e+01, -8.8626e+01, -1.1534e+02, -2.3989e+02,\n",
      "         9.4682e+01,  1.1865e+02, -4.6402e+01,  5.1066e+01,  2.6036e+02,\n",
      "         3.5131e+02,  1.7225e+01, -8.8238e+01,  1.5544e+02, -3.4298e+01,\n",
      "        -1.4500e+02, -1.3886e+01, -1.5300e+02, -1.6965e+02, -5.0262e+02,\n",
      "         1.5843e+02, -1.6203e+01, -4.3380e+01, -4.4606e+01,  5.1693e+01,\n",
      "        -7.7783e+01, -1.6362e+02, -4.7227e+02,  1.6335e+02,  9.9441e+01,\n",
      "         1.8677e+02, -2.3818e+01, -1.2577e+02,  5.3498e+01, -4.5300e+00,\n",
      "        -1.3261e+02, -1.8247e+02,  1.1211e+02,  1.3975e+02,  8.8629e+01,\n",
      "         2.3895e+02, -9.8217e+01,  1.8881e+02, -1.3945e+02,  1.3896e+02,\n",
      "        -1.3883e+02, -9.5396e+01, -6.8310e+01, -7.2958e+01,  3.0423e+02,\n",
      "        -1.3131e+02, -1.6585e+02,  2.5956e+02,  4.5121e+01, -3.9887e+02,\n",
      "         2.1066e+02,  8.6645e+01,  9.0184e+01,  8.3059e+01, -8.0926e+01,\n",
      "         2.5289e+02, -4.8378e+01,  2.5619e+02, -1.4512e+01, -1.6338e+02,\n",
      "        -1.7618e+02, -1.9833e+01, -9.2012e+01,  1.8989e+02, -9.2396e-02,\n",
      "        -3.0931e+02, -6.9723e+01, -1.5227e+02, -3.5901e+01, -1.1008e+02,\n",
      "         1.7626e+02,  4.4123e+02,  4.0130e+01,  1.6542e+02, -2.1312e+02,\n",
      "         2.6083e+02,  1.8981e+02,  1.6842e+02, -4.5497e+02,  1.3384e+02,\n",
      "         2.1632e+02, -5.8725e+01, -2.0020e+02,  2.7885e+02,  1.7282e+02,\n",
      "         1.2905e+02, -2.5175e+02,  1.1155e+02,  4.6633e+00, -4.7688e+01,\n",
      "        -9.0830e+01,  2.6391e+02,  2.9825e+01, -1.0714e+02,  2.5494e+02,\n",
      "         9.6932e+01,  1.4381e+02, -2.7162e+02,  3.4836e+00,  4.6773e+01,\n",
      "         4.2432e+01, -5.8266e+01, -1.7911e+02,  9.8616e+01, -1.2110e+02,\n",
      "         6.4280e+01,  1.4499e+01, -1.8956e+01,  5.5384e+01,  7.5103e+01,\n",
      "        -2.7323e+02,  1.5115e+02,  3.0219e+01,  1.0186e+00,  1.5851e+02,\n",
      "         1.1209e+02,  2.2215e+01,  8.5604e+01, -2.5019e+02,  1.2009e+01,\n",
      "         1.0719e+02, -5.8570e+01, -6.9843e+01,  3.7719e+02, -1.9668e+02,\n",
      "         4.6398e+01, -2.8584e+02,  8.1028e+01, -4.1836e+01, -2.1767e+02,\n",
      "         6.0550e+01, -1.5140e+02,  2.0934e+01,  4.3361e+02, -4.9746e+02,\n",
      "         2.3996e+02, -3.4800e+02, -2.0083e+01, -1.9232e+02, -1.3075e+02,\n",
      "        -1.9126e+02,  1.1760e+02,  2.4400e+02,  4.1938e+02,  2.6436e+02,\n",
      "        -5.0606e+02,  2.0219e+02, -4.9595e+01,  3.8133e+02, -2.2441e+02,\n",
      "         3.0977e+01,  1.4472e+02, -1.6471e+02, -4.7715e+01,  7.8517e+01,\n",
      "         1.5933e+02,  9.1774e+01, -2.0543e+02, -3.6829e+01, -1.2390e+02,\n",
      "         1.7687e+01, -1.0451e+02,  5.1348e+01, -2.9250e+02,  2.4816e+02,\n",
      "         4.5807e+01, -1.5723e+02])\n",
      "name of a parameter: fc2.weight, gradient: tensor([[ 1.7562e-03, -4.8064e-03,  4.1367e-05,  ...,  3.3165e-03,\n",
      "          1.2742e-03, -2.5722e-03],\n",
      "        [ 6.0774e-05,  1.4698e-04, -5.1206e-05,  ..., -9.0653e-05,\n",
      "         -1.6238e-04, -7.4425e-06],\n",
      "        [-2.6166e-03,  1.7555e-03, -5.3684e-05,  ...,  1.1830e-02,\n",
      "          4.3193e-04,  5.2415e-03],\n",
      "        ...,\n",
      "        [-3.8795e-03, -1.5143e-03,  1.1706e-05,  ...,  1.0963e-02,\n",
      "         -4.5785e-03,  1.2710e-03],\n",
      "        [-1.0782e-03,  3.7795e-03, -1.9426e-04,  ...,  1.6375e-02,\n",
      "         -1.8242e-03,  8.1569e-03],\n",
      "        [ 4.6489e-03,  1.6218e-03, -2.2778e-05,  ...,  2.0401e-02,\n",
      "          2.4034e-03,  8.1625e-03]])\n",
      "name of a parameter: fc2.bias, gradient: tensor([-2.4430e-05, -1.9459e-05,  3.0925e-05, -1.8700e-05, -6.7421e-06,\n",
      "        -6.1641e-05, -5.5509e-05, -9.6626e-06,  7.1803e-05, -3.3294e-05,\n",
      "        -2.4102e-05,  6.8477e-05, -5.3760e-05,  6.2678e-06,  6.0384e-05,\n",
      "         4.6124e-05,  3.4534e-05,  6.6987e-06, -3.6554e-05, -7.5270e-05,\n",
      "         2.1614e-05, -4.5773e-05, -1.0357e-05, -1.0887e-05, -5.0176e-05,\n",
      "         9.8884e-05, -1.1721e-05,  4.2125e-05, -2.0672e-05,  9.6151e-06,\n",
      "        -2.0424e-05, -2.1460e-05,  4.0872e-05,  1.4007e-04, -5.2106e-05,\n",
      "         1.7553e-05,  6.3428e-05,  3.6077e-05,  1.7288e-05,  1.9495e-05,\n",
      "         9.3787e-06,  3.6650e-05,  8.6095e-05, -9.0935e-06, -7.6857e-06,\n",
      "         4.1752e-05,  7.2537e-05, -2.6556e-05,  8.3470e-05, -3.3593e-05,\n",
      "         6.5309e-06,  1.8784e-05,  1.1175e-04, -3.3058e-05,  6.9026e-06,\n",
      "        -1.1786e-04, -9.4684e-05,  3.3573e-06, -5.1770e-05, -4.0487e-06,\n",
      "         7.3521e-06,  1.3349e-05, -3.1110e-05,  3.5762e-06,  2.0679e-05,\n",
      "         1.6119e-05,  1.3537e-05,  2.3945e-05,  1.7114e-04,  1.7392e-05,\n",
      "        -4.9049e-05,  4.4977e-05,  1.0188e-04,  2.7303e-05,  2.4112e-05,\n",
      "         1.8328e-04, -9.8194e-05, -5.5460e-05, -3.1844e-05, -7.0215e-05,\n",
      "         6.3829e-05, -7.5196e-06, -1.0761e-05, -3.2990e-07,  1.2745e-05,\n",
      "        -5.9147e-05, -1.2624e-07, -2.9232e-05, -4.2169e-05, -6.2637e-05,\n",
      "        -4.4430e-05,  1.0014e-04, -1.2910e-04,  5.1895e-05,  9.7056e-06,\n",
      "         5.8127e-05, -1.6386e-04,  3.2361e-05, -3.1819e-05, -6.8331e-06,\n",
      "        -4.9341e-05, -3.8735e-05, -3.1762e-06,  4.0007e-05, -4.3137e-05,\n",
      "        -1.0327e-05, -1.8097e-05, -5.6158e-05,  2.9677e-05,  6.8036e-05,\n",
      "         4.4130e-05,  6.6644e-05, -2.1822e-05, -1.2657e-05,  2.3045e-05,\n",
      "         1.1179e-05, -1.7275e-05,  1.2849e-05,  8.3534e-05,  5.8531e-06,\n",
      "        -5.6005e-05,  5.0322e-05,  7.8167e-05,  4.6594e-05, -3.4943e-05,\n",
      "        -1.3386e-05,  7.0443e-05,  6.3898e-06, -5.3839e-05, -2.7718e-05,\n",
      "         1.9347e-05,  1.2314e-05,  8.6681e-06,  1.2879e-04, -4.6213e-05,\n",
      "        -4.4220e-05,  2.5343e-05, -3.2812e-05,  2.3580e-05, -1.8741e-05,\n",
      "         3.0360e-05,  1.3022e-05, -1.3754e-05, -4.8276e-05, -9.6670e-06,\n",
      "         1.2650e-04, -2.0613e-05,  1.6354e-04,  4.0694e-05,  8.3074e-06,\n",
      "        -1.0773e-04,  1.6926e-05,  1.3217e-04, -1.1878e-05,  2.0504e-05,\n",
      "         3.1609e-05,  1.3076e-05, -1.2190e-05,  8.3609e-05,  3.0008e-05,\n",
      "        -7.0326e-06, -3.2672e-05, -3.5065e-05,  7.3102e-05,  7.1137e-05,\n",
      "        -6.0496e-05,  9.2189e-05, -3.9245e-06, -7.9326e-05,  5.5562e-05,\n",
      "         6.7264e-06,  2.8600e-05, -3.5209e-06,  2.1640e-05,  1.3108e-05,\n",
      "         3.6792e-05, -8.9445e-05,  9.7009e-05, -7.5632e-05, -1.3607e-04,\n",
      "         7.0986e-06, -1.5571e-05, -1.6632e-05,  5.3725e-07,  4.2239e-05,\n",
      "         2.2764e-05,  1.5263e-05,  7.7941e-06,  1.6620e-05,  5.5647e-05,\n",
      "         6.6354e-05, -4.9161e-05,  8.3094e-05, -1.0631e-05, -1.6487e-05,\n",
      "        -1.7075e-05, -5.3352e-05,  5.2632e-05,  1.0350e-05, -8.5266e-06,\n",
      "        -3.0369e-05,  4.6858e-05, -3.0593e-05,  1.2679e-06, -7.9751e-05,\n",
      "        -4.3619e-05,  8.4601e-05, -1.3287e-05,  1.6153e-05,  9.0185e-06,\n",
      "        -1.3397e-05, -2.1110e-05,  4.1760e-05, -6.0017e-06, -1.1484e-04,\n",
      "         4.1433e-05,  6.3267e-05, -8.3250e-05, -8.1936e-05, -4.1798e-06,\n",
      "         2.9832e-06, -4.8020e-06,  4.6475e-06,  2.5421e-06,  4.6015e-05,\n",
      "         6.3892e-05, -1.7306e-05, -1.7184e-05,  4.5287e-05, -1.0170e-04,\n",
      "        -1.8395e-05, -3.4279e-05,  1.0862e-05, -1.2207e-05, -2.9547e-05,\n",
      "         5.8143e-05, -6.3275e-05,  1.2921e-05,  5.4852e-05, -1.6173e-05,\n",
      "        -1.5566e-05, -3.9208e-05, -4.1605e-07, -2.7913e-05, -1.6619e-05,\n",
      "         4.4036e-05,  3.6683e-06,  1.0071e-04,  2.2317e-05,  2.2863e-05,\n",
      "        -2.7811e-05, -1.5606e-05, -1.0767e-04,  7.3545e-05,  1.4266e-05,\n",
      "         9.9123e-05, -1.6817e-05, -1.6913e-06,  1.9017e-05,  7.0952e-05,\n",
      "         1.2488e-04,  1.2912e-05, -1.5771e-06,  5.5517e-05,  9.0175e-06,\n",
      "        -6.9428e-05,  2.0532e-05, -1.3595e-05, -1.6296e-05,  5.2788e-05,\n",
      "        -4.5407e-05, -1.2744e-05, -5.3912e-05,  9.0499e-05,  5.1613e-07,\n",
      "        -1.4055e-05,  2.2649e-05,  5.8803e-05, -3.2116e-05, -1.6500e-04,\n",
      "         1.2252e-06, -4.7587e-06, -2.0742e-05,  3.6585e-05, -7.3019e-05,\n",
      "        -3.1832e-05,  2.4778e-06, -6.4722e-06,  5.5627e-05, -8.9934e-05,\n",
      "         1.5778e-04, -2.6221e-05, -5.5251e-05,  7.4206e-06, -1.0184e-05,\n",
      "        -1.3856e-05, -1.3939e-05,  4.8488e-05, -3.1241e-05,  6.4539e-05,\n",
      "        -4.4221e-05,  4.5440e-05,  3.0275e-05, -2.2411e-05,  4.1648e-05,\n",
      "        -4.2049e-05,  6.4238e-05,  1.1441e-04, -1.0618e-04,  1.2363e-05,\n",
      "        -8.5527e-05, -4.4510e-05, -7.7991e-06, -2.7027e-05, -1.2134e-04,\n",
      "        -2.2664e-05,  3.1276e-05, -4.3801e-05, -2.3638e-05,  5.3368e-05,\n",
      "         1.2075e-05,  7.1182e-05, -4.1272e-06, -5.8134e-05,  6.8581e-05,\n",
      "        -6.9848e-05,  1.9918e-05,  2.3664e-05, -8.9127e-05,  3.6256e-05,\n",
      "         2.8987e-05, -2.3783e-05, -4.0589e-05, -7.1388e-05,  3.2290e-05,\n",
      "        -1.5919e-05,  9.9313e-05, -7.2896e-05,  5.3925e-05, -7.1022e-05,\n",
      "        -5.7606e-05,  3.8591e-05, -5.8477e-07,  2.6709e-06, -5.4164e-05,\n",
      "        -1.2820e-05,  2.8485e-05,  8.7846e-06, -1.1667e-04,  8.2076e-06,\n",
      "         4.1877e-06,  6.2624e-05, -4.4414e-06, -6.5113e-05,  5.2370e-06,\n",
      "        -4.5749e-05,  1.4559e-05, -1.0251e-04, -5.3129e-06, -2.6710e-05,\n",
      "        -6.2391e-06,  1.1984e-05, -3.8740e-05,  6.0999e-05,  2.8069e-05,\n",
      "         4.6934e-05, -1.5692e-05, -8.5515e-05,  3.6092e-05,  4.3914e-05,\n",
      "        -1.6896e-05, -1.6148e-05, -1.6164e-05,  9.5100e-05, -3.0135e-05,\n",
      "         5.7233e-05,  1.6160e-05,  2.1698e-05,  6.1121e-05,  1.1521e-05,\n",
      "        -1.5572e-04, -1.5504e-05,  7.9327e-05,  4.6550e-06,  4.3156e-07,\n",
      "         7.1367e-05,  5.4073e-05, -1.6371e-05, -1.6451e-05, -1.5570e-05,\n",
      "         4.2923e-05, -5.8112e-05,  8.0407e-06, -9.2645e-05, -2.7234e-06,\n",
      "        -1.3778e-04, -2.2384e-05,  8.4498e-05, -1.1508e-04, -6.9197e-05,\n",
      "        -1.4881e-04, -1.0833e-04,  2.6472e-05, -1.8680e-05, -5.1557e-05,\n",
      "         7.5275e-06,  2.4864e-06, -2.9049e-05, -1.3024e-05, -8.8183e-05,\n",
      "        -3.1149e-05,  3.5075e-05, -2.8962e-05, -6.1913e-06, -2.5239e-05,\n",
      "         2.1583e-05,  5.1326e-05, -2.6522e-05,  1.0609e-04, -2.8136e-05,\n",
      "         3.9077e-05, -6.5947e-05, -3.3237e-05,  7.8087e-05,  6.6885e-05,\n",
      "         1.8990e-05, -5.2372e-05,  1.0243e-04,  7.7848e-05, -2.5713e-06,\n",
      "         7.1451e-05,  7.0789e-05, -3.0045e-05, -1.3217e-05, -8.5569e-06,\n",
      "         1.3833e-05, -2.1210e-05, -1.9948e-05,  3.4736e-05,  1.7216e-05,\n",
      "        -3.9399e-05, -3.0373e-05,  8.0178e-05,  2.9460e-05, -1.6795e-05,\n",
      "         9.5960e-05,  2.9086e-05, -5.9376e-05,  1.6274e-05, -6.9469e-05,\n",
      "         2.9707e-05,  7.5296e-05,  7.9744e-06, -4.2833e-05, -3.2560e-05,\n",
      "        -1.1631e-05,  4.6087e-05,  7.0799e-06, -7.7416e-06, -1.4200e-06,\n",
      "         9.8518e-05, -1.5102e-06,  2.4804e-05,  4.9175e-05,  6.1760e-05,\n",
      "         1.3994e-06, -1.5706e-04,  7.2042e-05, -2.1006e-05, -3.9471e-06,\n",
      "         3.0220e-05, -1.2547e-05,  7.1362e-05, -2.0189e-05,  5.3943e-05,\n",
      "        -2.4560e-05, -1.3588e-05, -4.0500e-05, -2.8526e-05, -1.0043e-04,\n",
      "         8.6574e-05,  3.3029e-06, -1.0552e-04, -1.4543e-05,  8.0117e-05,\n",
      "         1.2024e-04])\n",
      "name of a parameter: fc3.weight, gradient: tensor([[-3.0971e-03, -5.5260e-03, -1.2872e-02,  ..., -6.0397e-03,\n",
      "         -1.1219e-02, -8.9328e-03],\n",
      "        [-1.8676e-05,  6.3134e-04,  3.1107e-05,  ..., -1.1353e-03,\n",
      "          2.6807e-03, -2.7178e-03],\n",
      "        [-1.0869e-03,  1.6359e-03,  6.2504e-03,  ...,  1.0291e-02,\n",
      "          4.0308e-03,  1.2199e-02],\n",
      "        ...,\n",
      "        [-1.8425e-06, -6.7837e-03, -4.7658e-03,  ..., -9.2552e-03,\n",
      "         -1.3916e-02, -1.5397e-02],\n",
      "        [ 3.2575e-06,  1.3838e-04,  2.3201e-04,  ...,  3.6537e-04,\n",
      "         -6.8934e-06,  2.3136e-07],\n",
      "        [ 1.8675e-04, -9.4358e-05, -4.5622e-04,  ..., -1.7272e-03,\n",
      "          5.8392e-03, -2.3059e-03]])\n",
      "name of a parameter: fc3.bias, gradient: tensor([-3.0174e-04, -2.9919e-05,  1.4609e-04,  8.0127e-06,  1.1645e-04,\n",
      "         6.1661e-05, -4.8156e-05,  2.8485e-04,  1.5688e-04, -8.5150e-06,\n",
      "         1.5671e-04, -2.2385e-04, -2.3102e-04,  5.4256e-07,  2.2498e-04,\n",
      "         7.6651e-06,  1.0800e-04,  2.2397e-04,  1.4363e-04,  1.7983e-04,\n",
      "        -8.7188e-05, -4.1092e-04, -2.1053e-05,  2.5978e-04,  2.2012e-05,\n",
      "        -3.0306e-04,  2.3764e-04, -1.4608e-04,  1.9052e-04, -1.2575e-05,\n",
      "         1.9189e-05,  2.3689e-04, -1.5374e-04, -3.9138e-04,  9.8662e-05,\n",
      "        -1.2111e-04,  2.4402e-05, -8.8819e-05, -1.4969e-04,  3.3304e-05,\n",
      "        -5.7166e-04,  8.1518e-05,  1.0694e-04, -1.1931e-04,  3.1284e-05,\n",
      "        -1.1569e-04,  4.0163e-05,  2.6835e-04, -4.3836e-06, -7.3644e-05,\n",
      "         4.3528e-05, -7.0550e-05, -5.3661e-05, -3.5003e-05, -2.0618e-04,\n",
      "         8.3864e-05, -6.3243e-04,  3.9151e-04, -1.2631e-04, -3.3948e-05,\n",
      "        -3.1353e-04, -8.5633e-05,  2.4984e-05,  1.4062e-04,  8.3776e-05,\n",
      "        -9.5750e-05,  1.8107e-04, -5.7583e-04, -1.4812e-04,  2.0461e-04,\n",
      "        -8.4306e-05,  5.3108e-05, -1.3922e-04, -9.6434e-05, -1.2589e-04,\n",
      "        -6.3267e-05, -1.2036e-04, -1.1343e-04,  2.2851e-04,  3.8353e-04,\n",
      "         1.5834e-04,  1.9530e-04,  2.0936e-04,  1.2983e-04,  5.9879e-06,\n",
      "        -4.5890e-05, -3.3027e-04, -8.2287e-05,  1.0913e-04, -5.2975e-05,\n",
      "         1.3814e-04, -3.1958e-06,  2.7869e-04, -5.8879e-05,  9.8428e-05,\n",
      "         1.3717e-04,  2.3660e-05,  2.1033e-04,  6.1194e-04,  3.1989e-04,\n",
      "        -3.9174e-04,  8.1702e-06,  3.7118e-04,  5.8503e-04,  2.3212e-04,\n",
      "         7.2901e-05,  2.4474e-04, -2.9082e-04,  3.6519e-04, -8.2295e-05,\n",
      "        -1.7488e-04, -6.5290e-05,  2.5632e-05,  4.7971e-05, -1.3059e-04,\n",
      "        -1.1375e-05,  8.0686e-05,  2.6206e-05,  3.7316e-04,  3.3051e-04,\n",
      "         2.0386e-04, -1.9111e-04, -4.2211e-05, -1.1118e-04,  1.2769e-06,\n",
      "        -7.9314e-05,  4.5226e-06, -3.3658e-04, -6.1853e-05,  2.6096e-04,\n",
      "         4.0008e-05,  3.1551e-04, -1.0069e-04, -1.3782e-04,  1.4184e-04,\n",
      "        -8.3656e-06, -1.2833e-04, -4.8959e-05, -2.9579e-04, -5.9028e-05,\n",
      "        -3.8921e-04, -7.5425e-05, -7.6286e-04, -5.1451e-05,  3.7118e-04,\n",
      "        -1.7488e-04, -2.1884e-04,  4.9798e-04,  1.3923e-04,  2.7611e-04,\n",
      "         5.5240e-06,  1.8026e-04, -2.1978e-04,  1.6087e-04, -2.2198e-04,\n",
      "        -1.3084e-04, -4.9424e-05, -2.9573e-04,  2.4598e-06,  7.4040e-05])\n",
      "name of a parameter: fc4.weight, gradient: tensor([[ 5.8418e-03,  4.1097e-03, -5.4529e-03,  ...,  8.8925e-04,\n",
      "         -1.4209e-04,  1.1570e-03],\n",
      "        [-5.6669e-02, -1.0697e-02,  2.3953e-02,  ...,  4.2753e-04,\n",
      "          2.1831e-05,  4.6474e-03],\n",
      "        [-2.0582e-03, -6.0698e-03, -1.0335e-05,  ...,  1.0199e-03,\n",
      "          0.0000e+00,  3.6144e-03],\n",
      "        ...,\n",
      "        [-7.6197e-03, -6.0417e-03,  3.2259e-04,  ..., -2.9721e-03,\n",
      "          2.2381e-04, -4.5798e-03],\n",
      "        [-6.9154e-03, -1.4030e-02, -4.4203e-05,  ...,  7.4400e-04,\n",
      "         -2.4302e-11,  4.9844e-03],\n",
      "        [ 1.7621e-02,  7.8804e-04, -1.0064e-02,  ..., -1.0035e-02,\n",
      "         -1.4927e-04,  1.7517e-03]])\n",
      "name of a parameter: fc4.bias, gradient: tensor([-5.7416e-04,  2.0995e-03, -3.1668e-05,  2.2000e-03,  3.5829e-04,\n",
      "        -2.4017e-03,  1.0983e-03, -4.5363e-04, -7.3155e-06,  1.9380e-04,\n",
      "         6.8472e-05, -1.4862e-04, -1.4489e-03,  7.0418e-04,  2.6886e-04,\n",
      "        -1.2222e-03,  9.2243e-05, -5.0769e-04,  1.0873e-04,  1.2009e-05,\n",
      "        -2.3292e-04, -8.5921e-05, -7.0940e-04, -6.3277e-04,  2.8066e-04,\n",
      "        -1.1397e-04,  2.5418e-03, -1.2334e-03,  1.9285e-03,  4.6804e-04,\n",
      "         1.9347e-03,  5.2039e-04, -1.8298e-04, -1.3667e-03,  3.0747e-06,\n",
      "        -2.3414e-04,  6.8521e-04, -1.5537e-04, -2.3051e-04, -7.0722e-04])\n",
      "name of a parameter: fc5.weight, gradient: tensor([[-1.0360e-01, -3.4816e-01, -4.1287e-03, -1.7028e-01, -4.6373e-02,\n",
      "         -4.1145e-01,  7.0371e-03,  2.5410e-02,  6.5674e-02, -3.2205e-03,\n",
      "          2.6863e-02,  1.0215e-02, -2.4551e-01, -2.3424e-02, -1.1201e-01,\n",
      "         -1.0663e-01, -3.9291e-02,  1.5174e-02,  1.5095e-01, -1.1599e-01,\n",
      "          6.3637e-02, -1.2949e-01, -1.0147e-01,  1.3080e-02,  2.9815e-02,\n",
      "         -1.1195e-01, -2.1385e-02, -5.4082e-02, -4.0436e-01, -3.4788e-02,\n",
      "         -1.2646e-01, -3.3557e-02, -4.7910e-02, -2.2003e-01,  1.0265e-02,\n",
      "         -5.1181e-01, -5.2810e-02,  2.3158e-02, -3.0345e-02, -2.6316e-02],\n",
      "        [ 1.0406e-01,  4.1632e-01, -1.2221e-02,  2.7045e-01,  4.9487e-02,\n",
      "          5.3108e-01,  3.2389e-02, -3.2763e-02, -6.8195e-02, -2.7879e-04,\n",
      "         -3.4663e-03,  3.6781e-02,  2.9573e-01,  1.9698e-02,  1.4827e-01,\n",
      "          1.4142e-01,  4.0130e-02, -2.2636e-02, -1.0962e-01,  2.1524e-01,\n",
      "         -6.7021e-02,  1.2175e-01,  5.4038e-02, -1.2381e-02, -1.5896e-02,\n",
      "          4.7473e-02, -8.4355e-03,  8.1689e-02,  3.8125e-01,  3.5335e-02,\n",
      "          2.1119e-01,  3.3557e-02,  8.4815e-02,  2.2933e-01, -2.7598e-04,\n",
      "          5.5263e-01,  5.3389e-02, -3.8304e-03, -5.6497e-03,  1.1940e-01],\n",
      "        [-4.5869e-04, -6.8158e-02,  1.6350e-02, -1.0017e-01, -3.1141e-03,\n",
      "         -1.1963e-01, -3.9426e-02,  7.3535e-03,  2.5207e-03,  3.4993e-03,\n",
      "         -2.3396e-02, -4.6997e-02, -5.0218e-02,  3.7262e-03, -3.6263e-02,\n",
      "         -3.4786e-02, -8.3849e-04,  7.4617e-03, -4.1334e-02, -9.9251e-02,\n",
      "          3.3842e-03,  7.7355e-03,  4.7437e-02, -6.9904e-04, -1.3919e-02,\n",
      "          6.4476e-02,  2.9821e-02, -2.7607e-02,  2.3104e-02, -5.4667e-04,\n",
      "         -8.4734e-02,  2.2650e-09, -3.6905e-02, -9.3038e-03, -9.9886e-03,\n",
      "         -4.0818e-02, -5.7942e-04, -1.9328e-02,  3.5995e-02, -9.3081e-02]])\n",
      "name of a parameter: fc5.bias, gradient: tensor([-0.0067,  0.0091, -0.0024])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, gradient: {}\".\n",
    "          format(name, param.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have to do now is subtract the gradient of a given parameter from the parameter tensor itself and do it for all parameters of the model - that should decrease the loss. Normally the gradient is multiplied by a learning rate parameter $\\lambda$ so we don't go too far in the loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "for param in model_MLP.parameters():\n",
    "    param.data.add_(-lr*param.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call to backward **accumulates** gradients - so we also need to zero the gradient tensors if we want to keep going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_MLP.parameters():\n",
    "    param.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a much simpler way of doing this - we can use the pytorch [optim](https://pytorch.org/docs/stable/optim.html) classes. This allows us to easily use more advanced optimization options (like momentum or adaptive optimizers like [Adam](https://arxiv.org/abs/1412.6980)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model_MLP.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a new batch of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1=next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=batch1[0]\n",
    "labels=batch1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out=model_MLP(data)\n",
    "loss_tensor=loss_module(model_out,labels)\n",
    "loss_tensor.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just put the code above in a loop and be done with it, but the usual practice would be to wrap this functionality in a training object. Here we'll use the [engine](/edit/utils/engine.py) class. Let's examine it. We'll talk about:\n",
    "  1. Implementation of the training loop\n",
    "  2. Evaluation on validation set and training and test modes.\n",
    "  3. Turning evaluation of gradients on and off.\n",
    "  4. Saving and retrieving the model and optimizer state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.engine import Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a configuration object -we'll use this to set up our training engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    pass\n",
    "config=CONFIG()\n",
    "config.batch_size_test =512\n",
    "config.batch_size_train = 256\n",
    "config.batch_size_val = 512\n",
    "config.lr=0.00001\n",
    "config.device = 'cpu'\n",
    "config.num_workers_train=2\n",
    "config.num_workers_val=2\n",
    "config.num_workers_test=2\n",
    "config.dump_path = '../model_state_dumps'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sticking to CPU\n",
      "Creating a directory for run dump: ../model_state_dumps/20240425_135100/\n"
     ]
    }
   ],
   "source": [
    "engine=Engine(model_MLP,dset,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size_test': 512, 'batch_size_train': 256, 'batch_size_val': 512, 'lr': 1e-05, 'device': 'cpu', 'num_workers_train': 2, 'num_workers_val': 2, 'num_workers_test': 2, 'dump_path': '../model_state_dumps'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Starting @ 2024-04-25 13:51:01\n",
      "... Iteration 0 ... Epoch 0.00 ... Validation Loss 1.206 ... Validation Accuracy 0.346\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLP.pth\n",
      "best validation loss so far!: 1.2057417631149292\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLPBEST.pth\n",
      "... Iteration 1 ... Epoch 0.01 ... Loss 1.204 ... Accuracy 0.348\n",
      "... Iteration 11 ... Epoch 0.07 ... Loss 1.219 ... Accuracy 0.332\n",
      "... Iteration 21 ... Epoch 0.13 ... Loss 1.212 ... Accuracy 0.340\n",
      "... Iteration 31 ... Epoch 0.20 ... Loss 1.239 ... Accuracy 0.312\n",
      "... Iteration 41 ... Epoch 0.26 ... Loss 1.223 ... Accuracy 0.328\n",
      "... Iteration 51 ... Epoch 0.32 ... Loss 1.262 ... Accuracy 0.289\n",
      "... Iteration 61 ... Epoch 0.39 ... Loss 1.243 ... Accuracy 0.309\n",
      "... Iteration 71 ... Epoch 0.45 ... Loss 1.216 ... Accuracy 0.336\n",
      "... Iteration 81 ... Epoch 0.52 ... Loss 1.239 ... Accuracy 0.312\n",
      "... Iteration 91 ... Epoch 0.58 ... Loss 1.219 ... Accuracy 0.332\n",
      "... Iteration 100 ... Epoch 0.64 ... Validation Loss 1.229 ... Validation Accuracy 0.322\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLP.pth\n",
      "... Iteration 101 ... Epoch 0.64 ... Loss 1.223 ... Accuracy 0.328\n",
      "... Iteration 111 ... Epoch 0.71 ... Loss 1.200 ... Accuracy 0.352\n",
      "... Iteration 121 ... Epoch 0.77 ... Loss 1.176 ... Accuracy 0.375\n",
      "... Iteration 131 ... Epoch 0.83 ... Loss 1.149 ... Accuracy 0.402\n",
      "... Iteration 141 ... Epoch 0.90 ... Loss 1.227 ... Accuracy 0.324\n",
      "... Iteration 151 ... Epoch 0.96 ... Loss 1.231 ... Accuracy 0.320\n",
      "Epoch 1 Starting @ 2024-04-25 13:58:27\n",
      "... Iteration 157 ... Epoch 1.00 ... Validation Loss 1.229 ... Validation Accuracy 0.322\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLP.pth\n",
      "... Iteration 158 ... Epoch 1.01 ... Loss 1.200 ... Accuracy 0.352\n",
      "... Iteration 168 ... Epoch 1.07 ... Loss 1.274 ... Accuracy 0.277\n",
      "... Iteration 178 ... Epoch 1.13 ... Loss 1.231 ... Accuracy 0.320\n",
      "... Iteration 188 ... Epoch 1.20 ... Loss 1.219 ... Accuracy 0.332\n",
      "... Iteration 198 ... Epoch 1.26 ... Loss 1.274 ... Accuracy 0.277\n",
      "... Iteration 208 ... Epoch 1.32 ... Loss 1.212 ... Accuracy 0.340\n",
      "... Iteration 218 ... Epoch 1.39 ... Loss 1.231 ... Accuracy 0.320\n",
      "... Iteration 228 ... Epoch 1.45 ... Loss 1.235 ... Accuracy 0.316\n",
      "... Iteration 238 ... Epoch 1.52 ... Loss 1.251 ... Accuracy 0.301\n",
      "... Iteration 248 ... Epoch 1.58 ... Loss 1.188 ... Accuracy 0.363\n",
      "... Iteration 257 ... Epoch 1.64 ... Validation Loss 1.196 ... Validation Accuracy 0.355\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLP.pth\n",
      "best validation loss so far!: 1.1959761381149292\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLPBEST.pth\n",
      "... Iteration 258 ... Epoch 1.64 ... Loss 1.204 ... Accuracy 0.348\n",
      "... Iteration 268 ... Epoch 1.71 ... Loss 1.239 ... Accuracy 0.312\n",
      "... Iteration 278 ... Epoch 1.77 ... Loss 1.200 ... Accuracy 0.352\n",
      "... Iteration 288 ... Epoch 1.83 ... Loss 1.188 ... Accuracy 0.363\n",
      "... Iteration 298 ... Epoch 1.90 ... Loss 1.212 ... Accuracy 0.340\n",
      "... Iteration 308 ... Epoch 1.96 ... Loss 1.266 ... Accuracy 0.285\n",
      "Epoch 2 Starting @ 2024-04-25 14:02:05\n",
      "... Iteration 314 ... Epoch 2.00 ... Validation Loss 1.202 ... Validation Accuracy 0.350\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_135100/SimpleMLP.pth\n",
      "... Iteration 315 ... Epoch 2.01 ... Loss 1.251 ... Accuracy 0.301\n",
      "... Iteration 325 ... Epoch 2.07 ... Loss 1.243 ... Accuracy 0.309\n",
      "... Iteration 335 ... Epoch 2.13 ... Loss 1.216 ... Accuracy 0.336\n",
      "... Iteration 345 ... Epoch 2.20 ... Loss 1.223 ... Accuracy 0.328\n",
      "... Iteration 355 ... Epoch 2.26 ... Loss 1.192 ... Accuracy 0.359\n",
      "... Iteration 365 ... Epoch 2.32 ... Loss 1.231 ... Accuracy 0.320\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "engine.train(epochs=2.5,report_interval=10,valid_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a simple Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open [simpleCNN](http://localhost:8888/edit/models/simpleCNN.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleCNN import SimpleCNN\n",
    "model_CNN=SimpleCNN(num_input_channels=38,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rotate_chan(x):\n",
    "    return np.transpose(x,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=WCH5Dataset(\"/project/rpp-blairt2k/machine_learning/data/TRISEP_data/NUPRISM.h5\",val_split=0.1,test_split=0.1,transform=rotate_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sticking to CPU\n",
      "Creating a directory for run dump: ../model_state_dumps/20240424_223542/\n"
     ]
    }
   ],
   "source": [
    "engine=Engine(model_CNN,dset,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: f_embed.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_embed.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2a.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2a.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2b.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2b.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3a.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3a.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3b.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3b.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_CNN.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Starting @ 2024-04-24 22:35:47\n",
      "tensor([[-0.2139,  0.2188,  0.1590],\n",
      "        [-0.2356,  0.1918,  0.1596]])\n",
      "... Iteration 0 ... Epoch 0.00 ... Validation Loss 1.004 ... Validation Accuracy 0.000\n",
      "Saved checkpoint as: ../model_state_dumps/20240424_223542/SimpleCNN.pth\n",
      "best validation loss so far!: 1.0036206245422363\n",
      "Saved checkpoint as: ../model_state_dumps/20240424_223542/SimpleCNNBEST.pth\n",
      "tensor([[-0.2629,  0.2181,  0.2056]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Unfortunately this seems to hang and not train\n",
    "%%time\n",
    "engine.train(epochs=5,report_interval=1,valid_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HKCA2 Python 3.x Kernel",
   "language": "python",
   "name": "hk_ca_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
