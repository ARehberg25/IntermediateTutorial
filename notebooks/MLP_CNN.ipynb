{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your first fully connected network and a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple fully connected network (a Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the paths and make a dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_handling import WCH5Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's make our model. We'll talk about \n",
    "  - model parameters\n",
    "  - inputs and the forward method\n",
    "  - Modules containing modules\n",
    "  - Sequential Module  \n",
    "  Lets open [simpleMLP](/edit/models/simpleMLP.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleMLP import SimpleMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP=SimpleMLP(num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's look at the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc5.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc5.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by default the parameters have `requires_grad` set - i.e. we will be able to obtain gradient of the loss function with respect to these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the [source](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear) for the linear module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters descend from the `Tensor` class. When `Parameter` object is instantiated as a member of a `Module` object class the parameter is added to `Module`s list of parameters automatically. This list and values are captured in the 'state dictionary' of a module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.0032, -0.0011, -0.0044,  ...,  0.0013,  0.0013,  0.0009],\n",
       "                      [ 0.0007, -0.0053, -0.0060,  ..., -0.0046, -0.0016,  0.0049],\n",
       "                      [ 0.0023,  0.0037,  0.0026,  ..., -0.0043, -0.0042,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0055, -0.0047, -0.0045,  ..., -0.0009,  0.0002, -0.0053],\n",
       "                      [-0.0003,  0.0016, -0.0061,  ...,  0.0019,  0.0059,  0.0034],\n",
       "                      [ 0.0032,  0.0011,  0.0052,  ..., -0.0009, -0.0064,  0.0013]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-4.4495e-03,  1.9484e-03, -2.3167e-03,  5.9439e-03,  1.8358e-04,\n",
       "                       5.6971e-03,  2.4905e-03,  5.5448e-03,  3.9652e-03, -4.6164e-03,\n",
       "                      -5.1608e-03,  1.3911e-03,  1.7667e-03,  5.9702e-03,  4.0597e-03,\n",
       "                       7.7379e-05, -4.9664e-03, -1.4828e-03, -1.8718e-03, -4.5426e-03,\n",
       "                       1.4716e-03,  4.9301e-03, -5.1270e-03,  3.8659e-03, -3.6461e-03,\n",
       "                       1.0682e-03, -3.0784e-03, -2.2955e-03,  5.0395e-04,  3.4510e-03,\n",
       "                      -3.0970e-03,  4.0065e-03, -5.1468e-03, -2.7897e-03, -6.0889e-03,\n",
       "                       3.6471e-04, -3.3925e-06, -2.5139e-03, -5.8374e-03,  3.0405e-03,\n",
       "                      -3.9506e-03, -1.7689e-03,  4.8051e-03,  2.8568e-03, -6.2665e-03,\n",
       "                      -1.7968e-03,  4.7992e-03, -2.1692e-03,  5.1638e-04, -5.6497e-04,\n",
       "                       1.4919e-03, -5.7744e-03, -1.9325e-03,  3.7892e-03,  3.0591e-03,\n",
       "                       6.1091e-03,  4.1972e-03,  5.3782e-03, -2.3418e-03,  9.7933e-04,\n",
       "                       4.4613e-03,  3.7165e-03,  5.3061e-03, -5.7309e-03, -3.3165e-03,\n",
       "                      -3.3527e-03, -3.8680e-03, -5.5794e-03, -5.4728e-03,  1.1658e-03,\n",
       "                      -6.3505e-03,  4.3059e-03, -2.8699e-03,  1.0793e-03,  1.9181e-03,\n",
       "                       5.7880e-03,  1.2679e-03,  1.4515e-03,  3.1915e-03,  5.3398e-03,\n",
       "                      -1.7482e-03, -1.6247e-03,  5.0819e-03,  3.0841e-03,  6.7076e-04,\n",
       "                       4.0105e-03, -1.0566e-04,  4.1019e-03,  4.9422e-03, -2.2271e-03,\n",
       "                       5.3004e-03,  4.0101e-03,  7.1600e-04,  1.8653e-03,  1.7172e-03,\n",
       "                      -9.9664e-06,  2.3156e-03, -1.6548e-03, -3.5264e-03,  3.4288e-03,\n",
       "                      -1.7553e-03, -4.8520e-03, -3.8610e-03,  4.7945e-03,  6.0957e-03,\n",
       "                       6.1941e-03,  5.5867e-03,  4.7986e-03,  5.7537e-03,  1.0962e-03,\n",
       "                      -3.7204e-03,  4.6250e-03, -2.1979e-03,  5.3151e-03,  1.8500e-03,\n",
       "                       5.5863e-03, -3.2063e-03, -1.5821e-03,  1.9262e-03,  5.0836e-03,\n",
       "                      -1.2573e-03,  3.0298e-03,  2.0322e-03,  5.7868e-04,  3.3174e-03,\n",
       "                      -7.7838e-04,  3.3258e-03, -5.4329e-03, -3.2490e-03,  2.3713e-03,\n",
       "                       3.7125e-03,  4.7005e-03, -5.3556e-03, -4.5965e-03, -1.8207e-03,\n",
       "                       2.2719e-03, -4.3102e-03,  1.9546e-03, -9.0231e-04, -2.8012e-03,\n",
       "                      -2.7600e-03,  1.1300e-03, -8.2929e-04, -4.4586e-04, -2.5315e-03,\n",
       "                       1.3796e-03, -9.7777e-04, -9.4660e-04, -1.8653e-03, -4.4320e-03,\n",
       "                       9.3346e-05,  4.0015e-03,  4.1509e-03, -7.5487e-04, -4.6780e-03,\n",
       "                      -6.0604e-04, -1.9917e-03,  3.4136e-03,  9.5945e-04,  5.8401e-03,\n",
       "                       1.6523e-03,  5.2203e-03, -1.0798e-03,  3.7116e-04, -1.5548e-03,\n",
       "                       5.5668e-03, -6.2179e-03,  4.8796e-04,  6.0757e-03,  3.9169e-03,\n",
       "                       5.4052e-03,  5.9421e-03, -5.0105e-03,  2.8191e-03, -4.9420e-03,\n",
       "                      -2.2495e-03,  4.3403e-03,  6.0163e-03,  3.7027e-03,  2.9626e-03,\n",
       "                      -6.0248e-03, -1.3901e-03, -2.0285e-03,  3.2782e-03,  3.1177e-03,\n",
       "                       9.8566e-04, -3.3817e-03, -5.8761e-03,  5.0759e-03,  5.3218e-03,\n",
       "                       5.9265e-03,  3.6779e-03, -5.9354e-03, -2.4108e-03,  1.1780e-03,\n",
       "                       3.2998e-03, -3.1984e-03,  2.5649e-03,  1.2710e-03, -1.4034e-03,\n",
       "                       3.9563e-03,  2.7690e-03, -1.6516e-03, -3.8625e-04, -6.2865e-03,\n",
       "                       3.8980e-04, -3.4750e-03,  5.6358e-03,  2.4101e-03,  2.5957e-04,\n",
       "                      -2.5051e-04, -3.7166e-03,  1.3032e-03,  9.3154e-04, -2.1221e-03,\n",
       "                      -9.1285e-04,  5.7500e-04, -2.9024e-03,  4.0466e-03, -5.7741e-03,\n",
       "                       3.5553e-03,  2.1984e-04,  6.2427e-03,  4.1069e-05, -4.0257e-03,\n",
       "                       6.8423e-04, -5.1322e-03,  1.4684e-03, -6.2984e-03, -5.2076e-03,\n",
       "                      -4.5825e-03,  3.7988e-05,  9.3429e-04,  4.8438e-03,  2.9361e-03,\n",
       "                      -2.9694e-03,  5.4664e-03, -2.5894e-03,  5.7173e-04,  2.5012e-03,\n",
       "                      -2.5764e-04,  4.1958e-03,  4.3775e-03,  5.2958e-03, -4.4053e-05,\n",
       "                      -1.1569e-03,  2.5055e-03, -9.5543e-04, -4.3908e-03,  5.0966e-03,\n",
       "                      -2.4973e-03, -5.4433e-03,  5.2350e-03, -3.2188e-03, -9.0129e-04,\n",
       "                      -1.3898e-03, -4.6257e-03,  3.8516e-05,  5.0884e-03,  4.7673e-03,\n",
       "                      -3.7948e-03,  3.1062e-03, -1.7091e-03, -2.5694e-03, -4.1595e-03,\n",
       "                       1.6375e-03, -4.2243e-03, -2.3180e-03,  6.3535e-03,  3.5135e-03,\n",
       "                      -6.1924e-03, -5.7673e-03,  5.6071e-03, -5.6120e-03,  6.2025e-03,\n",
       "                       3.8848e-03,  3.8131e-03,  4.7599e-03, -2.8383e-03, -8.5232e-04,\n",
       "                       4.4063e-03, -7.1468e-04,  5.7714e-03,  4.8265e-03, -4.6309e-03,\n",
       "                       5.4281e-03, -5.6917e-03,  2.6465e-03, -5.9405e-03, -1.4602e-04,\n",
       "                      -4.9904e-03, -2.1538e-04,  6.4002e-03, -3.2577e-03,  5.9983e-04,\n",
       "                      -1.5642e-03,  2.9471e-03, -2.9380e-03,  2.3790e-04, -2.5608e-03,\n",
       "                       5.8957e-04,  6.3845e-03,  1.6166e-03, -2.5346e-03,  4.5542e-03,\n",
       "                      -1.5883e-03,  2.7506e-03, -3.6990e-03,  4.2330e-03,  4.6483e-03,\n",
       "                       2.3337e-03, -5.2421e-03,  5.8282e-03, -2.9899e-03, -2.8109e-03,\n",
       "                      -2.6117e-03,  2.1672e-03, -7.0003e-04, -2.6620e-03,  5.6571e-03,\n",
       "                      -3.9256e-03,  2.8907e-03,  3.2506e-03,  5.3381e-03,  4.7871e-03,\n",
       "                      -1.4901e-03,  5.6388e-03, -5.5568e-03, -5.1037e-03, -6.4051e-03,\n",
       "                       5.8714e-03, -4.1953e-03,  3.4707e-03, -6.1098e-04, -5.1377e-03,\n",
       "                       6.1360e-03,  5.6836e-03, -4.5969e-03, -1.3158e-03,  2.3424e-03,\n",
       "                       3.3334e-03, -1.2796e-03, -4.0579e-03, -4.9268e-03,  5.2622e-03,\n",
       "                      -9.8765e-05,  1.4818e-03, -1.1768e-03, -3.3724e-03, -1.1780e-03,\n",
       "                      -3.1155e-03,  4.6240e-03,  3.0710e-03, -9.2343e-04, -1.0053e-03,\n",
       "                       8.8859e-04,  6.6554e-04,  2.7113e-03, -2.1256e-05, -3.5212e-03,\n",
       "                      -4.2604e-03,  9.9408e-05, -1.0272e-04, -1.9804e-03,  2.2395e-03,\n",
       "                       5.7736e-03, -6.3943e-03,  2.4644e-04,  3.7200e-03,  3.6691e-03,\n",
       "                      -5.3012e-03, -1.2416e-03,  1.5682e-03, -4.9769e-03,  1.7788e-03,\n",
       "                      -1.0667e-03,  3.6907e-03, -2.7118e-03, -6.0882e-03,  5.2086e-04,\n",
       "                      -2.7974e-03, -1.5766e-03, -1.2782e-03,  3.8449e-03, -3.7765e-03,\n",
       "                      -4.4775e-03,  4.8815e-03,  5.2141e-04, -5.9023e-03, -4.7298e-03,\n",
       "                       4.0583e-03,  3.8989e-04, -5.9181e-03,  1.0220e-03,  2.7720e-04,\n",
       "                       3.9661e-03,  1.6986e-04,  1.1667e-03,  1.6454e-03, -1.6478e-03,\n",
       "                      -9.1972e-04,  1.9611e-03, -6.4112e-03,  5.0071e-03,  4.4018e-03,\n",
       "                       5.3395e-03,  4.1101e-03, -4.7533e-03, -4.7684e-03, -1.8500e-03,\n",
       "                       5.1908e-03,  1.8436e-03, -1.0786e-03, -5.5718e-03, -1.0301e-03,\n",
       "                      -4.6704e-04, -1.8320e-03, -6.0180e-03, -6.0315e-03, -4.5740e-03,\n",
       "                       5.1297e-03,  3.0017e-03, -4.0444e-03,  2.7325e-03,  3.4591e-03,\n",
       "                      -6.2592e-03,  5.4571e-06, -3.6995e-03,  4.5366e-03, -1.7216e-03,\n",
       "                       1.9570e-05, -1.2587e-03,  7.3333e-04,  3.9621e-03, -6.1040e-03,\n",
       "                       4.8560e-03,  2.7234e-03,  1.5239e-04, -6.4002e-03,  2.7994e-03,\n",
       "                       1.2585e-03, -4.5043e-03, -2.6837e-03,  4.3291e-03,  5.4970e-03,\n",
       "                       1.7583e-03,  4.3277e-03, -6.5986e-04, -2.4704e-03, -1.6858e-03,\n",
       "                      -1.7401e-03,  4.8134e-03,  3.9196e-03, -1.2426e-03, -4.0859e-03,\n",
       "                      -2.5519e-04,  6.3256e-04, -4.3361e-03, -4.6365e-03,  4.4508e-03,\n",
       "                      -1.1978e-03,  4.7123e-03,  1.8867e-03, -3.0623e-04, -1.6943e-03,\n",
       "                       5.6032e-03, -1.7411e-03, -1.4833e-04, -4.1765e-03,  4.1597e-03,\n",
       "                       1.2136e-03,  3.7594e-03,  6.2430e-03,  5.7542e-03, -1.8878e-03,\n",
       "                      -4.3903e-03,  5.0023e-03,  2.9523e-04,  5.2860e-03,  1.6188e-03,\n",
       "                      -3.0056e-03,  6.0850e-03,  2.2380e-03, -6.1808e-03, -5.4637e-03,\n",
       "                      -3.9518e-03, -9.4968e-04,  2.1570e-03, -3.5193e-05,  2.7917e-03,\n",
       "                       2.2381e-03, -4.4964e-03,  8.1842e-04,  5.6163e-03, -3.9315e-03,\n",
       "                       2.7959e-03,  2.3406e-03,  8.0123e-04,  2.8476e-03,  5.3700e-03,\n",
       "                       4.9579e-03,  5.5690e-03, -1.3783e-03,  3.6786e-04,  4.0080e-03,\n",
       "                       2.6477e-04, -4.3445e-03,  1.2535e-04, -3.3848e-03, -4.6911e-03,\n",
       "                       5.7084e-03,  5.1603e-03,  2.8216e-03, -1.2182e-03,  1.5481e-03,\n",
       "                      -4.4712e-03, -6.2796e-04,  2.5325e-03,  3.2921e-04, -5.9727e-03,\n",
       "                       3.4831e-03,  3.5003e-03,  5.5368e-04,  8.5519e-04,  5.5072e-03,\n",
       "                      -4.4111e-03, -5.6280e-03,  3.2332e-03, -5.3690e-03, -1.4267e-03,\n",
       "                      -3.1890e-03,  2.0325e-03, -2.8990e-03, -5.8802e-03, -2.7336e-03,\n",
       "                      -5.7090e-04,  2.3026e-03, -3.9546e-03,  5.2078e-03, -7.0311e-04,\n",
       "                       1.2605e-03,  3.9321e-03, -2.4779e-03, -3.0991e-03,  4.2514e-03,\n",
       "                       6.3664e-03, -2.8319e-03,  4.3741e-04, -6.1302e-03,  3.6305e-03,\n",
       "                       4.5648e-03,  5.5351e-03,  2.6130e-03, -1.1661e-04,  5.8010e-03,\n",
       "                      -3.7465e-03, -1.2942e-03,  2.3995e-03, -2.7200e-03, -5.7346e-03,\n",
       "                       3.9263e-03, -3.1580e-03,  1.2610e-03,  5.1095e-03,  3.3293e-03,\n",
       "                      -9.8844e-04, -1.7673e-03,  2.0756e-03, -2.1621e-03, -1.3677e-03,\n",
       "                      -4.6208e-03, -5.5433e-03,  1.2211e-04, -2.0605e-04,  1.6866e-03,\n",
       "                      -7.4304e-04, -2.1422e-03, -2.3281e-03, -2.9004e-03,  5.7417e-03,\n",
       "                      -1.8876e-03, -2.2600e-03,  5.6900e-03,  2.7440e-03, -1.7925e-03,\n",
       "                       9.4734e-04, -2.9097e-03,  2.2696e-05, -5.4628e-03,  4.8123e-03,\n",
       "                      -3.6464e-03,  3.6432e-03, -2.4971e-03,  2.7377e-03, -1.2085e-03,\n",
       "                       4.3121e-03, -7.4858e-04,  3.7882e-03,  5.2784e-04, -5.3659e-03,\n",
       "                       5.6938e-03, -5.2460e-03,  2.2405e-03, -6.0749e-03,  5.3657e-03,\n",
       "                       3.4096e-03,  2.7635e-03, -1.3691e-03,  2.6340e-03, -2.6770e-03,\n",
       "                       4.2117e-04,  2.6962e-03, -4.6978e-05, -4.1191e-03, -6.3525e-03,\n",
       "                      -4.8252e-03,  3.6995e-03, -3.6496e-03,  1.8020e-03,  3.9871e-04,\n",
       "                      -4.7409e-04, -4.2006e-03,  4.0806e-03, -1.0764e-03,  2.1736e-03,\n",
       "                       1.5753e-03,  6.0190e-03,  6.1297e-03,  1.7369e-03, -1.5325e-04,\n",
       "                      -2.5679e-03, -6.3999e-03,  3.0301e-03,  4.9829e-03,  1.4344e-04,\n",
       "                       6.3748e-03,  4.5732e-03, -3.4319e-03,  2.7143e-03,  3.0183e-03,\n",
       "                      -5.9372e-04, -6.8359e-04,  1.6282e-03, -2.5211e-04,  4.8995e-03,\n",
       "                      -1.7926e-03, -2.4164e-04, -6.3462e-03,  6.3331e-03,  2.0685e-03,\n",
       "                       1.3002e-03,  9.2249e-04,  5.5373e-03, -1.2922e-03,  4.7153e-03,\n",
       "                       3.5455e-04, -3.0031e-03,  2.3412e-03, -3.6745e-03, -5.4035e-03,\n",
       "                      -1.6075e-03,  2.2443e-03, -2.3865e-03,  3.1043e-03,  9.5166e-04,\n",
       "                       3.4279e-03,  1.4048e-03, -2.2402e-03, -3.5494e-03, -4.1314e-03,\n",
       "                      -1.2202e-03,  2.4475e-03,  4.3789e-03,  5.1289e-03, -2.0453e-03,\n",
       "                       1.2525e-03,  3.3323e-03,  2.1414e-03, -2.1676e-03, -3.1325e-03,\n",
       "                       6.3917e-03,  4.0338e-03,  6.1153e-05,  2.7997e-03,  5.8623e-03,\n",
       "                       1.5702e-04,  2.7143e-04, -3.6870e-03, -3.2107e-03,  6.0225e-03,\n",
       "                       1.7403e-03, -2.3868e-03, -4.8127e-03,  2.1323e-03, -2.5027e-03,\n",
       "                      -1.0460e-03, -1.5950e-03,  4.3205e-03, -4.0698e-03, -3.2342e-03,\n",
       "                       4.3530e-03,  3.3199e-03, -2.8583e-03, -1.0376e-03, -2.2949e-03,\n",
       "                       3.1795e-03,  2.0496e-03,  4.4739e-04,  4.4530e-03, -2.1755e-03,\n",
       "                       2.3508e-03,  5.4421e-03,  4.3453e-03,  6.3278e-03,  2.6476e-03,\n",
       "                      -1.0611e-03,  4.7266e-03, -3.1795e-03,  1.1741e-03,  6.3879e-03,\n",
       "                       6.5425e-04,  5.2639e-03,  2.5906e-04,  5.8144e-03, -5.8703e-03,\n",
       "                       5.0243e-03,  2.7634e-03, -1.5593e-03, -6.7717e-04, -4.6630e-03,\n",
       "                      -2.2713e-03, -3.5700e-03,  5.8150e-03, -3.8174e-03, -3.1791e-03,\n",
       "                      -2.2742e-03,  4.3918e-03,  3.7206e-03, -4.8735e-03,  4.0580e-03,\n",
       "                      -1.4316e-03, -2.6617e-03,  2.3617e-04,  3.7951e-04,  5.1489e-03,\n",
       "                       5.1260e-03,  6.3299e-03,  1.7994e-03, -5.0405e-03,  7.2115e-04,\n",
       "                      -2.3246e-03,  5.3903e-03, -3.4370e-03,  1.3848e-03,  5.8309e-03,\n",
       "                      -2.8019e-03,  2.1421e-03, -1.0146e-03,  2.8036e-03, -6.2709e-03,\n",
       "                      -3.4051e-03, -5.1891e-03,  2.9839e-03,  2.4155e-03, -4.2018e-03,\n",
       "                       2.4627e-03,  5.7288e-03,  2.3036e-03,  1.9441e-03, -5.5746e-03,\n",
       "                      -3.4089e-03, -2.3568e-03,  4.5864e-03, -4.1315e-04, -1.0785e-03,\n",
       "                      -5.1460e-03, -5.0717e-03, -6.2579e-03,  3.1402e-04,  6.3143e-03,\n",
       "                       4.0358e-03,  4.0063e-03,  2.9068e-03,  1.3842e-03,  2.8850e-03,\n",
       "                      -4.3539e-03, -4.2327e-03,  3.4637e-03, -3.8732e-03, -4.6896e-04,\n",
       "                       4.6466e-03, -2.5264e-03,  5.4299e-04, -1.6798e-04,  3.9742e-03,\n",
       "                       4.8245e-03,  5.9934e-03,  4.3349e-03,  5.0566e-03,  1.7201e-04,\n",
       "                       3.6550e-03, -6.0336e-03, -5.7031e-03, -4.5687e-04, -8.6385e-04,\n",
       "                      -3.0117e-03,  2.2561e-03, -2.4246e-03, -4.2753e-03,  1.2734e-03,\n",
       "                       2.7926e-03, -2.1643e-03,  5.1269e-03,  1.5390e-03,  5.1002e-03,\n",
       "                      -5.6707e-03,  2.4816e-03, -2.4628e-03,  6.0537e-03, -5.6687e-03,\n",
       "                       3.7145e-03,  9.2503e-04, -4.9089e-03, -1.6801e-03, -5.2145e-04,\n",
       "                       9.3367e-04,  3.2447e-04,  3.6606e-03, -2.9114e-03,  6.6438e-04,\n",
       "                       5.7594e-03, -5.5206e-03, -6.3938e-04, -3.2694e-03,  5.6688e-03,\n",
       "                      -3.8327e-03,  5.8985e-05,  2.8031e-03, -3.9464e-03,  6.1228e-04,\n",
       "                       5.5248e-03, -3.8440e-03, -3.1412e-03,  6.9590e-05,  6.0209e-04,\n",
       "                       5.7389e-03,  1.9781e-03, -1.2733e-03,  1.2512e-03, -4.0791e-03,\n",
       "                      -7.7864e-04, -3.0079e-03, -3.4954e-03, -4.1051e-03, -6.2923e-03,\n",
       "                       1.4835e-03,  4.1753e-03,  6.6269e-05, -3.7222e-03,  1.4558e-03,\n",
       "                       3.2130e-03,  2.9148e-03,  1.5423e-03, -2.0020e-03, -1.6143e-03,\n",
       "                      -1.4701e-03, -4.2751e-03, -7.4373e-04, -3.6240e-03, -3.6429e-03,\n",
       "                      -3.0906e-03, -4.0353e-03,  2.4570e-04, -3.7244e-03, -3.4989e-03,\n",
       "                      -2.1490e-03,  5.5517e-04,  1.3794e-03,  5.8583e-03, -4.9824e-03,\n",
       "                       4.5160e-03, -6.1370e-03,  1.9941e-03,  2.7308e-03, -3.5033e-03,\n",
       "                      -6.2250e-04,  5.2523e-03, -5.1240e-03,  2.7091e-03, -5.6420e-03,\n",
       "                      -1.1282e-03, -5.6476e-03,  1.5730e-03, -5.5051e-05,  4.0517e-03,\n",
       "                       2.2618e-03,  4.1001e-03,  2.1379e-03,  3.2435e-03,  3.1663e-03,\n",
       "                       4.2370e-03,  2.4300e-03,  8.6113e-04,  2.3925e-03, -4.9492e-03,\n",
       "                       2.3668e-03,  3.9606e-03,  1.7726e-03, -4.2212e-03, -8.5841e-04,\n",
       "                      -3.3107e-03, -2.6990e-03, -3.6681e-03, -3.2899e-03, -2.9741e-03,\n",
       "                      -2.3696e-03, -1.2124e-03, -2.2414e-03,  3.6577e-03,  3.2026e-03,\n",
       "                       3.1604e-03, -2.7353e-03, -2.8731e-03,  3.0924e-03, -1.2900e-03,\n",
       "                       3.6140e-03,  4.5066e-03,  4.2316e-03,  6.0972e-03,  5.8307e-03,\n",
       "                       9.8272e-04, -3.4299e-03,  3.2320e-04, -1.0788e-03,  3.8140e-03,\n",
       "                      -6.0803e-03,  4.6812e-03, -7.7371e-04,  1.4435e-03,  6.2537e-03,\n",
       "                       1.9931e-03, -2.2332e-03, -1.8034e-03, -1.7146e-03, -6.1227e-03,\n",
       "                      -6.0314e-03,  1.4573e-03,  1.9571e-03, -2.0019e-03, -4.2617e-04,\n",
       "                      -4.5420e-03, -6.2003e-03,  4.8749e-03, -2.7475e-03,  1.7966e-03,\n",
       "                       4.1716e-03,  1.1548e-03,  2.3688e-03, -6.2493e-03, -3.2272e-03,\n",
       "                      -1.3236e-03,  9.8878e-04, -5.1061e-03, -6.3917e-03,  1.5875e-03,\n",
       "                       2.7077e-03,  4.9061e-03,  5.6035e-03, -6.3135e-03, -1.9848e-03,\n",
       "                      -5.1088e-04,  3.9547e-04])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0309,  0.0318, -0.0030,  ..., -0.0088,  0.0112, -0.0251],\n",
       "                      [ 0.0233, -0.0112,  0.0208,  ..., -0.0082,  0.0260,  0.0257],\n",
       "                      [ 0.0214,  0.0162, -0.0134,  ..., -0.0301,  0.0304,  0.0075],\n",
       "                      ...,\n",
       "                      [-0.0254, -0.0170, -0.0261,  ..., -0.0191, -0.0097, -0.0016],\n",
       "                      [-0.0073, -0.0022,  0.0212,  ..., -0.0168,  0.0001,  0.0162],\n",
       "                      [ 0.0279,  0.0004, -0.0260,  ...,  0.0046, -0.0261, -0.0186]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-1.5926e-02, -8.9370e-03,  2.3344e-02,  1.3937e-02,  2.6369e-02,\n",
       "                      -1.5920e-02,  1.3424e-02,  6.3328e-03,  6.9494e-03, -2.5605e-02,\n",
       "                       2.0869e-02,  2.3032e-02,  1.9369e-02, -3.6345e-03,  1.6533e-02,\n",
       "                      -2.3072e-02,  6.8045e-03,  2.7670e-04, -3.1995e-02, -6.1233e-03,\n",
       "                       1.1360e-02,  2.9613e-02,  3.0655e-02,  1.7502e-02, -1.9575e-02,\n",
       "                      -3.1846e-02, -9.9241e-03,  4.4017e-03, -3.2295e-03, -1.8259e-02,\n",
       "                       6.6787e-03, -1.0241e-02,  1.7481e-02,  3.1101e-02, -2.1091e-03,\n",
       "                       8.8964e-03, -2.7093e-02, -2.7266e-02, -3.2019e-02, -4.7358e-03,\n",
       "                      -1.6536e-02, -3.1146e-02,  2.2512e-02, -7.2951e-03,  2.3605e-02,\n",
       "                      -1.4245e-02,  2.6303e-02,  2.8816e-03, -6.4750e-03, -2.0401e-02,\n",
       "                       1.2499e-02, -1.3280e-02, -9.8789e-03,  1.0532e-02, -8.3634e-03,\n",
       "                       8.3781e-03,  2.3985e-02, -2.4157e-02, -2.4143e-02, -1.3296e-03,\n",
       "                       1.0456e-02, -7.7739e-03,  1.1275e-02, -2.6618e-02,  3.3003e-03,\n",
       "                       2.0932e-02,  2.4668e-04, -2.3338e-02, -3.0974e-02, -1.9942e-02,\n",
       "                       1.7782e-02, -4.6622e-03,  2.7230e-02, -1.4207e-02, -8.1475e-03,\n",
       "                      -5.1591e-03, -2.9101e-02, -3.1729e-02,  5.0205e-03,  3.9437e-03,\n",
       "                       1.8758e-02,  1.5113e-02,  1.0794e-02,  1.3090e-03, -2.8419e-02,\n",
       "                       2.7660e-02, -7.2335e-03,  5.4746e-03, -4.6235e-03,  1.6210e-03,\n",
       "                      -2.6968e-02, -8.0332e-03, -2.3303e-02, -1.1048e-04,  3.1548e-02,\n",
       "                       2.1117e-03, -2.0767e-02,  3.0069e-02, -7.7425e-03,  3.0362e-02,\n",
       "                       1.7116e-03,  1.0277e-02,  3.1692e-02,  2.0236e-02, -1.9209e-02,\n",
       "                      -2.9250e-02,  2.0194e-02,  2.6534e-02,  1.2534e-02,  6.2617e-03,\n",
       "                       2.9482e-02, -3.1775e-02,  5.8776e-03, -1.7165e-02,  4.1948e-03,\n",
       "                       8.8759e-03, -1.8653e-02, -1.2199e-03, -3.0849e-02,  1.5297e-02,\n",
       "                       1.4065e-02,  2.4715e-02,  2.6027e-02,  1.7003e-02, -3.6900e-03,\n",
       "                      -1.7165e-03,  2.3003e-02, -1.8564e-02, -2.9192e-03,  9.6731e-03,\n",
       "                      -1.2172e-02,  9.8007e-03, -2.9508e-02,  6.0542e-03,  2.2229e-02,\n",
       "                       1.3189e-02, -7.7584e-03, -1.9509e-02,  6.3943e-03, -3.6255e-03,\n",
       "                      -2.2453e-03, -1.6629e-02, -1.3644e-02, -1.9391e-02,  2.3450e-02,\n",
       "                       7.5160e-04, -1.4624e-02, -1.1472e-02, -3.1336e-02, -5.0125e-03,\n",
       "                      -1.4988e-02,  2.6809e-02,  1.2059e-02,  2.2963e-02, -1.2718e-02,\n",
       "                      -2.8708e-02,  1.8482e-03,  2.0307e-02,  2.8872e-02,  2.1812e-02,\n",
       "                      -2.5883e-03,  1.3654e-02,  1.6319e-02, -2.0096e-02, -2.2924e-02,\n",
       "                       3.0484e-02,  5.9993e-03,  2.7224e-02,  1.9937e-02,  1.5763e-02,\n",
       "                      -4.9092e-03, -6.3541e-03, -1.2857e-02,  2.3710e-02, -1.7577e-02,\n",
       "                       1.4990e-03,  2.8736e-02,  2.7541e-02,  2.1042e-03, -1.6304e-02,\n",
       "                       2.1235e-02,  2.3859e-03,  2.9826e-02,  9.7808e-03,  4.9807e-03,\n",
       "                      -9.7307e-03,  8.0454e-03, -2.3821e-02,  1.5119e-04, -1.3341e-02,\n",
       "                       3.1483e-02,  1.8811e-02, -3.1543e-02, -9.5170e-03,  2.8663e-02,\n",
       "                       2.3902e-02, -2.9692e-02, -2.7412e-02, -1.0203e-03,  1.9679e-02,\n",
       "                      -2.6833e-02,  9.5703e-03,  4.8122e-03,  2.5372e-02,  2.0696e-02,\n",
       "                      -3.0961e-03,  1.2285e-02,  2.4849e-03,  5.6067e-03, -2.4093e-02,\n",
       "                       8.6240e-03, -1.6192e-02,  1.7491e-03, -2.6379e-03,  1.1653e-02,\n",
       "                      -1.6784e-02, -2.8439e-02, -2.6849e-02, -8.6250e-03, -1.6970e-02,\n",
       "                      -1.8634e-02, -3.2081e-03,  3.1383e-02, -9.6880e-04,  1.7972e-03,\n",
       "                       6.5555e-03,  1.1715e-02, -2.6997e-02,  5.4016e-03, -8.0401e-03,\n",
       "                      -2.0891e-02,  1.7181e-02,  1.0153e-02, -1.1050e-02,  1.5003e-02,\n",
       "                      -1.4615e-02,  2.5912e-02, -8.1141e-03,  2.4482e-02,  1.2535e-02,\n",
       "                      -1.6674e-02, -1.2102e-02, -1.3892e-02, -4.4869e-03, -3.9199e-03,\n",
       "                      -1.9307e-02,  8.4304e-03,  5.6809e-03, -1.6428e-02, -4.8788e-03,\n",
       "                      -2.1931e-02,  1.7860e-02,  1.4314e-02, -1.1094e-02,  9.4818e-03,\n",
       "                      -2.4575e-02, -1.9511e-02, -9.8295e-03,  1.9400e-02, -1.6442e-02,\n",
       "                       1.8073e-02, -2.2537e-02,  5.5495e-03, -8.2303e-03, -2.1793e-02,\n",
       "                      -2.4339e-02,  1.7982e-02,  1.1928e-02, -1.7955e-03,  1.8488e-02,\n",
       "                      -2.8145e-02, -2.3743e-02,  3.6785e-03, -1.7729e-02, -1.0543e-02,\n",
       "                       1.9445e-02, -2.3373e-02,  1.1233e-02, -3.1669e-02,  1.1145e-02,\n",
       "                      -1.9515e-02, -1.1531e-02,  1.9306e-02,  6.0297e-03, -1.6697e-02,\n",
       "                      -6.3308e-03,  2.9305e-02, -2.8235e-02, -1.3018e-02,  6.0552e-03,\n",
       "                       2.8344e-02,  2.9030e-02,  9.0394e-03,  5.2381e-03,  2.9318e-02,\n",
       "                      -2.9753e-02,  2.1964e-02,  2.3899e-04,  1.6840e-02, -8.3289e-03,\n",
       "                      -1.3999e-02,  1.1002e-02,  2.6148e-02,  1.9023e-03,  1.3449e-02,\n",
       "                      -1.2449e-02, -1.7233e-02, -4.2483e-03,  2.9023e-03,  5.5477e-03,\n",
       "                      -1.0189e-02, -1.3690e-02,  2.4315e-02,  3.0387e-02, -2.3835e-02,\n",
       "                      -1.7377e-03,  6.3666e-03, -1.8664e-02, -1.6137e-02,  2.5355e-03,\n",
       "                       1.2254e-02,  1.9663e-02,  2.0351e-03,  3.1989e-02,  3.0065e-02,\n",
       "                       6.6110e-03, -3.1961e-02, -1.2124e-02,  9.1321e-03, -1.0630e-02,\n",
       "                      -7.1324e-03,  1.4944e-02,  5.7915e-03, -1.0733e-02, -1.4643e-02,\n",
       "                       8.7985e-03, -1.6687e-02, -1.4901e-02, -2.1187e-02, -1.8562e-02,\n",
       "                       1.3335e-02, -2.8506e-02,  2.2467e-02, -3.4868e-03, -1.4251e-02,\n",
       "                       2.5870e-02,  3.0985e-03,  2.0043e-02,  1.7252e-02,  2.1146e-02,\n",
       "                       2.9462e-02,  1.7220e-02,  1.3053e-02,  2.9256e-02, -9.0124e-03,\n",
       "                      -1.2679e-02,  1.5940e-02,  1.8663e-03, -1.5900e-02,  2.1505e-02,\n",
       "                      -5.2645e-04, -2.2875e-02, -9.4648e-03, -3.7352e-03,  1.2644e-02,\n",
       "                       1.7312e-02,  2.4655e-02, -5.0620e-03, -1.6839e-02, -1.2593e-02,\n",
       "                      -9.7874e-04, -2.8532e-02,  2.2279e-02,  2.7531e-02,  2.5820e-02,\n",
       "                       1.0897e-02,  2.0230e-02, -1.0991e-02,  1.5257e-02,  1.7132e-02,\n",
       "                      -4.0706e-03, -1.1464e-02, -3.1377e-02,  1.8052e-02,  2.4785e-03,\n",
       "                       2.1618e-02, -1.8879e-02,  5.3119e-03, -1.4884e-02,  7.1298e-03,\n",
       "                      -2.2134e-02,  6.3842e-03, -1.4963e-02, -2.1058e-02, -2.4190e-02,\n",
       "                      -2.0272e-02, -1.7452e-02, -3.0250e-02, -8.1500e-03, -9.5005e-03,\n",
       "                      -1.2206e-02,  2.1056e-02, -1.8564e-02,  1.7009e-02,  3.0979e-02,\n",
       "                       6.5725e-03,  2.8700e-02, -2.2936e-02,  2.5923e-02, -1.3728e-02,\n",
       "                       1.1865e-02, -2.9076e-02,  2.3718e-02,  1.0665e-03, -3.1630e-02,\n",
       "                      -5.1341e-03,  2.0437e-02, -3.1645e-02, -1.2219e-02,  1.7245e-02,\n",
       "                      -3.8809e-03,  4.7050e-03,  1.7375e-02,  5.0468e-05, -1.7512e-02,\n",
       "                       2.8862e-02,  1.6731e-02,  1.7220e-03, -8.0754e-04,  2.1145e-02,\n",
       "                      -1.9357e-03, -2.9825e-02, -2.2710e-02, -2.9990e-02,  3.1948e-02,\n",
       "                      -2.4780e-02,  2.7416e-03,  1.2661e-02, -2.2702e-02,  2.1516e-02,\n",
       "                       4.8929e-03,  1.1573e-02, -1.7800e-03, -1.7201e-02,  1.0282e-02,\n",
       "                       2.7275e-02,  6.8646e-03, -2.1114e-02,  3.2054e-02, -4.8976e-03,\n",
       "                       3.1205e-02, -2.5035e-03, -2.1615e-02, -2.0719e-02,  2.9442e-02,\n",
       "                       2.7167e-02, -2.3072e-02, -3.1470e-02,  8.6579e-03,  1.2941e-02,\n",
       "                      -2.9344e-02, -3.8269e-03,  2.2785e-02,  1.2773e-02, -2.5434e-02,\n",
       "                       1.7810e-02,  1.2712e-02,  2.5920e-02, -8.4814e-03, -4.6859e-03,\n",
       "                      -2.8661e-02, -3.5360e-03, -1.3444e-02,  2.0581e-02,  2.8308e-02,\n",
       "                       3.1801e-02, -2.5119e-02,  2.1973e-02, -4.7850e-03,  1.7280e-02,\n",
       "                       1.6170e-02,  1.5260e-02,  9.4006e-03, -2.6775e-02, -5.8490e-03,\n",
       "                       3.1784e-02])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0040, -0.0400, -0.0211,  ..., -0.0445, -0.0244, -0.0133],\n",
       "                      [ 0.0189,  0.0443, -0.0088,  ...,  0.0118,  0.0198,  0.0057],\n",
       "                      [ 0.0357, -0.0073,  0.0116,  ...,  0.0314, -0.0280, -0.0072],\n",
       "                      ...,\n",
       "                      [ 0.0040, -0.0009,  0.0382,  ...,  0.0189, -0.0222, -0.0303],\n",
       "                      [-0.0110,  0.0422, -0.0437,  ...,  0.0391,  0.0439, -0.0195],\n",
       "                      [-0.0085,  0.0423, -0.0316,  ...,  0.0071, -0.0148, -0.0346]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0044, -0.0065,  0.0165,  0.0164,  0.0443, -0.0320,  0.0364, -0.0352,\n",
       "                      -0.0267,  0.0020,  0.0159, -0.0315,  0.0215, -0.0017,  0.0337,  0.0003,\n",
       "                       0.0240, -0.0354, -0.0097,  0.0301, -0.0124,  0.0347, -0.0204,  0.0070,\n",
       "                       0.0379,  0.0163,  0.0175, -0.0251, -0.0359,  0.0068, -0.0237,  0.0258,\n",
       "                      -0.0392,  0.0069, -0.0308,  0.0361, -0.0180,  0.0021,  0.0167,  0.0440,\n",
       "                      -0.0448,  0.0075,  0.0238,  0.0349, -0.0431,  0.0061,  0.0226,  0.0197,\n",
       "                      -0.0254, -0.0273, -0.0252,  0.0384,  0.0042,  0.0142,  0.0236, -0.0235,\n",
       "                      -0.0041, -0.0363, -0.0226, -0.0183, -0.0349, -0.0320,  0.0042,  0.0420,\n",
       "                      -0.0035, -0.0140, -0.0049, -0.0376, -0.0079,  0.0031,  0.0425,  0.0311,\n",
       "                      -0.0338, -0.0249,  0.0365, -0.0035, -0.0260, -0.0426,  0.0372,  0.0300,\n",
       "                       0.0129, -0.0275,  0.0439, -0.0409,  0.0021,  0.0333,  0.0428,  0.0261,\n",
       "                       0.0330,  0.0204,  0.0003,  0.0066, -0.0429,  0.0140,  0.0109,  0.0350,\n",
       "                      -0.0141, -0.0397,  0.0153, -0.0065,  0.0164, -0.0177,  0.0422,  0.0145,\n",
       "                      -0.0083, -0.0181,  0.0011, -0.0381,  0.0100, -0.0083,  0.0252, -0.0038,\n",
       "                      -0.0128, -0.0179,  0.0453,  0.0357, -0.0428, -0.0163, -0.0026,  0.0136,\n",
       "                       0.0230,  0.0185,  0.0322, -0.0429, -0.0380, -0.0409, -0.0421,  0.0319,\n",
       "                      -0.0218, -0.0183,  0.0193, -0.0389,  0.0428, -0.0025, -0.0131, -0.0127,\n",
       "                      -0.0421, -0.0035, -0.0118,  0.0431, -0.0224, -0.0286,  0.0090, -0.0194,\n",
       "                      -0.0248, -0.0259, -0.0451, -0.0430,  0.0095,  0.0234,  0.0281,  0.0297,\n",
       "                      -0.0126, -0.0058,  0.0238,  0.0386, -0.0087,  0.0246,  0.0083, -0.0337])),\n",
       "             ('fc4.weight',\n",
       "              tensor([[ 0.0250,  0.0285,  0.0260,  ..., -0.0570, -0.0091, -0.0021],\n",
       "                      [-0.0743, -0.0275,  0.0315,  ...,  0.0315, -0.0236,  0.0372],\n",
       "                      [-0.0165,  0.0342,  0.0090,  ..., -0.0523, -0.0595, -0.0104],\n",
       "                      ...,\n",
       "                      [ 0.0615, -0.0173, -0.0552,  ..., -0.0126, -0.0446,  0.0089],\n",
       "                      [ 0.0102, -0.0485,  0.0025,  ..., -0.0514, -0.0377,  0.0531],\n",
       "                      [ 0.0600, -0.0096,  0.0610,  ...,  0.0278,  0.0305, -0.0526]])),\n",
       "             ('fc4.bias',\n",
       "              tensor([-0.0008, -0.0726,  0.0615, -0.0007, -0.0165, -0.0712, -0.0510,  0.0363,\n",
       "                       0.0539, -0.0130, -0.0553,  0.0697, -0.0323, -0.0531, -0.0473,  0.0644,\n",
       "                      -0.0412,  0.0105,  0.0145,  0.0441, -0.0355,  0.0685,  0.0787,  0.0212,\n",
       "                       0.0714,  0.0767,  0.0707, -0.0332, -0.0347,  0.0415, -0.0675,  0.0424,\n",
       "                       0.0525, -0.0117, -0.0155, -0.0201,  0.0655, -0.0038, -0.0255, -0.0541])),\n",
       "             ('fc5.weight',\n",
       "              tensor([[ 0.0411, -0.0925,  0.0694,  0.1275,  0.1052, -0.1377,  0.1085, -0.0024,\n",
       "                        0.0064,  0.1406,  0.0374, -0.0745, -0.1339,  0.0482,  0.1388,  0.1308,\n",
       "                       -0.0675,  0.0363,  0.0066, -0.0629, -0.0353,  0.1432, -0.1180, -0.1033,\n",
       "                        0.1425,  0.0464,  0.0221,  0.0268, -0.1338,  0.0145,  0.0114, -0.0631,\n",
       "                        0.0259,  0.0248,  0.1039, -0.1204, -0.0105, -0.0854,  0.1430, -0.0492],\n",
       "                      [ 0.0996,  0.0738, -0.0274,  0.0546,  0.0050, -0.0575,  0.1474,  0.0982,\n",
       "                       -0.0992,  0.0790,  0.0052,  0.0498, -0.0818, -0.1144,  0.0650, -0.1253,\n",
       "                        0.0899,  0.1107,  0.1104,  0.0308, -0.0953, -0.0932,  0.0587, -0.1162,\n",
       "                       -0.1388, -0.0301, -0.1342,  0.1279, -0.1484,  0.0356,  0.0191, -0.0190,\n",
       "                       -0.0189, -0.0432,  0.1230,  0.1288, -0.0232,  0.1200,  0.0472, -0.0423],\n",
       "                      [ 0.0861, -0.0088, -0.0166,  0.0830,  0.1516, -0.0287, -0.0075,  0.0255,\n",
       "                       -0.0446,  0.0304, -0.1407,  0.0289,  0.1487, -0.0040,  0.0156,  0.1364,\n",
       "                       -0.0586,  0.1353, -0.1435,  0.1449,  0.1025, -0.0724,  0.0392,  0.0415,\n",
       "                       -0.0416, -0.1472,  0.1289,  0.0390, -0.0876, -0.0746,  0.0856, -0.0710,\n",
       "                        0.0544, -0.1526,  0.1515, -0.1332,  0.0106,  0.1520,  0.0855,  0.0603]])),\n",
       "             ('fc5.bias', tensor([0.0849, 0.0644, 0.0502]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that the values are not 0? This is actually by design - by default that initialization follows an accepted scheme - but many strategies are possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at sequential version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleMLP import SimpleMLPSEQ\n",
    "model_MLPSEQ=SimpleMLPSEQ(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: _sequence.0.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.0.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.6.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.6.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.8.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: _sequence.8.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLPSEQ.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('_sequence.0.weight', tensor([[-0.0021,  0.0013, -0.0044,  ...,  0.0021,  0.0038, -0.0047],\n",
      "        [ 0.0030, -0.0041, -0.0002,  ..., -0.0013,  0.0025, -0.0054],\n",
      "        [ 0.0055, -0.0060,  0.0051,  ...,  0.0003,  0.0029,  0.0002],\n",
      "        ...,\n",
      "        [-0.0063,  0.0048,  0.0048,  ..., -0.0044,  0.0014,  0.0005],\n",
      "        [-0.0024,  0.0060,  0.0037,  ..., -0.0014,  0.0045,  0.0024],\n",
      "        [-0.0020,  0.0013,  0.0041,  ...,  0.0027,  0.0012, -0.0052]])), ('_sequence.0.bias', tensor([ 3.9647e-03,  2.2322e-03, -5.9673e-03,  5.2527e-03,  1.0601e-04,\n",
      "         5.0981e-03, -5.2769e-03, -3.0881e-03,  3.6165e-03,  3.5715e-03,\n",
      "         5.4864e-03, -3.8988e-03, -5.0683e-03, -4.7195e-03, -2.5161e-03,\n",
      "         3.5732e-04,  8.2366e-05, -6.3135e-03, -4.4399e-03,  5.1865e-03,\n",
      "        -5.0972e-03, -5.9398e-04, -4.9559e-03,  3.7632e-03,  2.7563e-03,\n",
      "        -6.3603e-03, -3.1967e-03,  4.9773e-03, -9.4762e-04,  1.5432e-03,\n",
      "         2.2819e-05, -2.7849e-03,  1.3282e-03,  4.2533e-03, -1.7885e-03,\n",
      "         2.7018e-03,  5.5670e-03,  4.9699e-03,  3.4821e-04,  2.9810e-03,\n",
      "        -3.6135e-03, -2.0045e-05, -2.8113e-03, -2.7908e-04, -5.2371e-03,\n",
      "         4.9857e-03, -3.8993e-03,  2.4087e-03, -1.4210e-03,  2.9301e-03,\n",
      "         4.8168e-03,  4.0850e-03,  2.4116e-03,  2.4175e-03, -3.7475e-03,\n",
      "        -1.8525e-03, -1.6343e-03,  4.3070e-03,  4.0862e-03,  3.5924e-04,\n",
      "         2.6352e-03,  1.4030e-03, -1.2065e-03,  6.9481e-04, -6.3465e-03,\n",
      "         3.4195e-03, -5.6216e-03,  4.4447e-03,  4.8548e-04, -3.0861e-03,\n",
      "        -4.9959e-04, -1.5942e-03,  2.1563e-03,  5.2496e-03, -7.4049e-04,\n",
      "        -1.1287e-03, -5.2597e-03, -1.9556e-03, -4.1181e-03,  1.6816e-03,\n",
      "        -4.9317e-03, -5.9662e-03,  3.0028e-03, -3.4999e-03,  2.1754e-03,\n",
      "         1.7383e-03, -2.9671e-03,  1.4259e-03,  5.9952e-04, -5.9860e-03,\n",
      "        -4.8743e-03, -1.6781e-03,  2.8340e-03, -5.8020e-03,  4.6587e-03,\n",
      "        -3.7139e-03, -4.5529e-03,  4.5059e-03, -5.4125e-03, -5.5740e-03,\n",
      "         4.9391e-03, -1.7410e-03,  2.4119e-03, -2.4966e-03,  6.0705e-03,\n",
      "        -2.4293e-03,  3.3573e-03, -1.6499e-03, -2.9501e-03,  1.7257e-03,\n",
      "        -4.6284e-05, -3.7298e-03, -1.7744e-03,  3.8860e-03, -5.2843e-04,\n",
      "         1.9814e-03, -3.6508e-03,  1.6750e-03,  3.0786e-03,  3.5619e-03,\n",
      "         3.4864e-03,  3.1985e-03,  5.0591e-03, -3.0384e-03, -3.3506e-03,\n",
      "         3.9659e-03, -6.1673e-03,  2.4835e-03,  5.1360e-03,  5.1017e-03,\n",
      "        -5.2487e-03,  5.0799e-04, -2.1056e-03, -4.9898e-03, -6.3037e-03,\n",
      "        -2.8649e-03,  9.3338e-04,  1.1622e-03, -4.5134e-03, -4.7573e-03,\n",
      "        -8.8122e-04, -2.6362e-03, -6.2862e-03, -5.4885e-03, -5.5819e-03,\n",
      "        -3.6283e-03, -4.4948e-03, -5.2689e-03, -1.9818e-03,  2.7355e-03,\n",
      "         4.2774e-03,  1.4183e-03, -2.0230e-03,  5.8743e-03,  5.5758e-03,\n",
      "         1.8610e-03, -5.6876e-03,  3.4751e-03, -2.0386e-03, -2.8933e-03,\n",
      "        -1.6759e-03,  5.9591e-03, -3.4740e-04, -1.0014e-03, -4.1975e-03,\n",
      "         5.8765e-03, -4.0674e-03,  5.2386e-03, -4.9817e-03,  2.5933e-03,\n",
      "        -5.9663e-03,  3.1249e-03,  6.1191e-03,  3.6582e-03, -4.7583e-03,\n",
      "         3.2052e-03, -3.9292e-04, -4.1959e-03,  6.0153e-03, -1.7466e-05,\n",
      "        -1.3845e-03, -2.6603e-03, -1.9058e-03, -6.1357e-03, -6.7708e-04,\n",
      "        -3.0040e-03, -2.9894e-04,  2.7980e-03, -4.2829e-03,  5.0786e-03,\n",
      "        -4.8580e-03, -5.5503e-05, -5.6555e-03,  5.6447e-03,  4.9306e-04,\n",
      "        -2.4460e-03, -3.0520e-03, -5.5376e-03,  6.0596e-03, -2.8713e-05,\n",
      "        -3.0143e-03, -5.8269e-03, -3.1909e-03, -1.6713e-03,  2.1666e-03,\n",
      "         3.0324e-03, -9.1030e-04,  4.6225e-03,  3.0419e-03, -4.2944e-03,\n",
      "         6.0835e-04,  5.2202e-03, -5.5186e-03,  3.6320e-03,  2.2182e-04,\n",
      "        -5.2790e-03, -2.0244e-03,  3.6148e-03, -2.2149e-03,  1.0466e-03,\n",
      "        -8.2246e-04, -2.7982e-03, -3.8311e-03, -6.2466e-03, -6.9330e-04,\n",
      "         3.2757e-03, -1.9023e-03, -3.6142e-03, -3.3885e-03,  2.8114e-03,\n",
      "         3.2189e-04, -6.8598e-04, -2.7754e-04, -6.1916e-03, -5.1570e-03,\n",
      "         6.1717e-04,  4.5258e-03,  5.2904e-03, -1.2663e-03, -2.0162e-03,\n",
      "        -3.0671e-03,  1.1896e-03, -6.3075e-04, -3.2629e-04, -2.9491e-03,\n",
      "        -2.5171e-03, -4.8760e-04, -5.4913e-03, -6.2663e-03,  3.3706e-03,\n",
      "        -3.3784e-03,  1.2910e-03, -5.7709e-03,  1.5105e-03, -4.5670e-03,\n",
      "        -2.4480e-03, -1.5424e-04,  3.0587e-03,  3.0460e-03, -5.5927e-03,\n",
      "         4.7022e-03, -3.8742e-03,  1.2031e-03,  3.9412e-03, -2.6620e-03,\n",
      "        -2.1959e-03, -5.5972e-03,  3.2720e-03,  3.4230e-03,  1.7716e-03,\n",
      "         1.8533e-03,  5.5829e-03,  2.2286e-03,  3.6278e-03,  3.4610e-03,\n",
      "        -1.6593e-03, -1.4432e-03, -5.8901e-03,  5.4064e-03,  3.8422e-03,\n",
      "        -3.9505e-03,  3.2941e-04,  3.5172e-03,  5.9515e-03, -5.5521e-03,\n",
      "         3.8809e-03,  6.1983e-03, -1.9768e-03, -3.9783e-03, -6.8866e-04,\n",
      "         1.2120e-03, -4.1196e-03, -3.7508e-03,  2.1254e-03, -1.3923e-03,\n",
      "        -3.2789e-03,  4.3208e-03,  1.3763e-03,  6.8705e-04,  2.1888e-03,\n",
      "         2.9369e-03, -5.9454e-03,  1.4883e-03,  5.7382e-03, -8.7394e-04,\n",
      "        -3.0098e-03, -4.3278e-04, -3.4134e-03, -5.5317e-04, -2.7171e-04,\n",
      "         2.9478e-03, -4.9577e-03, -4.7727e-03,  2.5508e-04,  5.1897e-03,\n",
      "        -5.5949e-04, -9.6366e-04, -1.2516e-04, -3.4292e-03, -6.1963e-04,\n",
      "        -4.2661e-04,  1.8829e-03,  5.7865e-03, -4.8964e-03, -5.3071e-03,\n",
      "         1.4149e-03,  6.5299e-04, -2.5079e-03,  5.9528e-03, -7.3258e-04,\n",
      "        -8.4055e-05,  5.5072e-03,  4.1788e-03,  3.7747e-03,  2.1700e-03,\n",
      "        -6.3151e-03,  4.9234e-04, -6.1125e-03,  1.1788e-03,  3.7457e-03,\n",
      "        -1.1767e-04, -2.6180e-03,  6.3373e-03, -1.0863e-03,  2.7512e-03,\n",
      "        -6.3607e-03, -3.3868e-03, -5.6249e-03, -6.0099e-03, -7.4833e-04,\n",
      "         1.1611e-03, -4.2153e-03, -5.1433e-03,  6.3022e-03, -6.1597e-03,\n",
      "        -4.2812e-03,  1.9461e-03,  4.8425e-03, -1.0857e-03,  1.5420e-04,\n",
      "        -5.9473e-03, -1.2157e-03, -9.8500e-04, -1.0861e-03, -4.8419e-03,\n",
      "        -5.7252e-04,  8.3827e-04,  4.7349e-03, -5.9111e-03,  5.9487e-03,\n",
      "         3.3937e-03, -7.8692e-04,  2.8017e-03,  5.0647e-03,  3.2708e-03,\n",
      "        -2.1648e-04, -6.0168e-03,  1.9016e-03, -5.9349e-03, -1.9406e-03,\n",
      "        -5.4790e-03, -7.8775e-04, -5.3422e-03, -3.7148e-03,  3.8274e-03,\n",
      "        -6.0108e-03,  5.8219e-03, -3.9575e-03, -5.2761e-03, -3.1643e-03,\n",
      "        -4.8139e-03,  3.7154e-03, -5.8615e-03,  1.0372e-03, -7.1262e-04,\n",
      "        -6.8240e-04, -4.0071e-03, -5.5880e-03,  1.6626e-03,  1.3354e-03,\n",
      "        -2.8664e-03, -3.9771e-03,  6.0005e-03, -2.5198e-03,  5.1953e-03,\n",
      "         3.6759e-03, -2.7301e-03, -7.4524e-04, -5.3357e-03,  2.8664e-03,\n",
      "         3.2046e-03,  2.1080e-03, -1.9580e-03, -5.7094e-03, -4.5183e-03,\n",
      "        -1.0156e-03, -1.6119e-03, -5.2946e-03,  6.0141e-03,  4.4927e-03,\n",
      "        -5.3852e-03, -3.0093e-03,  4.0160e-04, -2.5591e-03,  7.8007e-04,\n",
      "         4.4693e-03,  5.5080e-04,  1.7205e-03,  6.1148e-03,  2.0187e-03,\n",
      "         4.4914e-03, -9.5753e-04,  3.6664e-04,  2.1650e-03, -3.3223e-03,\n",
      "         2.0988e-04,  2.2347e-03,  1.4699e-03,  9.1135e-04,  3.0335e-04,\n",
      "        -3.8154e-03, -4.0951e-03,  1.6145e-03,  1.5355e-03,  4.5856e-03,\n",
      "         1.0477e-03,  2.3354e-03, -3.8754e-03, -2.6329e-04, -4.8371e-03,\n",
      "        -1.1866e-03, -5.3679e-03, -5.8864e-03, -4.8478e-04, -5.8780e-03,\n",
      "        -3.1483e-03, -4.7379e-03, -2.1152e-03,  2.5435e-04,  2.9585e-03,\n",
      "         4.1327e-03, -3.8431e-03, -1.5392e-03, -1.6823e-03,  4.3748e-03,\n",
      "        -1.1848e-03, -1.5398e-03,  3.8961e-03, -2.6784e-03, -4.8360e-03,\n",
      "        -5.0384e-03,  2.3926e-03,  3.3302e-03, -6.0381e-03,  1.7122e-05,\n",
      "         2.0987e-03,  3.7240e-03,  5.8206e-03, -4.7884e-04,  9.1347e-04,\n",
      "        -3.6954e-03,  4.2001e-03, -3.5466e-05,  5.9535e-04,  2.7850e-03,\n",
      "         3.7108e-03, -4.9196e-03,  6.3478e-03, -5.7258e-03,  3.9426e-03,\n",
      "         6.3667e-03,  8.1433e-04,  2.3937e-04,  5.3589e-03, -4.5973e-03,\n",
      "        -3.2448e-03,  3.6872e-03,  5.7567e-03, -3.3827e-03, -5.1466e-03,\n",
      "        -4.8983e-03, -3.3975e-03,  3.5454e-03, -6.1186e-03, -4.5181e-04,\n",
      "         2.0809e-04,  5.2847e-04, -5.9437e-03,  1.0538e-03,  5.5729e-03,\n",
      "         1.7109e-03, -5.0642e-05, -5.3171e-03,  2.7001e-04, -1.3896e-03,\n",
      "        -5.5012e-03, -1.2182e-03, -4.5308e-03,  1.0034e-03,  3.8382e-03,\n",
      "         3.7882e-03, -4.7813e-03, -3.5041e-03,  8.0835e-04, -4.7995e-03,\n",
      "        -1.1184e-03, -4.4395e-03,  3.0681e-03,  3.8890e-03,  3.3753e-03,\n",
      "        -6.2112e-03,  4.7046e-03, -9.1894e-04, -6.3120e-03, -3.9720e-03,\n",
      "        -6.1499e-03,  5.4418e-04,  5.9241e-03, -5.6958e-03, -5.3036e-03,\n",
      "         5.7671e-03,  1.4211e-03, -1.5099e-03,  5.4642e-03,  5.9017e-03,\n",
      "        -4.1632e-03,  7.7498e-04,  4.9939e-03,  2.0108e-03,  5.0799e-04,\n",
      "         5.6500e-03, -3.4106e-03, -2.7238e-03, -2.6018e-03,  4.0684e-03,\n",
      "         1.4212e-03, -5.6302e-03,  5.6023e-03, -5.7689e-03,  1.1301e-03,\n",
      "        -3.9908e-03,  6.2191e-03, -2.2724e-03,  2.6943e-03,  5.9202e-03,\n",
      "         4.7701e-03,  5.8438e-03,  1.1373e-03, -1.7304e-03,  1.0287e-03,\n",
      "        -2.7556e-03, -4.7414e-03,  6.8487e-04,  2.3769e-04,  1.2752e-03,\n",
      "         4.3985e-03, -1.9411e-03, -3.7188e-03,  3.6370e-03,  6.3463e-03,\n",
      "         2.0472e-03, -6.3339e-03, -2.0914e-03,  4.5693e-03,  3.9562e-03,\n",
      "        -4.4353e-03, -2.9168e-04,  3.5284e-03, -3.9999e-04, -1.4477e-04,\n",
      "        -5.9840e-03, -2.0843e-03, -2.2837e-03, -6.0345e-03,  4.8524e-03,\n",
      "        -3.6067e-04,  4.9447e-03,  9.6877e-04, -5.0751e-03, -1.0023e-03,\n",
      "        -4.0669e-03, -4.9883e-03, -1.1817e-03,  2.5220e-03,  3.7115e-03,\n",
      "         2.8754e-03,  4.5173e-03, -2.0034e-03, -3.6089e-03, -5.3020e-03,\n",
      "         1.8071e-04, -1.0275e-03, -3.1652e-03,  3.1439e-03, -1.0237e-03,\n",
      "         1.5658e-03,  6.1788e-03, -3.1314e-03, -4.1332e-03, -4.3916e-03,\n",
      "         5.9551e-03, -5.2451e-03,  4.0671e-03,  5.4067e-03, -5.2661e-03,\n",
      "        -2.4342e-03, -2.0337e-03, -3.0758e-03, -3.9530e-03,  1.7836e-03,\n",
      "         1.8450e-03, -3.6742e-03,  5.0122e-03, -2.7046e-04,  1.9463e-03,\n",
      "        -2.0392e-03,  5.4883e-04,  3.5746e-03, -3.9399e-03,  5.9419e-03,\n",
      "        -1.2889e-03, -2.5029e-03,  4.9363e-03, -5.2450e-03,  3.3576e-03,\n",
      "         2.0371e-03,  7.9787e-04,  6.9013e-04,  5.4445e-03,  9.8820e-04,\n",
      "        -7.9312e-04,  4.9957e-03, -5.7286e-03,  8.5567e-04, -2.4545e-03,\n",
      "         3.5919e-03, -4.9364e-03, -5.5938e-03,  3.1896e-03, -3.9480e-03,\n",
      "         2.3991e-03,  3.5341e-03,  4.3739e-03, -5.6524e-03,  5.5234e-03,\n",
      "        -5.5146e-03, -5.4983e-03,  1.4931e-03,  5.0023e-03,  4.7970e-03,\n",
      "        -2.8135e-03,  5.1521e-03,  1.0436e-03, -3.0018e-03, -3.2740e-03,\n",
      "        -2.0394e-03, -4.2638e-03, -5.4252e-03, -3.7136e-03,  3.2527e-03,\n",
      "        -4.8336e-05,  3.4850e-04,  1.8624e-03,  5.7123e-03, -4.9555e-03,\n",
      "        -4.4968e-03, -3.0548e-03,  4.4844e-03, -2.1860e-03,  5.9869e-03,\n",
      "         4.2610e-03, -1.6203e-03, -3.1421e-04,  1.0746e-03,  2.9026e-05,\n",
      "        -6.1594e-03,  1.3456e-03, -5.5684e-05, -1.9095e-03, -2.4415e-03,\n",
      "        -5.8393e-03, -5.6841e-03, -4.7740e-03, -5.7753e-03, -3.2000e-03,\n",
      "        -4.4413e-03, -2.5830e-06, -6.2424e-03,  6.0533e-03, -2.8482e-03,\n",
      "        -3.1484e-03,  1.4731e-03, -4.4443e-03,  5.0511e-03, -1.5685e-03,\n",
      "        -4.9256e-03,  5.1385e-04,  5.0915e-03, -6.6524e-04,  5.0612e-03,\n",
      "        -5.9050e-03,  2.7709e-03,  3.6591e-03, -5.1876e-03, -6.0649e-03,\n",
      "         5.8968e-03,  8.3571e-05, -8.2773e-04, -4.8458e-04, -1.3521e-03,\n",
      "        -4.8483e-03, -3.3278e-03,  4.2952e-03, -2.6598e-03,  6.0836e-03,\n",
      "         6.2211e-03,  2.3507e-03, -1.2259e-03,  5.3446e-03, -3.5392e-03,\n",
      "         2.6151e-03,  2.6961e-03, -5.1390e-03, -3.6244e-03, -3.5409e-03,\n",
      "        -1.3565e-03, -2.9329e-03, -6.2530e-03, -4.9245e-03,  6.1040e-03,\n",
      "         3.7684e-03,  1.4115e-03,  6.2443e-03,  3.1920e-03, -2.5108e-03,\n",
      "         2.0821e-03, -5.7341e-03,  5.4227e-03, -5.9227e-03, -3.9534e-03,\n",
      "        -2.6448e-03, -5.1083e-04,  5.5882e-03,  5.8541e-03,  3.6900e-03,\n",
      "        -2.0230e-03,  1.9014e-03,  3.9597e-04, -4.2031e-03,  2.1844e-03,\n",
      "         4.8169e-03, -1.4744e-03,  4.2996e-04, -2.4354e-03,  6.0588e-03,\n",
      "         6.0052e-03, -1.1808e-03,  3.6567e-03, -1.2126e-03,  1.3327e-03,\n",
      "         1.1600e-03, -5.7264e-03,  1.8823e-03, -4.7437e-03, -4.8847e-03,\n",
      "         9.7258e-04,  6.0573e-03, -2.6824e-03,  5.4126e-03, -3.7227e-03,\n",
      "         3.3158e-04,  5.5237e-03,  4.9088e-03, -2.3802e-03, -1.7761e-03,\n",
      "         1.5867e-03, -4.3838e-03, -8.7835e-04, -3.2519e-04,  6.0691e-03,\n",
      "        -4.1891e-04,  1.2089e-03, -3.0994e-03, -1.6766e-03, -1.7132e-03,\n",
      "         4.0958e-03,  4.5990e-03,  3.2594e-03, -5.3902e-03, -3.8491e-03,\n",
      "        -5.1053e-03,  4.3450e-03,  5.4006e-03, -1.5297e-03, -4.0928e-03,\n",
      "        -2.6323e-03,  6.2055e-03, -3.5323e-03, -2.2102e-03, -8.6529e-04,\n",
      "        -1.8968e-03,  6.0510e-03, -3.4747e-04, -5.2064e-03, -2.5228e-03,\n",
      "        -1.9638e-04, -7.5692e-04, -1.4257e-03,  1.4150e-03, -1.9416e-03,\n",
      "         2.7941e-03, -4.2975e-03,  2.8629e-03, -5.0112e-03, -4.3263e-03,\n",
      "         2.2904e-03, -5.4464e-03, -4.2176e-03,  5.7669e-03,  8.4264e-04,\n",
      "        -3.5627e-03,  3.3755e-03, -4.6048e-03,  5.6512e-03, -2.3805e-03,\n",
      "        -1.9217e-03,  5.2683e-03,  5.1189e-03,  4.0643e-03,  2.8969e-03,\n",
      "         1.7855e-03,  3.9480e-03,  4.1231e-03, -5.8237e-03,  4.3371e-04,\n",
      "         4.7602e-03,  2.2555e-03,  2.5276e-04, -9.7197e-04,  3.2246e-03,\n",
      "        -3.3771e-03,  1.7541e-03,  2.7684e-03, -3.5785e-03, -4.2903e-03,\n",
      "        -1.9976e-03, -6.2906e-03,  5.7306e-03, -4.0977e-03,  1.9840e-03,\n",
      "        -2.2198e-03,  4.5667e-03,  3.5985e-03,  6.0107e-04, -2.4494e-03,\n",
      "        -3.8177e-03, -3.3011e-03, -4.2698e-03,  1.4729e-03, -5.2835e-04,\n",
      "        -4.9809e-03,  2.7126e-03,  3.7183e-03,  3.1181e-04, -7.2398e-04,\n",
      "        -3.7902e-04,  3.1477e-03, -1.4688e-03,  6.0769e-04,  2.2331e-03,\n",
      "         4.2344e-03,  4.7265e-03, -6.9255e-05,  1.0992e-04, -2.0950e-04,\n",
      "        -9.7301e-04,  6.2210e-03,  9.4237e-04,  1.2744e-03, -4.8609e-03,\n",
      "        -5.8562e-04,  4.9098e-03,  2.3959e-03,  4.2263e-04, -2.1595e-03,\n",
      "         2.9299e-03,  5.1270e-03,  4.3372e-03,  4.7678e-03, -4.2518e-03,\n",
      "         1.3827e-03, -7.5943e-04,  5.4928e-04, -1.7509e-03,  6.0749e-04,\n",
      "         5.7762e-05,  3.1932e-03, -4.2263e-03, -2.5003e-03, -1.6358e-03,\n",
      "        -6.1310e-03,  1.4767e-03, -1.9080e-03, -3.3710e-03,  3.5041e-03,\n",
      "        -1.3868e-03, -4.2409e-03, -1.0748e-04,  1.7690e-03,  7.8340e-04,\n",
      "         2.9252e-03,  5.1998e-03,  3.6833e-03, -4.6517e-03,  1.0221e-03,\n",
      "         1.2153e-04,  4.2099e-03, -3.6149e-04,  3.5782e-05,  1.8802e-03,\n",
      "         9.4652e-04, -4.2976e-03,  3.4483e-03,  4.0382e-03, -1.8319e-03,\n",
      "         2.4409e-03, -7.0923e-04,  2.4927e-03, -1.4460e-03,  5.2123e-03,\n",
      "        -1.4299e-03,  3.9918e-03,  5.7840e-03, -2.3956e-03,  6.3355e-03,\n",
      "        -5.7076e-03,  3.7199e-03,  3.5128e-03, -2.6113e-03,  5.7126e-03,\n",
      "         3.6439e-03, -2.0700e-03,  2.7441e-03,  1.2310e-03,  6.1837e-03,\n",
      "         4.3581e-03, -4.6091e-03, -5.6269e-03,  4.1896e-03, -2.6505e-05,\n",
      "         4.6263e-03,  5.5388e-04])), ('_sequence.2.weight', tensor([[-0.0265, -0.0032, -0.0209,  ...,  0.0068,  0.0133,  0.0067],\n",
      "        [ 0.0254, -0.0216,  0.0151,  ..., -0.0149,  0.0008, -0.0142],\n",
      "        [-0.0302,  0.0251, -0.0159,  ..., -0.0225,  0.0181,  0.0108],\n",
      "        ...,\n",
      "        [-0.0159,  0.0288,  0.0025,  ...,  0.0006, -0.0166, -0.0276],\n",
      "        [-0.0121,  0.0276, -0.0193,  ..., -0.0258, -0.0067, -0.0010],\n",
      "        [ 0.0306,  0.0006, -0.0228,  ...,  0.0243,  0.0027,  0.0237]])), ('_sequence.2.bias', tensor([ 5.3272e-03, -2.1185e-04, -9.8173e-03, -2.5926e-02,  2.3564e-02,\n",
      "         1.4115e-03,  1.6931e-03, -1.3128e-02, -8.5343e-03,  2.3104e-02,\n",
      "         3.1154e-02,  1.3720e-02,  4.8760e-03,  1.9221e-02,  2.5867e-02,\n",
      "         2.9281e-02, -1.4438e-02,  3.6851e-03,  8.1859e-03,  2.6024e-02,\n",
      "         8.4123e-03, -1.8110e-02,  9.7760e-03, -4.7615e-03, -1.8329e-02,\n",
      "        -2.5769e-02,  1.6269e-02, -5.0704e-03,  2.1056e-02, -2.3325e-02,\n",
      "         2.4116e-02,  1.4110e-02, -1.1612e-02,  2.5213e-05, -1.0400e-02,\n",
      "         1.6068e-02,  2.5554e-02, -3.2700e-03, -2.5387e-02, -1.7771e-02,\n",
      "         2.5654e-02,  3.1935e-02,  2.8132e-02,  1.5560e-02, -2.7630e-02,\n",
      "         2.3520e-02,  2.9907e-02,  1.6982e-02, -1.8335e-02, -2.7993e-02,\n",
      "         2.2542e-02,  2.4736e-02,  8.7057e-03,  1.7934e-02,  3.5818e-03,\n",
      "         1.2295e-02,  4.7063e-03, -1.3918e-02, -1.8332e-02, -2.6678e-04,\n",
      "         1.0143e-02,  2.4631e-02,  5.0219e-03,  2.8098e-03, -1.2412e-03,\n",
      "         3.1971e-02, -1.4521e-02,  2.3374e-02,  2.8817e-02, -1.9434e-02,\n",
      "        -2.3852e-02,  2.5856e-02, -2.0919e-02,  1.6881e-03,  2.9942e-02,\n",
      "        -4.6544e-03,  2.2503e-02, -2.7349e-03,  7.1638e-03,  6.6464e-03,\n",
      "         2.4592e-02,  2.4405e-02, -9.3364e-04,  2.3237e-02,  6.8683e-03,\n",
      "        -3.0029e-02, -2.4786e-02,  2.5591e-02,  1.8686e-02, -6.2869e-03,\n",
      "        -5.1166e-03,  2.9385e-02,  2.6395e-02, -1.6365e-02, -5.8410e-03,\n",
      "        -9.6807e-03,  2.0209e-02,  2.8060e-03, -3.5092e-04, -2.1720e-03,\n",
      "         2.4153e-02, -4.2440e-03,  2.4524e-02,  9.9371e-03,  1.1200e-02,\n",
      "        -1.7482e-02,  2.9698e-02,  1.9805e-02,  1.6261e-02,  9.8437e-04,\n",
      "        -2.1790e-02,  5.3248e-03,  4.0539e-04,  1.0551e-02,  1.8346e-02,\n",
      "        -1.7195e-02,  1.6088e-02,  3.9093e-03, -2.3231e-02, -1.0790e-03,\n",
      "         2.3262e-02, -2.0216e-03,  8.1706e-03,  6.3048e-03, -3.1192e-02,\n",
      "         1.8660e-02,  1.7710e-02,  6.1876e-03, -4.8306e-03,  8.3696e-04,\n",
      "        -3.1025e-02, -2.4377e-02, -9.9105e-03,  1.6041e-02, -3.0590e-02,\n",
      "        -2.8068e-02,  1.0464e-02, -2.6970e-02,  3.0204e-02, -2.0080e-02,\n",
      "         1.9720e-03,  2.9769e-02,  1.4936e-03,  7.4989e-03,  2.2591e-02,\n",
      "         2.6520e-02,  4.8041e-03,  1.2521e-02, -1.9092e-02,  5.5009e-03,\n",
      "        -1.1289e-02, -7.7948e-03, -2.6526e-02,  2.3084e-02, -2.9000e-02,\n",
      "        -9.9247e-03, -1.4191e-02,  2.7148e-02, -2.5457e-02,  5.6221e-03,\n",
      "         1.0847e-02,  2.6259e-02,  1.3390e-02, -2.4543e-02,  2.3281e-02,\n",
      "         1.6044e-02, -3.7952e-03,  1.1461e-02,  7.0427e-03,  5.7984e-03,\n",
      "        -2.2045e-02, -3.9772e-03,  1.5467e-02,  2.7453e-02,  1.4351e-02,\n",
      "        -5.1864e-03,  4.4929e-03, -1.5660e-03,  3.0369e-02, -2.1507e-02,\n",
      "        -3.6000e-03,  2.5197e-02,  2.5019e-02, -1.1308e-02, -2.4889e-02,\n",
      "         1.4224e-02, -2.1731e-02,  3.1480e-02, -9.1188e-03, -8.0877e-03,\n",
      "        -1.7832e-02,  3.0954e-02,  2.0792e-02, -3.0069e-03,  2.6051e-02,\n",
      "        -4.8716e-03,  1.7818e-03,  4.7911e-03, -1.6572e-02,  2.8247e-02,\n",
      "         5.9541e-03,  3.0732e-03,  1.1941e-02,  2.9568e-03, -2.9706e-02,\n",
      "         1.7575e-02,  3.0234e-02,  9.5949e-03, -1.3538e-02, -2.4651e-02,\n",
      "         1.4097e-02,  1.9799e-02,  6.6059e-03,  1.4036e-03,  4.0269e-03,\n",
      "        -1.0456e-02,  1.0331e-02,  2.0110e-02,  1.5861e-02,  5.8850e-03,\n",
      "         3.0306e-02, -1.5499e-02, -3.0184e-02,  1.5509e-02, -3.0316e-02,\n",
      "         5.6092e-03,  2.3390e-03, -2.7208e-02, -7.1727e-03, -8.8250e-03,\n",
      "         8.5445e-03, -3.1589e-02,  3.2761e-04,  1.0442e-02,  7.2848e-03,\n",
      "         1.2794e-02,  1.2710e-02, -7.8163e-03, -1.7709e-02, -3.1521e-02,\n",
      "        -2.9224e-02,  3.2129e-03,  2.0223e-02, -2.9714e-02,  8.7965e-04,\n",
      "        -2.4851e-02,  1.7221e-02,  3.1216e-02, -2.6033e-02,  2.1142e-03,\n",
      "         2.5161e-02,  1.9778e-02, -7.2761e-03, -2.5387e-03, -1.1152e-02,\n",
      "        -8.0929e-03, -2.4907e-02, -4.1863e-04,  2.4665e-02,  4.7398e-03,\n",
      "         1.5635e-02,  9.1340e-03, -1.9895e-02, -1.2300e-03,  8.9390e-04,\n",
      "        -1.1118e-02,  2.2486e-02, -9.6079e-03,  1.2489e-02,  2.4775e-03,\n",
      "         5.3783e-03, -3.1294e-02,  2.1810e-02,  1.9363e-02,  1.1007e-02,\n",
      "        -4.9121e-03, -3.1695e-02,  1.5054e-02, -3.0786e-02, -2.3901e-03,\n",
      "        -3.0813e-02, -1.7910e-02, -1.0609e-02,  2.4185e-02,  2.5291e-02,\n",
      "         2.6720e-03, -1.9498e-03,  3.0708e-02,  2.9733e-02, -3.0651e-02,\n",
      "        -1.7208e-02,  3.1312e-02, -1.0403e-02,  1.4623e-02,  2.7249e-02,\n",
      "         1.9519e-02,  2.7267e-02, -8.9479e-03,  3.1672e-02,  1.4999e-02,\n",
      "         2.5042e-03, -7.0693e-03,  2.7453e-02, -1.0900e-03, -9.3500e-03,\n",
      "         3.1834e-02,  9.8325e-03, -2.9063e-02, -1.2134e-02,  2.2896e-02,\n",
      "         2.7244e-02,  1.2973e-02,  3.3154e-03, -1.2864e-02,  1.1418e-02,\n",
      "        -1.3106e-02, -1.0151e-02,  2.9510e-02,  6.3878e-03,  1.6650e-03,\n",
      "         2.5697e-02,  1.3398e-02, -2.9033e-02, -2.1279e-02, -6.4159e-03,\n",
      "        -1.5555e-02,  2.3943e-02, -1.5445e-02, -9.2684e-03, -2.6940e-02,\n",
      "        -1.3336e-02,  2.8392e-02,  1.8820e-02,  2.8503e-02,  1.1388e-03,\n",
      "        -1.8642e-02, -1.7098e-02,  2.4421e-02, -1.6922e-02, -1.8297e-02,\n",
      "         3.1936e-02,  6.5423e-03, -1.5008e-02, -5.4467e-04,  4.5809e-03,\n",
      "         1.8325e-02, -1.0799e-02,  2.9285e-03,  4.7869e-03,  3.0907e-02,\n",
      "         2.9026e-02, -4.3740e-03,  5.5187e-03, -3.0741e-02,  2.2471e-02,\n",
      "        -7.3696e-03,  2.6743e-02, -2.9924e-02,  6.1585e-03, -2.5491e-02,\n",
      "         2.5407e-03,  1.8172e-02,  1.5700e-02, -2.4738e-02,  2.3533e-02,\n",
      "        -7.8149e-04,  1.0949e-02,  1.1821e-02, -2.2246e-02,  1.8728e-02,\n",
      "         2.0316e-02,  1.7350e-03, -5.4783e-03, -2.5259e-02,  5.7973e-04,\n",
      "        -2.0356e-02, -2.8005e-02,  3.9852e-03,  1.8781e-02, -2.6059e-03,\n",
      "         2.3289e-03, -1.5051e-02, -1.7423e-02, -1.2728e-02,  3.1398e-02,\n",
      "         1.2377e-02, -1.9681e-03,  1.6508e-02,  1.8750e-02,  2.2609e-02,\n",
      "        -1.7760e-02, -2.5501e-02,  3.5098e-03,  2.2593e-04, -2.8984e-02,\n",
      "         2.9345e-02, -3.0870e-02,  7.0456e-03,  1.6428e-02, -3.1963e-02,\n",
      "        -1.8653e-02,  1.2999e-02,  2.1153e-02, -5.1216e-03,  2.9464e-02,\n",
      "        -2.7076e-02,  1.4138e-02,  3.3069e-03,  1.8670e-02,  8.6472e-03,\n",
      "         7.0859e-03, -1.8698e-02,  5.4263e-03,  1.9776e-02, -6.3275e-03,\n",
      "        -5.5316e-03, -2.6093e-03,  5.2515e-03, -2.8835e-03, -6.3519e-03,\n",
      "        -1.5210e-02, -2.4561e-02,  2.3214e-02,  1.4104e-02,  2.2526e-03,\n",
      "        -6.8798e-03, -9.1536e-03,  2.6262e-02,  3.1963e-02, -3.1090e-02,\n",
      "         2.4395e-02,  1.0629e-02, -1.2066e-03,  1.1474e-02,  2.2016e-02,\n",
      "        -2.5600e-02,  1.2648e-02, -1.2918e-02, -2.3378e-02,  1.9825e-02,\n",
      "        -1.7619e-02, -1.7748e-02,  3.1136e-02,  2.8121e-02,  2.7746e-02,\n",
      "         5.9721e-03,  2.8378e-02, -2.9802e-02,  2.8687e-02, -2.5501e-02,\n",
      "        -7.1744e-03, -2.6213e-02, -3.8184e-03, -2.8765e-02,  1.1400e-02,\n",
      "        -2.9598e-02, -2.9796e-02, -1.2665e-02, -1.7483e-02,  2.8117e-02,\n",
      "         2.4345e-04, -3.1796e-02, -2.6192e-02,  3.1657e-02,  1.0595e-02,\n",
      "         2.5919e-02,  1.4715e-02,  1.4611e-02, -2.3724e-02, -2.9828e-03,\n",
      "        -1.6504e-02, -3.1973e-02,  1.7464e-02,  3.0565e-02, -5.8348e-03,\n",
      "         2.5601e-02, -2.1678e-03,  3.1436e-02, -2.5906e-02, -2.1538e-02,\n",
      "        -2.6661e-02,  2.2212e-02, -1.9314e-02,  1.2785e-02,  2.0824e-02,\n",
      "        -1.3539e-02])), ('_sequence.4.weight', tensor([[ 0.0340, -0.0231,  0.0099,  ..., -0.0202, -0.0347, -0.0274],\n",
      "        [ 0.0075, -0.0234, -0.0246,  ..., -0.0176,  0.0441,  0.0129],\n",
      "        [ 0.0454, -0.0208,  0.0295,  ...,  0.0156, -0.0299,  0.0360],\n",
      "        ...,\n",
      "        [-0.0441,  0.0139, -0.0108,  ...,  0.0330, -0.0085, -0.0081],\n",
      "        [-0.0302, -0.0095, -0.0084,  ..., -0.0233, -0.0321, -0.0248],\n",
      "        [ 0.0213,  0.0040,  0.0381,  ...,  0.0225, -0.0097,  0.0302]])), ('_sequence.4.bias', tensor([ 9.7790e-03, -4.4155e-03,  3.3015e-02, -4.3726e-02, -1.8536e-02,\n",
      "         2.8009e-02,  1.0352e-02,  1.2126e-02,  1.3639e-02, -1.8237e-02,\n",
      "         1.9696e-02,  2.5216e-02, -3.2488e-02,  4.4952e-02,  2.3429e-02,\n",
      "        -2.9996e-02,  4.2971e-02, -3.6240e-02,  2.3793e-02, -1.2321e-02,\n",
      "        -4.4744e-02, -7.6088e-03, -7.8536e-03,  4.9785e-04,  1.3048e-02,\n",
      "         3.4809e-05,  3.9119e-02, -1.4159e-02, -2.5208e-02,  7.9535e-03,\n",
      "         1.1193e-02, -2.1814e-02, -3.6301e-02, -8.6793e-04,  7.3633e-03,\n",
      "        -2.4846e-02,  4.1722e-02, -1.6285e-02,  1.6220e-02, -2.6059e-02,\n",
      "        -3.7461e-02,  1.7341e-02, -2.6028e-02,  3.3954e-03, -3.1991e-03,\n",
      "        -8.2129e-03,  2.6748e-02,  2.6976e-02, -3.0287e-02, -7.5447e-03,\n",
      "         3.1748e-02,  1.4011e-02, -1.4374e-02, -5.5694e-03,  1.3641e-03,\n",
      "         2.3354e-02,  3.7432e-02, -1.5873e-02,  2.6795e-02, -4.3108e-02,\n",
      "        -2.3117e-02, -1.1533e-03,  1.1208e-02, -3.8865e-02, -1.7932e-02,\n",
      "        -5.6365e-03, -3.1595e-02, -3.9871e-02, -2.4128e-02,  4.2174e-02,\n",
      "         8.4843e-03, -3.8122e-02,  1.6183e-02,  1.4369e-02,  3.0019e-02,\n",
      "         4.2047e-02, -4.1651e-02,  1.5720e-02, -1.2055e-02,  4.5040e-03,\n",
      "        -2.3215e-02, -2.5376e-02, -1.2967e-02,  4.3793e-02,  5.4449e-03,\n",
      "        -1.4019e-02, -2.1287e-02, -2.0615e-02,  4.2397e-02, -2.9435e-02,\n",
      "         2.9687e-02,  3.0046e-02, -3.7535e-02,  2.2832e-02,  3.0759e-02,\n",
      "        -4.3856e-02,  6.5558e-03, -3.9917e-02, -1.3121e-02, -3.0752e-02,\n",
      "        -7.1529e-03, -1.8935e-02,  4.2014e-02,  7.1324e-03, -4.4726e-02,\n",
      "         1.0750e-02,  2.5336e-02, -2.2811e-02, -2.4800e-02, -1.9028e-02,\n",
      "        -2.0925e-02, -1.1798e-03,  7.8733e-03, -2.3829e-02, -1.3156e-05,\n",
      "        -5.7433e-03, -4.0583e-02,  1.9017e-02, -3.6986e-02,  2.9473e-02,\n",
      "         4.1262e-02,  2.7359e-02, -2.4132e-03, -3.9842e-02,  2.0118e-02,\n",
      "         1.4949e-02, -1.5777e-02,  2.7426e-02,  1.1181e-02, -2.8996e-02,\n",
      "        -1.1181e-03,  2.3168e-02, -2.7968e-03,  1.6851e-02, -3.1081e-02,\n",
      "        -3.1549e-02, -8.6339e-03, -4.3025e-02,  8.4741e-03,  1.4084e-03,\n",
      "         5.9570e-03,  3.6870e-02, -1.7514e-04,  4.0010e-02,  8.4553e-03,\n",
      "         6.3628e-03,  2.4563e-02, -1.9091e-02, -2.3498e-02,  2.9697e-02,\n",
      "         4.5366e-02, -8.4329e-03, -4.0734e-02,  3.5636e-02,  5.1944e-03,\n",
      "        -3.1646e-02,  2.4096e-03, -4.4591e-02,  1.3413e-02, -2.7076e-02])), ('_sequence.6.weight', tensor([[ 0.0735,  0.0495, -0.0730,  ..., -0.0008, -0.0250,  0.0679],\n",
      "        [ 0.0173, -0.0443,  0.0066,  ..., -0.0175,  0.0521, -0.0299],\n",
      "        [-0.0407, -0.0336,  0.0263,  ...,  0.0029, -0.0266, -0.0729],\n",
      "        ...,\n",
      "        [-0.0547, -0.0599,  0.0117,  ...,  0.0370, -0.0749, -0.0250],\n",
      "        [-0.0042, -0.0378, -0.0288,  ..., -0.0388,  0.0196, -0.0046],\n",
      "        [-0.0787,  0.0215, -0.0336,  ...,  0.0651,  0.0570,  0.0164]])), ('_sequence.6.bias', tensor([ 0.0731,  0.0178, -0.0342,  0.0134,  0.0740,  0.0773, -0.0310, -0.0722,\n",
      "        -0.0600,  0.0581,  0.0705,  0.0155, -0.0648, -0.0776, -0.0422, -0.0275,\n",
      "         0.0144,  0.0505,  0.0174,  0.0766, -0.0481, -0.0062, -0.0075, -0.0504,\n",
      "         0.0137,  0.0204, -0.0779,  0.0132,  0.0128, -0.0109,  0.0583,  0.0607,\n",
      "         0.0364,  0.0008,  0.0732, -0.0608, -0.0303,  0.0168, -0.0056, -0.0560])), ('_sequence.8.weight', tensor([[ 0.0628,  0.1303, -0.0302, -0.0237, -0.0173, -0.0813,  0.0952, -0.0105,\n",
      "          0.0782,  0.0992,  0.0170, -0.1049, -0.1269, -0.1392,  0.1500,  0.1080,\n",
      "          0.0800, -0.1063,  0.1352, -0.0970,  0.1339,  0.1262,  0.0295,  0.0211,\n",
      "         -0.1479,  0.0177,  0.1451,  0.0582,  0.0905,  0.0887, -0.1364, -0.0871,\n",
      "          0.0702,  0.1331, -0.0505, -0.1519, -0.0703, -0.1487, -0.1555, -0.1232],\n",
      "        [-0.0664,  0.0956,  0.0831,  0.1432, -0.0765, -0.0133,  0.1238, -0.0675,\n",
      "         -0.1100,  0.0270,  0.1279,  0.0473,  0.0339, -0.0102,  0.1493,  0.1279,\n",
      "         -0.0333, -0.0196,  0.0887,  0.1289, -0.0180, -0.0330, -0.0255, -0.1454,\n",
      "         -0.0022,  0.1512,  0.0218,  0.0481,  0.0872,  0.0405, -0.0338,  0.0004,\n",
      "         -0.0715, -0.0169, -0.1428,  0.1025,  0.1424, -0.0572,  0.0467, -0.0285],\n",
      "        [-0.1207, -0.0275, -0.1458, -0.1109,  0.0759,  0.0964,  0.0850,  0.1117,\n",
      "          0.0938,  0.0230, -0.0858,  0.0729,  0.1484,  0.0211, -0.0888,  0.1573,\n",
      "          0.0100, -0.0367, -0.0104,  0.0095, -0.0851, -0.0597, -0.0741,  0.0097,\n",
      "          0.0045, -0.0027,  0.0131,  0.1370, -0.0655,  0.1302,  0.0806, -0.1246,\n",
      "         -0.1209, -0.1224, -0.0952,  0.0604, -0.0423, -0.0346, -0.0506, -0.1264]])), ('_sequence.8.bias', tensor([-0.0487,  0.0920,  0.0615]))])\n"
     ]
    }
   ],
   "source": [
    "print(model_MLPSEQ.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the parameters look similar but have different names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced size: 50000\n"
     ]
    }
   ],
   "source": [
    "dset=WCH5Dataset(\"/project/rpp-blairt2k/machine_learning/data/TRISEP_data/NUPRISM.h5\",reduced_dataset_size=50000,val_split=0.1,test_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataloader and grab a first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_dldr=DataLoader(dset,\n",
    "                      batch_size=32,\n",
    "                      shuffle=False,\n",
    "                      sampler=SubsetRandomSampler(dset.train_indices))\n",
    "train_iter=iter(train_dldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch0=next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=batch0[0]\n",
    "labels=batch0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the model output on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out=model_MLP(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 1, 2, 2, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0766e-04, 2.2861e-03, 9.9751e-01],\n",
      "        [7.7425e-03, 9.9220e-01, 6.1803e-05],\n",
      "        [1.4131e-02, 8.5355e-01, 1.3232e-01],\n",
      "        [6.2084e-06, 6.9774e-04, 9.9930e-01],\n",
      "        [1.0020e-01, 1.1429e-01, 7.8551e-01],\n",
      "        [7.1198e-02, 8.8704e-01, 4.1764e-02],\n",
      "        [6.2450e-08, 2.1018e-04, 9.9979e-01],\n",
      "        [4.5996e-07, 6.7011e-01, 3.2989e-01],\n",
      "        [3.5929e-02, 7.3118e-02, 8.9095e-01],\n",
      "        [9.9574e-01, 7.8176e-06, 4.2512e-03],\n",
      "        [9.4577e-01, 5.4228e-02, 2.5399e-06],\n",
      "        [1.0821e-03, 1.0757e-01, 8.9135e-01],\n",
      "        [7.4092e-03, 7.6919e-02, 9.1567e-01],\n",
      "        [5.0925e-01, 4.7701e-01, 1.3732e-02],\n",
      "        [2.3426e-01, 7.0428e-02, 6.9532e-01],\n",
      "        [1.9544e-11, 2.5087e-06, 1.0000e+00],\n",
      "        [1.0053e-05, 4.8213e-04, 9.9951e-01],\n",
      "        [4.2321e-02, 6.3290e-05, 9.5762e-01],\n",
      "        [6.6926e-04, 9.7137e-01, 2.7962e-02],\n",
      "        [1.1637e-04, 1.0239e-02, 9.8964e-01],\n",
      "        [1.2192e-08, 4.5288e-05, 9.9995e-01],\n",
      "        [6.8494e-06, 2.5255e-01, 7.4744e-01],\n",
      "        [9.3457e-06, 9.9812e-01, 1.8738e-03],\n",
      "        [3.1867e-07, 1.1161e-07, 1.0000e+00],\n",
      "        [1.4182e-06, 9.7231e-01, 2.7684e-02],\n",
      "        [9.3914e-01, 1.3349e-02, 4.7508e-02],\n",
      "        [1.4292e-02, 2.4546e-02, 9.6116e-01],\n",
      "        [8.7330e-06, 9.7093e-01, 2.9062e-02],\n",
      "        [1.8964e-02, 3.9487e-05, 9.8100e-01],\n",
      "        [7.9790e-02, 2.0532e-01, 7.1489e-01],\n",
      "        [7.4493e-04, 4.2711e-05, 9.9921e-01],\n",
      "        [9.6629e-01, 3.1171e-02, 2.5365e-03]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have model's predictions and we above got 'true' labels from the dataset, so we can now compute the loss - CrossEntropyLoss is the apropropriate one to use here. We will use `CrossEntropyLoss` from `torch.nn` - btw it is also a `Module`. First create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_module=CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_tensor=loss_module(model_out,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1414, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a 'forward pass'. We should now have a computational graph available - let's plot it for the kicks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't get torchivz in compute canada\n",
    "#from torchviz import make_dot\n",
    "#make_dot(loss_tensor,params=dict(model_MLP.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we calculate the gradients - let's check what they are now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, gradient: None\n",
      "name of a parameter: fc1.bias, gradient: None\n",
      "name of a parameter: fc2.weight, gradient: None\n",
      "name of a parameter: fc2.bias, gradient: None\n",
      "name of a parameter: fc3.weight, gradient: None\n",
      "name of a parameter: fc3.bias, gradient: None\n",
      "name of a parameter: fc4.weight, gradient: None\n",
      "name of a parameter: fc4.bias, gradient: None\n",
      "name of a parameter: fc5.weight, gradient: None\n",
      "name of a parameter: fc5.bias, gradient: None\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, gradient: {}\".\n",
    "          format(name, param.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No wonder - let's calculate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_tensor.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: fc1.weight, gradient: tensor([[-4.1110e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "         -2.1971e+04, -3.2625e+04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.2140e-03,\n",
      "         -1.2567e-02, -4.1266e+04],\n",
      "        [ 1.6237e-05,  0.0000e+00,  0.0000e+00,  ...,  7.0808e-03,\n",
      "          8.5391e-02, -4.5400e+04],\n",
      "        ...,\n",
      "        [-2.7679e+01,  0.0000e+00,  0.0000e+00,  ...,  3.1880e+04,\n",
      "          3.3283e+04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.9950e+04,\n",
      "         -6.3717e+04,  2.0506e+04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.1391e+04,\n",
      "         -1.2491e-02,  0.0000e+00]])\n",
      "name of a parameter: fc1.bias, gradient: tensor([-8.3951e+01, -1.9057e+02, -1.1009e+02, -7.2049e+01,  1.0797e+02,\n",
      "         1.0328e+02,  5.0550e+01, -1.4977e+01, -7.8430e+01, -7.4572e+01,\n",
      "        -4.8448e+01, -4.7588e+02, -1.0624e+01,  1.9674e+02,  1.8997e+01,\n",
      "        -5.3124e+01,  2.1320e+02,  4.6717e+01,  1.4570e+02,  4.5277e+01,\n",
      "         2.1899e+02,  8.4339e+01,  2.7654e-01, -2.0527e+02,  4.6786e+01,\n",
      "        -6.0769e+01,  3.0377e+01, -7.8464e+01,  1.8630e+02,  2.0086e+01,\n",
      "        -8.0262e+00,  1.2810e+02, -5.4664e+01,  1.2825e+02,  1.5634e+02,\n",
      "         2.0275e+02,  1.5458e+02,  6.2973e+01,  1.1750e+01,  2.1107e+01,\n",
      "        -2.8755e+02, -3.4249e+01, -3.6834e+01, -5.7381e+01,  1.8476e+02,\n",
      "        -9.5358e+01, -2.3857e+02,  1.6659e+02, -2.5555e+02,  9.0783e+01,\n",
      "         5.5105e+01,  1.7345e+02,  1.3977e+02, -2.2302e+01,  7.0344e+01,\n",
      "        -9.0370e+01, -3.4925e+01,  1.2914e+02,  7.7309e+01, -9.1984e+01,\n",
      "         2.3527e+02,  3.5332e+01,  4.5941e+01,  3.4570e+02, -1.2149e+02,\n",
      "         5.0689e+01, -3.3633e+01,  8.8904e+01,  1.0491e+01, -7.3221e+01,\n",
      "        -4.4291e+01,  7.7725e+01, -1.4473e+02, -8.5949e+01, -1.0558e+02,\n",
      "         6.0933e+01,  1.5000e+02,  2.2876e+01, -1.1944e+00,  2.7502e+02,\n",
      "        -3.7914e+02,  2.2338e+01,  1.2156e+02,  7.8354e+01, -2.8594e+01,\n",
      "        -2.9403e+02, -1.2625e+02, -1.7504e+02,  1.7194e+00, -3.1811e+01,\n",
      "        -1.6756e+02,  1.0446e+01, -2.4596e+01,  1.6422e+02, -1.0297e+02,\n",
      "        -9.0234e+01,  3.6531e+02, -1.9705e+02, -1.5729e+02,  4.8950e+01,\n",
      "         3.7021e+01,  1.5107e+02, -9.7610e+01,  1.0254e+02,  2.9451e+01,\n",
      "         6.9784e+01, -2.5662e+00, -1.6199e+02, -1.0776e+02,  1.0648e+02,\n",
      "         5.5648e+01,  1.1968e+02, -1.5908e+02, -9.3465e+01, -2.2385e+01,\n",
      "        -1.3272e+02,  3.5565e+01, -3.5150e+01,  3.6922e+01,  1.2423e+02,\n",
      "         5.4778e+01,  1.2924e+02, -5.6520e+01, -5.1718e+01,  1.6422e+00,\n",
      "         7.4070e+01, -1.1830e+02, -5.9910e+01, -1.3989e+02,  6.4184e+00,\n",
      "         4.3341e+01,  1.4114e+02,  7.4187e+01, -3.8468e+01, -3.7128e+01,\n",
      "        -6.7214e+01,  8.9826e+01,  5.4278e+01,  7.0396e+01, -2.3769e+02,\n",
      "        -1.4249e+02,  1.1291e+02,  1.9920e+02,  9.6619e+01, -1.9819e+02,\n",
      "         5.2216e+01, -1.0731e+02,  3.9230e+01,  1.7227e+02, -2.9162e+01,\n",
      "         1.3745e+02,  1.2525e+02,  5.2061e+01,  5.2051e+01,  1.3294e+01,\n",
      "        -7.0905e+01, -2.6712e+01,  1.2330e+02,  8.4182e+00, -6.6998e+01,\n",
      "         2.2576e+01, -1.4183e+01,  6.3083e+01,  3.9437e+01,  2.2795e+02,\n",
      "         2.7017e+01,  6.4279e+01, -9.3626e+01,  3.8280e+01,  4.0419e+01,\n",
      "         2.8953e+01, -1.5310e+01,  2.0109e+02,  8.3939e+01, -1.0903e+02,\n",
      "        -6.0908e+01,  6.5696e+01, -1.1853e+02,  1.3922e+01, -6.2887e+00,\n",
      "        -5.3865e+00,  1.5619e+02,  2.3127e+01, -4.5443e+01,  6.6086e+01,\n",
      "         1.1096e+02,  3.5343e+01,  4.1597e+00,  1.1345e+01,  9.6948e+01,\n",
      "        -5.1419e+01,  1.0630e+02, -1.4951e+02,  2.0502e+01, -5.7781e+01,\n",
      "        -2.7878e+01,  4.1231e+01,  1.4126e+01,  1.2540e-01, -1.3089e+02,\n",
      "        -1.1153e+02, -1.2227e+02, -5.3545e+01, -8.2442e+01,  2.0461e+02,\n",
      "        -5.0997e+01, -2.4119e+02,  5.4797e+00,  7.2166e+01,  2.1229e+02,\n",
      "        -1.5283e+01, -8.1803e+01, -1.3838e+02, -1.1249e+02,  1.2376e+02,\n",
      "         3.6628e+01, -1.3544e+01, -7.2382e+01, -3.3668e+01, -1.2345e+01,\n",
      "         4.5944e+01, -2.2909e+02,  3.9664e+01,  3.3519e+01,  6.2015e+01,\n",
      "         7.6445e+01, -1.9000e+01,  2.3864e+02,  9.0065e+01,  1.4083e+02,\n",
      "        -4.6373e+01,  1.5273e+02,  2.5782e+01, -1.0042e+02,  1.1905e+02,\n",
      "        -2.0866e+02, -7.4691e+01,  1.6718e+02, -1.8056e+01, -1.4149e+02,\n",
      "         1.3243e+02,  3.6625e+01, -1.7703e+02,  2.4407e+02, -1.9858e+02,\n",
      "         1.2677e+02, -1.5114e+01, -5.0124e+01, -7.3096e+01, -1.3339e+02,\n",
      "         3.7068e+01, -1.1955e+01,  9.4113e+01,  8.2584e+01,  2.1999e+02,\n",
      "         2.5052e+01,  3.0141e+01,  9.5785e+01, -6.8457e+01, -1.9642e+00,\n",
      "        -4.7573e+01, -1.5974e+02, -1.9663e+02,  6.1068e+01,  3.6285e+02,\n",
      "         1.4605e+02, -1.7472e+02,  8.9048e+01, -1.2678e+02,  1.6521e+02,\n",
      "         4.7293e+01,  1.7626e+02,  7.3541e+01,  4.0398e+01, -8.9237e+01,\n",
      "         1.8220e+02, -1.9730e+02,  8.3986e+01, -8.2449e-02,  1.5333e+02,\n",
      "         1.2224e+02,  1.7757e+02, -1.5187e+02, -1.8477e+02,  2.5517e+02,\n",
      "        -6.7093e+00,  1.7611e+02,  6.1042e+00,  8.7763e+00,  1.2731e+02,\n",
      "         9.8076e+01,  2.8400e+02,  1.2336e+02,  2.2600e+01, -1.2871e+02,\n",
      "         2.0173e+01, -1.5064e+02,  6.2024e+01,  1.3259e+02,  2.3653e+02,\n",
      "         1.9633e+02,  2.5783e+02,  7.6723e+01, -3.1976e+02,  7.9593e+01,\n",
      "         2.2541e+02,  7.6655e+01,  2.8577e+01,  1.4837e+02,  2.5865e+02,\n",
      "         1.0516e+01,  7.8568e+01,  4.1694e+01,  2.7202e+01, -8.7310e+01,\n",
      "        -1.0688e+02,  1.8991e+02,  1.6179e+02, -6.5832e+01,  1.9525e+02,\n",
      "         1.8657e+02, -8.8151e+00,  2.1776e+02,  1.5993e+02, -2.1776e+02,\n",
      "         2.6111e+02, -2.6656e+01,  1.6250e+02,  9.0413e+01, -2.8630e+02,\n",
      "         1.5865e+02, -1.9840e+01,  1.8182e+02,  4.5137e+01,  2.1603e+02,\n",
      "         1.7935e+02,  6.4619e+01, -5.1344e+01, -8.3496e+01,  1.0237e+02,\n",
      "        -1.7290e+02,  2.2509e+01, -1.6732e+02,  3.6592e+02, -6.3481e+01,\n",
      "        -1.0805e+02, -1.6905e+02,  4.8930e+01,  3.4446e+02, -1.2057e+02,\n",
      "         1.0684e+02,  7.5799e+01,  3.0039e+01,  1.0656e+02, -1.9181e+02,\n",
      "         2.3133e+02,  1.3727e+02,  1.5061e+02,  2.0034e+01,  1.7763e+02,\n",
      "         7.2832e+01,  8.2761e+01, -2.1469e+02,  1.0152e+02,  2.3262e+01,\n",
      "        -3.0518e+01,  5.0801e+01, -9.2554e+01,  6.8500e+01,  5.6729e+00,\n",
      "         1.0592e+02,  5.3214e+01, -2.4992e+00,  1.8938e+02,  7.0471e+01,\n",
      "         9.6543e+01, -2.1705e+02,  1.7127e+02, -1.4192e+01,  5.3790e+01,\n",
      "         2.7615e+02,  8.8367e+00,  2.3577e+02,  1.4031e+01, -5.5384e+01,\n",
      "         3.1751e+01,  8.1172e+00, -8.7052e+01, -2.2836e+02,  1.5441e+01,\n",
      "         4.2708e+01,  1.4153e+02,  1.1676e+01, -2.6257e+02,  9.6083e+01,\n",
      "        -1.7154e+02, -7.6035e+01, -4.5466e+01, -1.9328e+02,  1.7044e+02,\n",
      "        -1.2860e+02,  3.6720e+02,  3.3103e+01, -1.1497e+02,  1.1974e+02,\n",
      "        -1.8832e+02,  8.9899e+01,  8.8000e+01,  1.3201e+01, -1.0151e+02,\n",
      "         2.2309e+02, -1.9939e+02,  2.9919e+01, -9.3394e+00,  3.6333e+02,\n",
      "        -6.0480e+01,  1.2597e+02,  1.3260e+02, -1.4002e+02,  8.8415e+01,\n",
      "        -7.5135e+01,  7.5194e+01,  4.3122e+00,  1.1276e+02,  2.1882e+02,\n",
      "        -1.7033e+02,  9.0425e+01, -3.4401e+02,  5.2354e+01,  1.2694e+02,\n",
      "         1.3690e+00, -1.1003e+02,  7.9272e+01, -9.7258e-01,  1.6165e+02,\n",
      "         2.4143e+02, -3.6197e+01,  1.7967e+02, -1.1673e+00,  4.0380e+01,\n",
      "         1.3935e+02,  1.8261e+02, -7.2291e+01, -5.7504e+01,  1.4024e+02,\n",
      "        -1.6380e+02,  2.1227e+02, -1.0254e+02, -9.9933e+01,  1.0573e+02,\n",
      "         8.9452e+01, -1.3958e+02, -2.9823e+01, -2.6675e+01,  1.3808e+01,\n",
      "        -4.2675e+01,  2.6017e+02,  1.4485e+02, -1.7279e+01, -1.6862e+02,\n",
      "        -1.0322e+01,  1.0666e+02,  3.1864e+01,  2.1703e+02, -9.4112e+01,\n",
      "        -2.2240e+01, -1.5853e+02, -3.9530e+01,  2.3660e+02,  1.0297e+01,\n",
      "        -2.0014e+02,  1.1954e+02,  2.3687e+01, -6.3908e+01,  1.1440e+01,\n",
      "        -5.0169e+00,  2.4488e+02, -2.8109e+01,  1.3607e+02,  2.6505e+01,\n",
      "         1.5132e+02,  2.6192e+01,  1.2586e+00, -5.4490e+01, -4.3581e+01,\n",
      "        -8.6230e+01, -4.9708e+00, -1.4344e+02,  1.8717e+02, -8.3545e+01,\n",
      "        -1.3185e+01, -2.9881e+01,  1.9791e+01,  2.6891e+02, -3.7209e+01,\n",
      "         1.0788e+02,  3.5674e+00, -3.6925e+01, -3.4812e+01,  2.6948e+02,\n",
      "        -1.6837e+02, -1.0728e+02,  1.3015e+01, -1.3124e+02,  7.6411e+01,\n",
      "        -8.1002e+01, -4.7308e+00, -7.2436e+00,  2.4328e+02,  1.3536e+02,\n",
      "         1.2145e+02, -1.6230e+02, -3.6846e+01,  5.1874e+01,  1.2011e+02,\n",
      "         2.5286e+02, -3.9376e+01,  1.5092e+02, -5.4718e+01,  9.1891e+01,\n",
      "         7.5679e+01,  4.0164e+01,  2.5375e+01, -2.9842e+01,  6.4780e+01,\n",
      "         1.0997e+02,  1.2087e+02, -3.3161e+01,  2.0696e+02,  1.0623e+02,\n",
      "        -8.4167e+01,  2.0851e+01, -3.4962e+02,  8.0493e+01, -2.8328e+02,\n",
      "         1.3196e+02,  1.9571e+02, -5.9115e+00, -5.5593e+01, -3.9366e+01,\n",
      "         9.0309e+01, -5.7869e+01, -1.8366e+02,  2.9049e+02, -1.4028e+02,\n",
      "        -1.9538e+02,  1.7119e+01,  1.2400e+02, -9.0689e+01,  2.8301e+02,\n",
      "         3.3579e+01,  1.2768e+02, -1.8765e+01, -5.4187e+01,  1.8090e+02,\n",
      "        -1.7915e+00, -1.9153e+00, -7.9318e+01, -2.4735e+02,  2.4281e+02,\n",
      "         7.9574e+01, -1.3272e+02, -1.4510e+02, -1.7868e+01,  8.5395e+01,\n",
      "        -6.8401e+01, -1.3668e+01,  2.5280e+01,  3.6766e+02,  1.5395e+02,\n",
      "         1.3266e+02, -1.9355e+02, -1.2200e+02, -1.7969e+02, -4.9386e+01,\n",
      "         5.0998e+02,  4.5375e+02,  1.1863e+02,  6.2724e+00, -4.6271e+01,\n",
      "        -2.5029e+02, -4.7436e+01, -5.2468e+01, -1.0094e+02, -5.8787e+01,\n",
      "         7.8761e+01,  1.8292e+02, -6.4127e+01, -4.8887e+01, -6.5519e+01,\n",
      "        -1.3139e+02, -1.2272e+02,  9.1805e+01,  2.5028e-01,  9.7136e+01,\n",
      "        -2.8773e+02,  3.8890e+01, -1.8633e+02,  2.7496e+00,  1.2248e+02,\n",
      "        -2.1822e+01,  3.4841e+01, -2.8552e+01,  2.0144e+02,  5.3577e+02,\n",
      "        -2.2694e+02, -1.8265e+02, -4.2296e+01,  3.9407e+01,  3.8757e+01,\n",
      "        -2.2793e+02, -1.1799e+02,  6.9526e+01,  2.8768e+02,  2.5454e+02,\n",
      "         5.8133e+01,  2.4061e+02, -1.7496e+02,  3.2894e+01, -3.7093e+01,\n",
      "         1.0750e+02,  1.3856e+02, -2.8932e+01,  5.8982e+01,  1.2966e+02,\n",
      "        -1.5589e+02, -7.7923e+01, -1.2579e+02,  4.6394e+01,  6.5350e+01,\n",
      "        -1.8353e+02, -3.7784e+01,  1.2174e+02, -9.0311e+01,  1.7963e+02,\n",
      "        -3.3503e+01,  6.1464e-01, -6.4092e+01,  7.7873e+01, -8.5074e+01,\n",
      "        -1.7578e+02, -1.3602e+01,  7.8151e+01, -4.6479e+02,  9.3682e+01,\n",
      "         6.7193e+01,  2.9324e+00, -1.1947e+02, -3.3114e+02,  1.3623e+01,\n",
      "        -2.8587e+02,  2.5234e+01,  8.9513e+00,  1.2274e+02,  6.8300e+01,\n",
      "         2.1134e+02,  3.7152e+01, -2.9439e+02, -1.1530e+02,  2.0853e+02,\n",
      "         1.1659e+02,  1.2436e+01, -8.0933e+00,  1.0672e+02,  1.0821e+02,\n",
      "        -1.0784e+02,  4.4758e+01, -1.0503e+02, -1.3725e+02,  2.7761e+01,\n",
      "        -3.1586e+01,  2.0125e+02,  9.8085e+01,  6.5339e+01, -9.5659e+01,\n",
      "         2.9672e+00,  1.0033e+02,  1.8310e+02,  1.7133e+02,  2.5673e+02,\n",
      "        -5.6881e+01, -2.7907e+02,  1.4920e+02, -1.8974e+02,  3.2870e+02,\n",
      "         8.1337e+01,  5.0657e+02,  2.1414e+02,  1.9457e+02,  5.0683e+01,\n",
      "        -1.2702e+02, -2.4844e+01, -3.4591e+02, -3.1149e+01, -2.0944e+02,\n",
      "         1.4998e+02, -1.5455e+01,  5.3718e+01,  8.5873e+01, -1.9135e+02,\n",
      "         1.3760e+02,  8.9170e+00,  8.0333e+01,  9.5633e+01, -4.0598e+01,\n",
      "        -2.6745e+02, -4.7494e+00,  2.9940e+01, -7.5598e+01,  8.0410e+01,\n",
      "         4.4833e+02,  4.0227e+01,  1.7080e+02, -7.8671e-01,  4.9550e+01,\n",
      "         4.1382e+01,  2.9765e+02,  2.8076e+02,  4.4984e+01,  2.0101e+02,\n",
      "        -1.7589e+02,  1.3087e+02,  3.2562e+01,  3.4636e+01, -1.8311e+02,\n",
      "         1.8788e+02,  2.3049e+02, -8.8586e+01,  1.1370e+01, -4.1523e+02,\n",
      "        -6.8416e+01, -9.9187e+01, -1.3170e+02,  1.9667e+00,  8.2879e+01,\n",
      "        -1.2730e+01, -1.4231e+02,  6.3619e+00, -2.1000e+02,  7.7868e+01,\n",
      "        -3.1677e+01,  2.3033e+02,  1.0431e+02,  3.7684e+00, -2.4593e+02,\n",
      "        -1.4834e+02, -6.2062e+01, -8.0110e+01, -1.8508e+02, -7.4385e+01,\n",
      "         1.1266e+02, -2.4825e+01,  2.0906e+01,  2.0176e+02, -1.8365e+00,\n",
      "        -2.2588e+02, -8.1136e+01,  2.0657e+02, -7.4179e+01,  2.0905e+02,\n",
      "         8.0523e+01,  1.1045e+02,  1.8923e+02, -6.2895e+01, -4.5879e+01,\n",
      "        -3.2798e+01,  6.5391e+00,  1.1411e+02, -6.6532e+01,  5.8653e+02,\n",
      "        -6.8692e+01, -4.4110e+01, -1.6001e+02, -2.5708e+02,  9.0748e+01,\n",
      "        -2.1627e+01,  1.7648e+02, -1.5260e+02,  9.0961e+01, -1.8160e+02,\n",
      "         5.0123e+01,  2.1604e+02,  1.4261e+01,  9.5154e+01, -3.2566e+02,\n",
      "         1.8264e+02, -4.6017e+01,  1.4450e+01, -1.5207e+01,  1.7849e+02,\n",
      "         2.7213e+02, -1.9604e+02, -9.6431e+01,  2.1161e+02,  5.4034e+01,\n",
      "         1.4205e+02, -3.4108e+01,  1.6943e+02, -1.1768e+02,  9.7899e+01,\n",
      "         1.7481e+02, -7.9262e+01,  1.7680e+02,  1.0813e+02, -1.1174e+00,\n",
      "         2.2525e+02, -1.9390e+02, -1.1528e+02,  4.3403e+01, -3.3922e+02,\n",
      "        -7.4630e+01, -1.3870e+02,  4.4312e+00,  3.6446e+02, -1.8428e+02,\n",
      "         1.0513e+02,  2.0071e+02, -1.1687e+02,  1.5604e+02,  1.1433e+02,\n",
      "        -1.0319e+02, -2.4330e+02,  8.4611e+01, -3.5294e+01, -2.5843e+01,\n",
      "        -1.7288e+02, -4.9227e+02,  1.7548e+02,  1.1771e+02,  1.1445e+02,\n",
      "         1.5830e+02,  1.5313e+02, -1.1453e+02,  4.0355e+01,  7.6316e+01,\n",
      "         3.2116e+02, -2.7651e+02, -1.2615e+02,  2.6198e+02, -2.8876e+02,\n",
      "         3.8954e+01,  3.5890e+01, -8.4118e+01,  1.4822e+02, -2.6178e+01,\n",
      "         4.7222e+01, -3.9073e+01,  3.1630e+02, -7.1137e+01,  4.9279e+01,\n",
      "         1.5010e+02, -1.6094e+02,  3.8592e+01,  8.1207e+01, -1.2394e+02,\n",
      "        -2.4590e+02,  5.9163e+01,  2.8579e+02, -5.3567e+01, -7.4740e+01,\n",
      "        -3.0592e+01, -1.5611e+02,  1.0832e+02, -2.0222e+02,  4.1962e+02,\n",
      "         2.0902e+01, -1.9942e+02, -5.5258e+01, -3.9704e+02, -2.5856e+01,\n",
      "         4.8795e+01, -2.0500e+02, -8.4697e+01, -1.1348e+02, -1.3429e+02,\n",
      "        -3.0964e+02, -2.2993e+02,  5.1974e+01,  4.2651e+02,  4.2555e+01,\n",
      "         2.5309e+02,  3.4517e+02, -2.2245e+02, -8.5782e+01, -2.5031e+02,\n",
      "        -1.9373e+02,  4.5993e+02, -2.6729e+02, -1.7720e+02,  1.6615e+02,\n",
      "         8.3998e+01,  1.0788e+02, -1.6326e+02, -4.2179e+01,  1.5596e+02,\n",
      "         1.1603e+02,  2.8166e+02,  1.3423e+02,  6.0678e+00, -7.0322e+01,\n",
      "         2.7823e+02, -5.2828e+01,  1.7994e+02, -1.2625e+02, -4.3762e+01,\n",
      "         3.0333e+01,  1.4416e+01,  2.0158e+02,  6.0811e+02, -4.4797e+02,\n",
      "         3.4315e+02,  1.4529e+02,  7.5988e+01, -7.7283e+01,  1.8647e+01,\n",
      "        -1.1350e+02,  1.5343e+02,  1.9623e+02,  1.0609e+02, -5.3026e+02,\n",
      "        -2.7856e+01, -5.8267e+01,  1.7591e+02, -1.5530e+02,  1.3104e+02,\n",
      "        -3.8548e+02, -8.7740e+01, -2.4364e+01, -8.2776e+01,  4.3916e+02,\n",
      "        -2.2911e+02,  1.5394e+02, -1.9538e+02,  1.5848e+02,  2.5727e+02,\n",
      "         1.0258e+02, -1.5619e+02,  4.1613e+01, -1.5915e+02,  3.1028e+02,\n",
      "         2.7255e+02, -6.1814e+01,  2.7424e+01,  4.3598e+01, -4.3631e+01,\n",
      "        -1.4487e+02,  6.6460e+01,  5.3327e+01,  1.4267e+02,  1.7438e+02,\n",
      "        -6.1879e+01, -2.6738e+01, -5.9761e+01, -1.3914e+01,  1.1723e+02,\n",
      "         2.1651e+02, -1.1737e+02, -2.4175e+02,  4.1382e+02,  8.5019e+01,\n",
      "         2.8000e+02,  1.4801e+02,  5.8521e+00,  5.1315e+01, -1.4774e+02,\n",
      "        -4.3650e+01,  6.3718e+01, -7.9852e+01,  1.3948e+02,  1.2699e+02,\n",
      "        -1.3887e+02, -4.0073e+01])\n",
      "name of a parameter: fc2.weight, gradient: tensor([[ 0.0520,  0.1235,  0.0966,  ..., -0.0027,  0.0799,  0.0266],\n",
      "        [-0.0250, -0.0373, -0.0010,  ..., -0.0091,  0.0052,  0.0136],\n",
      "        [-0.0880,  0.0233,  0.0773,  ...,  0.0094,  0.1641,  0.1018],\n",
      "        ...,\n",
      "        [-0.0138,  0.0200,  0.0232,  ..., -0.0317, -0.0470,  0.0248],\n",
      "        [ 0.0949, -0.1382,  0.0380,  ...,  0.0019, -0.0540, -0.1375],\n",
      "        [-0.0092, -0.0062,  0.0423,  ..., -0.0137,  0.0394, -0.0347]])\n",
      "name of a parameter: fc2.bias, gradient: tensor([ 1.3514e-03,  1.0500e-04,  5.8835e-04, -1.2917e-03,  1.3985e-03,\n",
      "        -6.5999e-04,  3.0901e-04, -5.0033e-04, -8.9872e-04, -5.2743e-04,\n",
      "        -1.9146e-04,  1.5340e-04, -6.6646e-04,  5.0481e-04,  2.0807e-05,\n",
      "         6.5540e-04,  4.9558e-04, -1.0009e-04, -4.1280e-04,  5.2879e-04,\n",
      "        -1.8089e-04, -8.0590e-04, -2.1256e-04,  1.1191e-03,  5.1201e-04,\n",
      "         2.7410e-04, -9.4123e-04, -6.4288e-04,  4.6372e-04, -1.9123e-03,\n",
      "        -1.6419e-04, -6.7341e-05, -3.7137e-05,  4.4158e-04, -1.9823e-04,\n",
      "         5.2290e-04,  3.2445e-04,  2.2802e-04,  1.2016e-03, -8.0214e-04,\n",
      "         6.9199e-04,  2.0057e-03,  2.0830e-04, -5.5558e-05,  1.2172e-03,\n",
      "        -4.1105e-04,  2.4547e-04, -3.2023e-04,  1.4505e-03, -8.2672e-05,\n",
      "         7.9956e-04, -7.5729e-04,  7.4685e-05,  8.1347e-05, -1.8875e-05,\n",
      "        -4.1735e-05,  8.1404e-04,  5.8089e-04,  1.9680e-04,  8.7351e-05,\n",
      "        -1.4774e-04, -1.7032e-04, -1.2587e-03,  1.3866e-03, -3.7733e-04,\n",
      "        -1.6753e-04, -1.6354e-04, -1.5095e-03,  2.4142e-04, -1.2299e-04,\n",
      "        -4.0948e-04,  1.1039e-03,  9.0132e-04, -1.0925e-03,  9.9949e-05,\n",
      "         1.8320e-04,  1.2811e-03, -5.7719e-05, -9.9138e-04,  4.1760e-04,\n",
      "         2.9811e-04,  3.4571e-04,  3.1859e-04, -4.1400e-04,  5.0316e-04,\n",
      "         5.0009e-04, -1.5793e-04,  2.0854e-04, -1.8910e-03, -7.9200e-04,\n",
      "         4.9367e-04, -4.6968e-04, -2.8193e-04, -3.7910e-06,  4.1835e-04,\n",
      "         5.6386e-04, -8.6117e-04,  2.5657e-04,  2.0671e-04,  1.1880e-04,\n",
      "        -1.5444e-04, -2.2580e-04,  1.2230e-04,  7.7630e-04, -5.2319e-04,\n",
      "         1.4833e-04, -4.2560e-04, -1.7093e-04,  1.1398e-03, -9.8324e-04,\n",
      "         5.6235e-04, -9.3998e-05,  3.6545e-04,  2.9612e-04, -1.1426e-03,\n",
      "         5.0621e-04, -5.0529e-04, -3.5308e-04,  9.3121e-04,  3.2322e-04,\n",
      "         4.2026e-04, -1.9470e-04, -5.4341e-04,  1.7359e-04,  8.3839e-05,\n",
      "        -2.6240e-04, -2.5820e-04, -3.9747e-04, -2.6447e-04,  2.5849e-04,\n",
      "         6.8995e-04,  1.0596e-03, -3.9006e-04,  4.3768e-04, -1.1169e-04,\n",
      "         3.1947e-04, -1.5402e-03, -1.5037e-04,  6.2963e-04,  4.0464e-05,\n",
      "        -1.5340e-04,  8.5741e-04,  8.9763e-04,  4.9248e-04,  5.2782e-04,\n",
      "        -1.0444e-03, -5.5204e-04,  1.1571e-03,  3.4571e-04,  7.2995e-04,\n",
      "        -8.5888e-05, -1.9126e-04,  3.1207e-04,  1.9848e-04,  1.7502e-04,\n",
      "        -7.1392e-05,  7.5243e-05,  1.2300e-03, -1.7534e-04, -4.8811e-04,\n",
      "        -1.2946e-04,  7.9819e-05,  3.4465e-04,  6.3182e-04,  2.2552e-03,\n",
      "        -7.5022e-04, -1.2558e-04,  1.3843e-03,  3.8841e-04, -1.1451e-03,\n",
      "         1.2932e-04, -1.7378e-03, -1.4329e-04, -2.5685e-04,  1.1229e-04,\n",
      "         1.1642e-03, -9.6505e-04, -1.9781e-05,  8.3576e-05, -1.7709e-04,\n",
      "        -1.4399e-04, -1.0743e-03,  3.3934e-04, -2.0727e-04, -2.6387e-04,\n",
      "        -2.8292e-05,  1.7330e-04,  3.8091e-04,  5.3206e-04,  4.0877e-04,\n",
      "        -1.2241e-03,  7.8872e-04,  4.1095e-05,  6.6324e-04,  6.6369e-04,\n",
      "        -3.1465e-04,  6.1316e-04,  1.3021e-04, -9.6131e-04,  4.9670e-04,\n",
      "        -2.4685e-04,  7.1177e-04, -9.2389e-04, -1.4202e-03, -4.3986e-04,\n",
      "         2.6597e-04,  2.8188e-04,  7.5463e-04, -2.3484e-04, -2.7008e-04,\n",
      "        -1.5241e-04,  4.3823e-04, -3.9422e-04, -3.8012e-04,  1.6573e-04,\n",
      "        -3.7237e-04,  4.8279e-04, -2.4209e-04, -4.4730e-04,  1.1259e-03,\n",
      "         3.4750e-04, -1.6582e-04,  4.2010e-04, -5.3100e-04, -1.0430e-03,\n",
      "         2.5206e-04, -2.8160e-04, -2.0796e-04,  1.2017e-05,  9.6780e-05,\n",
      "         6.5684e-04,  5.3903e-04, -1.0221e-03,  4.6041e-04, -1.7837e-04,\n",
      "         1.1727e-04, -4.5727e-04, -3.2925e-04,  3.8298e-05,  1.8590e-04,\n",
      "         1.3619e-03,  1.2646e-03, -3.5289e-04,  4.0870e-05,  7.9397e-04,\n",
      "        -4.2119e-04, -8.8039e-05, -1.8257e-04,  2.4690e-04, -8.8277e-05,\n",
      "        -8.5799e-04, -3.1495e-04,  5.8635e-05,  3.3509e-05, -7.4510e-04,\n",
      "         1.3284e-05,  1.7629e-05, -4.8275e-04,  2.2122e-04,  5.2317e-06,\n",
      "        -4.0941e-04,  9.2624e-04, -3.8309e-04, -1.2355e-04, -1.4769e-04,\n",
      "        -6.1172e-04, -2.4349e-04, -5.2565e-04, -7.9745e-04,  3.4377e-04,\n",
      "         1.4412e-03,  4.7232e-04, -5.2619e-04,  2.7965e-04,  1.5899e-03,\n",
      "         6.3030e-04, -3.3840e-04, -9.6407e-05, -5.4548e-04,  3.2682e-04,\n",
      "         4.4401e-04, -4.4656e-06,  1.8378e-03,  6.7318e-04,  6.7572e-04,\n",
      "         3.8366e-04, -2.0061e-04, -1.2650e-03,  5.8804e-04,  6.0206e-06,\n",
      "         5.0515e-04, -6.0198e-04,  7.1424e-05,  6.0368e-04, -6.1973e-04,\n",
      "        -1.7243e-04,  6.1821e-04, -2.3071e-04,  6.1477e-04,  1.9386e-04,\n",
      "        -9.7430e-05,  1.2017e-05, -4.1124e-04,  2.4670e-04, -1.3969e-04,\n",
      "        -1.5342e-04, -9.6601e-05, -1.4045e-03, -6.9105e-04, -5.1777e-04,\n",
      "        -8.6618e-04,  3.0971e-04,  2.3754e-04, -2.8831e-04,  1.5200e-04,\n",
      "         3.3486e-04,  7.0725e-04, -1.1541e-03,  3.9724e-04, -2.7617e-04,\n",
      "         8.0937e-04, -3.2775e-04, -7.2502e-04, -1.1624e-04,  2.5271e-04,\n",
      "         1.9886e-05, -3.2536e-04, -4.3201e-04,  2.9460e-04, -5.5572e-04,\n",
      "         4.4772e-04, -7.6973e-04, -1.3690e-03,  1.9541e-04,  4.4534e-05,\n",
      "         1.4598e-05, -3.5927e-05, -9.5714e-05, -5.7018e-04, -1.6756e-03,\n",
      "         3.7830e-04, -1.5465e-04,  2.1623e-04, -3.7058e-04, -1.2911e-03,\n",
      "         4.3637e-04, -3.0390e-04, -5.9290e-04, -2.3189e-04, -3.2810e-05,\n",
      "        -1.7407e-04,  4.4815e-04, -1.5924e-03,  2.8898e-04, -1.6484e-04,\n",
      "        -4.1791e-04, -1.0396e-03,  6.0973e-05, -4.9562e-04, -9.8552e-04,\n",
      "         4.5082e-04,  1.4555e-04, -6.3433e-04,  3.3578e-04, -6.8221e-05,\n",
      "        -1.0216e-04, -4.2732e-04,  4.6627e-04, -5.8566e-04,  3.3371e-04,\n",
      "        -6.4469e-04, -1.0857e-03, -6.6762e-04,  1.3743e-04,  2.5697e-04,\n",
      "        -2.0774e-04,  5.3843e-05, -1.5010e-04,  3.0724e-05, -9.0772e-05,\n",
      "         3.3900e-04, -1.0798e-04,  5.1484e-04,  4.6475e-04,  3.2467e-05,\n",
      "         1.3755e-04,  3.2990e-04, -4.4343e-04, -3.9637e-04,  1.8406e-03,\n",
      "         1.5185e-03, -7.0415e-04,  2.2335e-05, -4.9641e-04,  6.7147e-04,\n",
      "         5.6543e-04,  3.6299e-05, -1.4012e-04, -1.5735e-05, -1.2917e-04,\n",
      "         8.6883e-04, -1.2597e-03,  5.3967e-04,  5.8824e-05, -1.3207e-03,\n",
      "         1.9000e-03,  2.7216e-04, -9.2486e-04, -6.2030e-05, -1.9347e-04,\n",
      "         6.6071e-04,  2.1746e-04, -5.5941e-04,  4.6990e-04, -2.2824e-04,\n",
      "        -8.5845e-04,  1.8195e-04, -3.9654e-05, -3.1594e-04,  4.4929e-04,\n",
      "         2.6555e-04,  5.9855e-04,  8.0776e-04,  3.0060e-04, -3.8309e-04,\n",
      "         3.4617e-04, -3.2460e-04,  6.5920e-04, -4.8762e-05, -5.4513e-04,\n",
      "         2.4958e-04,  4.6108e-04, -1.0333e-04,  9.4655e-04,  3.5182e-04,\n",
      "        -4.7043e-04, -3.8220e-05, -1.3644e-04,  2.4593e-04, -1.8785e-04,\n",
      "         1.0426e-05, -7.6909e-05, -8.3535e-04,  7.4720e-04,  3.4695e-04,\n",
      "        -5.6207e-04,  4.5533e-04,  7.1194e-04,  2.7264e-04,  5.0811e-04,\n",
      "        -1.9132e-04, -6.8748e-04, -5.1670e-04, -1.0021e-03, -1.6240e-03,\n",
      "         2.4656e-04,  8.8518e-04,  6.7556e-06,  6.4268e-04,  7.7038e-06,\n",
      "         3.6939e-04, -2.6674e-04,  3.0908e-04, -8.5046e-05, -5.4864e-04,\n",
      "         6.4068e-04,  3.2841e-05, -1.5384e-04,  3.4701e-04,  2.9363e-04,\n",
      "        -2.4336e-04, -5.9772e-04,  7.7784e-04,  3.6790e-04, -8.2835e-04,\n",
      "         5.1373e-04,  2.6544e-04, -6.8916e-05, -1.1209e-03,  1.2504e-03,\n",
      "         7.4837e-05,  6.9872e-04,  3.0425e-04, -6.9531e-05, -4.7353e-05,\n",
      "         3.5594e-05])\n",
      "name of a parameter: fc3.weight, gradient: tensor([[-0.0511,  0.0042, -0.0113,  ...,  0.0210,  0.1355, -0.0452],\n",
      "        [-0.2089, -0.0866, -0.1060,  ...,  0.0386,  0.2009, -0.1635],\n",
      "        [-0.1074,  0.0086, -0.1239,  ...,  0.1097, -0.2480, -0.0339],\n",
      "        ...,\n",
      "        [-0.0537,  0.0000, -0.0360,  ...,  0.0000,  0.1099, -0.0059],\n",
      "        [ 0.0121, -0.1114,  0.0284,  ...,  0.1113, -0.0300,  0.0375],\n",
      "        [ 0.1587,  0.3884,  0.1907,  ...,  0.0821, -0.0464,  0.0936]])\n",
      "name of a parameter: fc3.bias, gradient: tensor([ 8.8442e-04, -5.3329e-04, -1.3124e-03,  1.1789e-03,  3.6223e-03,\n",
      "        -1.9733e-03, -5.0584e-03, -1.7892e-03,  6.3316e-03,  3.6987e-03,\n",
      "        -4.3298e-03, -1.2282e-03,  3.4733e-04,  2.6283e-03,  5.8133e-04,\n",
      "         9.7976e-04,  3.4094e-03, -2.0655e-04, -3.8301e-03, -1.4098e-03,\n",
      "        -1.5531e-03,  1.1541e-03, -3.1201e-03, -2.4136e-03,  1.8890e-03,\n",
      "         5.1160e-03,  1.6521e-03,  2.2273e-03, -2.4875e-03,  2.0261e-03,\n",
      "         3.4902e-03, -1.1931e-03,  2.6653e-03,  9.1253e-04,  1.4573e-03,\n",
      "        -1.6600e-04, -1.1770e-03, -4.7887e-03,  3.0063e-03, -3.5566e-04,\n",
      "         1.6601e-03,  3.3859e-05,  4.7582e-03,  2.3017e-03, -7.3102e-04,\n",
      "         6.0551e-03,  5.2561e-04, -3.7474e-03, -5.0908e-03,  1.8017e-05,\n",
      "        -3.3681e-03,  2.7499e-03, -4.7585e-03,  1.1257e-03,  8.5978e-04,\n",
      "         6.9862e-04, -3.7663e-04, -6.8720e-04, -4.4646e-03, -3.4312e-03,\n",
      "         1.9695e-03, -1.8963e-03,  3.5814e-04,  2.1536e-03,  1.3054e-03,\n",
      "         7.6562e-04, -1.3879e-03,  3.0820e-03, -4.1775e-03, -7.8923e-04,\n",
      "         5.7447e-03,  2.4235e-03, -1.4052e-03,  2.9912e-04,  2.9958e-04,\n",
      "         1.0561e-04,  1.4614e-03, -1.0004e-03,  1.3314e-03,  4.5405e-03,\n",
      "         2.1757e-04,  4.1895e-03, -2.0255e-04,  6.0831e-03,  6.5400e-04,\n",
      "         4.3857e-04,  2.0934e-03,  1.0951e-04,  2.0945e-03,  1.6164e-03,\n",
      "         5.7807e-04,  1.4503e-03,  2.0239e-03, -1.3968e-03,  2.9243e-03,\n",
      "         3.6873e-04,  8.8417e-04, -6.6212e-04,  1.6563e-04, -3.0011e-03,\n",
      "         3.3775e-03,  7.3849e-04, -1.5384e-03,  7.3735e-03,  1.8733e-04,\n",
      "         2.3348e-03, -1.5697e-03,  8.2771e-04,  4.5819e-04,  2.0694e-03,\n",
      "         8.4159e-04,  3.0927e-03,  2.2821e-04,  5.5921e-03,  1.4393e-03,\n",
      "         1.5080e-03,  1.6447e-03,  4.2228e-03, -5.1890e-03,  2.1505e-05,\n",
      "         3.6296e-03,  2.1993e-03,  4.1586e-03,  2.4237e-03,  2.0884e-03,\n",
      "        -3.1427e-03,  1.5736e-03,  4.4561e-03, -3.4885e-03,  1.9532e-05,\n",
      "        -1.9619e-03, -6.8556e-03, -5.3040e-04,  5.0417e-03,  1.1599e-03,\n",
      "        -1.2694e-04,  7.6946e-04, -3.6026e-03,  1.3944e-03, -4.8648e-04,\n",
      "         5.3934e-03,  1.9271e-03, -2.0267e-03,  2.3431e-03, -2.8492e-03,\n",
      "        -1.1118e-03,  2.0634e-03, -2.5373e-04,  3.1926e-03, -8.2007e-04,\n",
      "        -2.2674e-03, -3.0480e-03, -7.8262e-04, -1.7775e-03,  3.3248e-03,\n",
      "         3.0928e-03,  3.1182e-03,  7.0045e-04, -2.6348e-04,  3.8198e-03])\n",
      "name of a parameter: fc4.weight, gradient: tensor([[ 0.9278,  0.5719,  0.3457,  ..., -0.0037,  0.2358,  0.1870],\n",
      "        [ 0.0503,  0.0229,  0.1149,  ...,  0.0316,  0.0468,  0.0337],\n",
      "        [-0.0335, -0.1575,  0.0446,  ..., -0.0292, -0.0553,  0.0817],\n",
      "        ...,\n",
      "        [ 0.9886,  0.6666,  0.2883,  ..., -0.0241,  0.0863,  0.3389],\n",
      "        [-0.0614, -0.1798,  0.2807,  ...,  0.0658,  0.0194,  0.0761],\n",
      "        [ 0.2924,  0.2026,  0.0098,  ..., -0.0095,  0.0630,  0.1305]])\n",
      "name of a parameter: fc4.bias, gradient: tensor([ 8.8765e-03,  6.2720e-03, -2.1407e-03,  1.4319e-02,  4.4515e-04,\n",
      "         1.7096e-02,  6.5632e-03,  9.8501e-03,  1.9544e-03, -1.9274e-03,\n",
      "         2.7318e-02,  1.8460e-02,  3.4409e-02, -9.7379e-03,  6.1410e-03,\n",
      "        -1.2189e-02,  7.4943e-03, -3.2993e-03, -1.5759e-02, -9.2379e-03,\n",
      "        -5.0697e-03,  1.3152e-02,  1.1410e-05, -1.5338e-02,  2.4197e-03,\n",
      "        -3.0901e-03,  9.9586e-03, -1.3574e-02,  1.3699e-02,  2.5059e-02,\n",
      "         4.1874e-03, -9.8083e-03, -1.4978e-02, -3.8048e-02,  6.6386e-04,\n",
      "        -2.0969e-02, -1.6017e-02,  4.3289e-03,  1.1497e-02,  1.6718e-03])\n",
      "name of a parameter: fc5.weight, gradient: tensor([[ 2.3268e+00,  4.7719e+00,  3.7699e-01,  1.6903e-01,  1.9567e+00,\n",
      "          1.4202e+00,  6.8320e-01,  8.1715e-01, -1.7295e-01,  1.8630e+00,\n",
      "          6.7614e+00,  7.2098e-01,  6.4888e+00,  6.1507e-01,  4.2954e-02,\n",
      "          4.4981e-02,  4.5808e+00,  4.6767e-01,  1.6102e+00,  2.5139e+00,\n",
      "          2.0884e+00, -8.9195e-01, -8.1235e-05, -3.1182e-01,  2.3514e-01,\n",
      "          3.7806e-01,  4.9294e+00,  1.2270e+00,  3.6730e+00,  4.3692e+00,\n",
      "         -7.4413e-02,  2.0346e+00,  4.3355e+00,  1.0109e+00,  1.7992e+00,\n",
      "          7.9010e-01,  1.1008e+00,  4.4301e+00,  5.5027e-01,  1.8343e+00],\n",
      "        [-1.7569e+00, -2.7019e+00,  1.0572e+00, -3.1215e-01, -1.5191e+00,\n",
      "         -6.9919e-01, -1.7013e-01, -7.3188e-01,  2.1922e-01, -7.4436e-01,\n",
      "         -4.0680e+00, -6.7888e-01, -2.4092e+00,  2.1064e-01,  1.5743e-01,\n",
      "          5.2207e-01, -2.4883e+00, -4.8445e-01, -1.1328e+00, -5.5558e-01,\n",
      "         -2.5001e-01,  5.1631e-01,  2.2267e-05,  6.3843e-01,  2.4372e-02,\n",
      "         -1.1422e-01, -1.9566e+00, -8.0612e-01, -2.1005e+00, -1.2282e+00,\n",
      "          1.5461e-01, -2.5565e-01, -2.2457e+00, -4.3208e-01,  1.1196e+00,\n",
      "          4.2222e-01,  9.0366e-01, -1.0652e+00,  1.4988e-01,  5.7054e-02],\n",
      "        [-5.6986e-01, -2.0700e+00, -1.4342e+00,  1.4311e-01, -4.3759e-01,\n",
      "         -7.2097e-01, -5.1307e-01, -8.5268e-02, -4.6274e-02, -1.1186e+00,\n",
      "         -2.6934e+00, -4.2099e-02, -4.0797e+00, -8.2571e-01, -2.0038e-01,\n",
      "         -5.6705e-01, -2.0926e+00,  1.6785e-02, -4.7734e-01, -1.9584e+00,\n",
      "         -1.8384e+00,  3.7565e-01,  5.8965e-05, -3.2661e-01, -2.5951e-01,\n",
      "         -2.6384e-01, -2.9728e+00, -4.2089e-01, -1.5724e+00, -3.1410e+00,\n",
      "         -8.0192e-02, -1.7790e+00, -2.0897e+00, -5.7881e-01, -2.9188e+00,\n",
      "         -1.2123e+00, -2.0045e+00, -3.3649e+00, -7.0015e-01, -1.8913e+00]])\n",
      "name of a parameter: fc5.bias, gradient: tensor([ 0.2404, -0.0662, -0.1743])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_MLP.named_parameters():\n",
    "    print(\"name of a parameter: {}, gradient: {}\".\n",
    "          format(name, param.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have to do now is subtract the gradient of a given parameter from the parameter tensor itself and do it for all parameters of the model - that should decrease the loss. Normally the gradient is multiplied by a learning rate parameter $\\lambda$ so we don't go too far in the loss landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "for param in model_MLP.parameters():\n",
    "    param.data.add_(-lr*param.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call to backward **accumulates** gradients - so we also need to zero the gradient tensors if we want to keep going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_MLP.parameters():\n",
    "    param.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a much simpler way of doing this - we can use the pytorch [optim](https://pytorch.org/docs/stable/optim.html) classes. This allows us to easily use more advanced optimization options (like momentum or adaptive optimizers like [Adam](https://arxiv.org/abs/1412.6980)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model_MLP.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a new batch of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1=next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=batch1[0]\n",
    "labels=batch1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 0, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 1, 2, 1, 2, 2, 1, 0, 2,\n",
      "        0, 2, 1, 0, 0, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out=model_MLP(data)\n",
    "loss_tensor=loss_module(model_out,labels)\n",
    "loss_tensor.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just put the code above in a loop and be done with it, but the usual practice would be to wrap this functionality in a training object. Here we'll use the [engine](/edit/utils/engine.py) class. Let's examine it. We'll talk about:\n",
    "  1. Implementation of the training loop\n",
    "  2. Evaluation on validation set and training and test modes.\n",
    "  3. Turning evaluation of gradients on and off.\n",
    "  4. Saving and retrieving the model and optimizer state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.engine import Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a configuration object -we'll use this to set up our training engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    pass\n",
    "config=CONFIG()\n",
    "config.batch_size_test =512\n",
    "config.batch_size_train = 256\n",
    "config.batch_size_val = 512\n",
    "config.lr=0.01\n",
    "config.device = 'cpu'\n",
    "config.num_workers_train=2\n",
    "config.num_workers_val=2\n",
    "config.num_workers_test=2\n",
    "config.dump_path = '../model_state_dumps'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sticking to CPU\n",
      "Creating a directory for run dump: ../model_state_dumps/20240425_141704/\n"
     ]
    }
   ],
   "source": [
    "engine=Engine(model_MLP,dset,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size_test': 512, 'batch_size_train': 256, 'batch_size_val': 512, 'lr': 1e-05, 'device': 'cpu', 'num_workers_train': 2, 'num_workers_val': 2, 'num_workers_test': 2, 'dump_path': '../model_state_dumps'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Starting @ 2024-04-25 14:17:32\n",
      "... Iteration 0 ... Epoch 0.00 ... Validation Loss 1.205 ... Validation Accuracy 0.297\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_141704/SimpleMLP.pth\n",
      "best validation loss so far!: 1.2047725915908813\n",
      "Saved checkpoint as: ../model_state_dumps/20240425_141704/SimpleMLPBEST.pth\n",
      "... Iteration 1 ... Epoch 0.01 ... Loss 1.150 ... Accuracy 0.371\n",
      "... Iteration 11 ... Epoch 0.07 ... Loss 1.166 ... Accuracy 0.375\n",
      "... Iteration 21 ... Epoch 0.13 ... Loss 1.206 ... Accuracy 0.348\n",
      "... Iteration 31 ... Epoch 0.20 ... Loss 1.150 ... Accuracy 0.398\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "engine.train(epochs=2.5,report_interval=10,valid_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a simple Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open [simpleCNN](http://localhost:8888/edit/models/simpleCNN.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simpleCNN import SimpleCNN\n",
    "model_CNN=SimpleCNN(num_input_channels=38,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rotate_chan(x):\n",
    "    return np.transpose(x,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset=WCH5Dataset(\"/project/rpp-blairt2k/machine_learning/data/TRISEP_data/NUPRISM.h5\",val_split=0.1,test_split=0.1,transform=rotate_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sticking to CPU\n",
      "Creating a directory for run dump: ../model_state_dumps/20240424_223542/\n"
     ]
    }
   ],
   "source": [
    "engine=Engine(model_CNN,dset,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of a parameter: f_embed.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_embed.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2a.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2a.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2b.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv2b.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3a.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3a.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3b.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv3b.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv4.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: f_conv4.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc1.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc2.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.weight, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n",
      "name of a parameter: fc3.bias, type: <class 'torch.nn.parameter.Parameter'>, parameter requires a gradient?: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_CNN.named_parameters():\n",
    "    print(\"name of a parameter: {}, type: {}, parameter requires a gradient?: {}\".\n",
    "          format(name, type(param),param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Starting @ 2024-04-24 22:35:47\n",
      "tensor([[-0.2139,  0.2188,  0.1590],\n",
      "        [-0.2356,  0.1918,  0.1596]])\n",
      "... Iteration 0 ... Epoch 0.00 ... Validation Loss 1.004 ... Validation Accuracy 0.000\n",
      "Saved checkpoint as: ../model_state_dumps/20240424_223542/SimpleCNN.pth\n",
      "best validation loss so far!: 1.0036206245422363\n",
      "Saved checkpoint as: ../model_state_dumps/20240424_223542/SimpleCNNBEST.pth\n",
      "tensor([[-0.2629,  0.2181,  0.2056]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Unfortunately this seems to hang and not train\n",
    "%%time\n",
    "engine.train(epochs=5,report_interval=1,valid_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HKCA2 Python 3.x Kernel",
   "language": "python",
   "name": "hk_ca_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
